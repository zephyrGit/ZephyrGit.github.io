<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Anaconda更换国内源</title>
      <link href="/2020/05/12/Anaconda%E6%9B%B4%E6%8D%A2%E5%9B%BD%E5%86%85%E6%BA%90/"/>
      <url>/2020/05/12/Anaconda%E6%9B%B4%E6%8D%A2%E5%9B%BD%E5%86%85%E6%BA%90/</url>
      
        <content type="html"><![CDATA[<h2 id="1-添加清华源"><a href="#1-添加清华源" class="headerlink" title="1. 添加清华源"></a>1. 添加清华源</h2><p>修改.condarc文件如下：</p><pre class="line-numbers language-shell"><code class="language-shell">channels:  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/peterjc123/  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/show_channel_urls: truessl_verify: true<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-添加中科大源"><a href="#2-添加中科大源" class="headerlink" title="2. 添加中科大源"></a>2. 添加中科大源</h2><pre class="line-numbers language-python"><code class="language-python">conda config <span class="token operator">-</span><span class="token operator">-</span>add channels https<span class="token punctuation">:</span><span class="token operator">//</span>mirrors<span class="token punctuation">.</span>ustc<span class="token punctuation">.</span>edu<span class="token punctuation">.</span>cn<span class="token operator">/</span>anaconda<span class="token operator">/</span>pkgs<span class="token operator">/</span>main<span class="token operator">/</span>conda config <span class="token operator">-</span><span class="token operator">-</span>add channels https<span class="token punctuation">:</span><span class="token operator">//</span>mirrors<span class="token punctuation">.</span>ustc<span class="token punctuation">.</span>edu<span class="token punctuation">.</span>cn<span class="token operator">/</span>anaconda<span class="token operator">/</span>pkgs<span class="token operator">/</span>free<span class="token operator">/</span>conda config <span class="token operator">-</span><span class="token operator">-</span>add channels https<span class="token punctuation">:</span><span class="token operator">//</span>mirrors<span class="token punctuation">.</span>ustc<span class="token punctuation">.</span>edu<span class="token punctuation">.</span>cn<span class="token operator">/</span>anaconda<span class="token operator">/</span>cloud<span class="token operator">/</span>conda<span class="token operator">-</span>forge<span class="token operator">/</span>conda config <span class="token operator">-</span><span class="token operator">-</span>add channels https<span class="token punctuation">:</span><span class="token operator">//</span>mirrors<span class="token punctuation">.</span>ustc<span class="token punctuation">.</span>edu<span class="token punctuation">.</span>cn<span class="token operator">/</span>anaconda<span class="token operator">/</span>cloud<span class="token operator">/</span>msys2<span class="token operator">/</span>conda config <span class="token operator">-</span><span class="token operator">-</span>add channels https<span class="token punctuation">:</span><span class="token operator">//</span>mirrors<span class="token punctuation">.</span>ustc<span class="token punctuation">.</span>edu<span class="token punctuation">.</span>cn<span class="token operator">/</span>anaconda<span class="token operator">/</span>cloud<span class="token operator">/</span>bioconda<span class="token operator">/</span>conda config <span class="token operator">-</span><span class="token operator">-</span>add channels https<span class="token punctuation">:</span><span class="token operator">//</span>mirrors<span class="token punctuation">.</span>ustc<span class="token punctuation">.</span>edu<span class="token punctuation">.</span>cn<span class="token operator">/</span>anaconda<span class="token operator">/</span>cloud<span class="token operator">/</span>menpo<span class="token operator">/</span>conda config <span class="token operator">-</span><span class="token operator">-</span>set show_channel_urls yes<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-Linux"><a href="#3-Linux" class="headerlink" title="3. Linux"></a>3. Linux</h2><p>修改配置文件写在~/.condarc </p><pre class="line-numbers language-shell"><code class="language-shell">vim ~/.condarc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">channels<span class="token punctuation">:</span>  <span class="token operator">-</span> https<span class="token punctuation">:</span><span class="token operator">//</span>mirrors<span class="token punctuation">.</span>ustc<span class="token punctuation">.</span>edu<span class="token punctuation">.</span>cn<span class="token operator">/</span>anaconda<span class="token operator">/</span>pkgs<span class="token operator">/</span>main<span class="token operator">/</span>  <span class="token operator">-</span> https<span class="token punctuation">:</span><span class="token operator">//</span>mirrors<span class="token punctuation">.</span>ustc<span class="token punctuation">.</span>edu<span class="token punctuation">.</span>cn<span class="token operator">/</span>anaconda<span class="token operator">/</span>cloud<span class="token operator">/</span>conda<span class="token operator">-</span>forge<span class="token operator">/</span>  <span class="token operator">-</span> https<span class="token punctuation">:</span><span class="token operator">//</span>mirrors<span class="token punctuation">.</span>tuna<span class="token punctuation">.</span>tsinghua<span class="token punctuation">.</span>edu<span class="token punctuation">.</span>cn<span class="token operator">/</span>anaconda<span class="token operator">/</span>pkgs<span class="token operator">/</span>free<span class="token operator">/</span>  <span class="token operator">-</span> defaultsshow_channel_urls<span class="token punctuation">:</span> true<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h2><pre class="line-numbers language-python"><code class="language-python">conda config <span class="token operator">-</span><span class="token operator">-</span>remove<span class="token operator">-</span>key channels<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>anaconda用法：<br>查看已经安装的包：</p><pre class="line-numbers language-python"><code class="language-python">pip list 或者 conda list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>安装和更新：</p><pre class="line-numbers language-shell"><code class="language-shell">pip install requestspip install requests --upgrade或者conda install requestsconda update requests<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>更新所有库</p><pre class="line-numbers language-shell"><code class="language-shell">conda update --all更新 conda 自身conda update conda更新 anaconda 自身conda update anaconda<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux:常用命令</title>
      <link href="/2020/05/12/Linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2020/05/12/Linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h1 id="linux常用命令"><a href="#linux常用命令" class="headerlink" title="linux常用命令"></a>linux常用命令</h1><h2 id="一、linux文件系统结构"><a href="#一、linux文件系统结构" class="headerlink" title="一、linux文件系统结构"></a>一、linux文件系统结构</h2><pre class="line-numbers language-shell"><code class="language-shell">   sudo apt-get install tree   tree --help  #查看帮助   tree -L 1  #显示文件目录<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-shell"><code class="language-shell">root@ubuntu16 /# tree -L 1.           #系统根目录├── bin     #存放常见的命令├── boot    #系统启动文件和核心文件都在这个目录├── cdrom   #光驱├── dev     #存放设备文件，包括硬盘、光驱、键盘、鼠标等├── etc     #系统配置文件都在这个目录下├── home    #普通用户的家目录├── lib     #系统链接库├── lib64   #64位的链接库├── lost+found   #系统自动生成的，如果文件系统出错，会在目录下产生文件，记录错误├── media        #系统自动挂载的光驱、usb等├── mnt          #mount简写 挂载其他文件系统├── opt          #可在此安装第三方软件 ├── proc         #系统进程的信息、系统状态信息├── root         #超管的目录├── run          #进程运行数据├── sbin         #管理员的命令，普通用户无法使用├── srv          #服务信息├── sys          #系统相关├── tmp          #临时目录，所有用户都具有读写权限├── usr          #unix software resource  用户的软件安装到这个目录|    ├── bin     #应用程序的可执行文件|    ├── sbin    #用户或超管的标准命令|    ├── local   #管理员安装的应用程序目录|    └── share   #共享文件目录└── var          #存放不断扩充的文件。比如数据库文件、日志文件     ├── log     #日志目录，各种应用的日志     └── run     # /run的软连接<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="二、常见命令"><a href="#二、常见命令" class="headerlink" title="二、常见命令"></a>二、常见命令</h2><ol><li><p>ls</p><p>列出目录下的文件或子目录</p></li></ol><pre class="line-numbers language-shell"><code class="language-shell">   ls [参数]    #中括号表示可选   ls  -l    #以列表方式显示文件的详细信息   ls  -a   #显示隐藏文件，隐藏文件的文件名以.开头   ls  -al  #   ls --help #查看命令参数<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-shell"><code class="language-shell">   drwxr-xr-x  2 python python     4096 3月  28 11:20 Templates   drwxr-xr-x  2 python python     4096 3月  28 11:20 Videos<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>   第一部分：表示文件类型  d代表目录，-代表普通文件，l代表软连接<br>   第2部分，2-10列代表文件的权限：rwxr-xr-x.<br>   第3部分：数字代表文件的链接数<br>   第四部分：root代表文件的所有者<br>   第5部分：root表示文件属于哪个用户组<br>   第6部分：数字的表示文件大小，以字节为单位<br>   第7部分：时间，表示文件的修改时间<br>   第8部分：文件名</p><pre class="line-numbers language-shell"><code class="language-shell">   #文件权限   drwxr-xr-x.  2 root root 4096 Nov 20 07:36 tmp   r：read  可读   w：write 可写   x：excute  可执行   -：表示无权限   权限：       2-4位   ower  文件的所有者           5-7位   group：用户组       8-10位  other：其他用户<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>ll</li></ol><pre class="line-numbers language-shell"><code class="language-shell">   以列表方式显示，其实是ls -l的别名   白色代表普通文件   绿色代表可执行文件   蓝色代表目录<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>man命令</li></ol><pre class="line-numbers language-shell"><code class="language-shell">   #命令的帮助文档   sudo apt-get  install man   #用法：      man  命令名   常用的快捷键   空格 f     下翻页   b          上翻页   shift + g   到文件末尾  G   g         文件开头   q         退出   上下箭头   前翻和后翻   回车键     后翻   home      回到开始<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="4"><li><p>history命令</p><p>查看你敲过的命令</p></li><li><p>硬链接和软连接</p><p>文件都有文件名与数据，这在 Linux 上被分成两个部分：用户数据 (user data) 与元数据 (metadata)。用户数据，即文件数据块 (data block)，数据块是记录文件真实内容的地方；而元数据则是文件的附加属性，如文件大小、创建时间、所有者等信息。在 Linux 中，元数据中的 inode 号（inode 是文件元数据的一部分但其并不包含文件名，inode 号即索引节点号）才是文件的唯一标识而非文件名。文件名仅是为了方便人们的记忆和使用，系统或程序通过 inode 号寻找正确的文件数据块。</p><p>为解决文件的共享使用，Linux 系统引入了两种链接：硬链接 (hard link) 与软链接（又称符号链接，即 soft link 或 symbolic link）。链接为 Linux 系统解决了文件的共享使用，还带来了隐藏文件路径、增加权限安全及节省存储等好处。</p><ul><li>一个 inode 号对应多个文件名，则称这些文件为<strong>硬链接</strong><pre class="line-numbers language-shell"><code class="language-shell">link 源文件名 新文件名 ln 源文件名 新文件名 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ul><p>stat 文件名 #查看文件信息<br>ls -i  #查看目录下文件的硬链接数<br>python@ubuntu:/csl$ ls -la<br>total 4<br>913923 lrwxrwxrwx. 1 root root    5 Mar 18 16:20 2.txt -&gt; 1.txt<br>913926 -rw-r–r–. 2 root root    0 Mar 18 19:58 31.txt<br>913926 -rw-r–r–. 2 root root    0 Mar 18 19:58 32.txt<br>913925 -rwxr-xr-x. 1 root root    0 Mar 18 17:29 5.txt<br>913924 drwxr-xr-x. 2 root root 4096 Mar 18 17:29 test</p><h1 id="硬链接的特点："><a href="#硬链接的特点：" class="headerlink" title="硬链接的特点："></a>硬链接的特点：</h1><p>   1.只能对已存在的文件进行创建；<br>   2.不能交叉文件系统进行硬链接的创建；<br>   3.不能对目录进行创建，只可对文件创建；<br>   4.删除一个硬链接文件并不影响其他有相同inode 号的文件。</p></li></ol><pre><code>   -   软连接    软链接与硬链接不同，若文件用户数据块中存放的内容是另一文件的路径名的指向，则该文件就是软连接。软链接就是一个普通文件，只是数据块内容有点特殊。软链接类似快捷方式~~~shellln -s 源文件 目标文件。软连接的特点：   软链接有自己的文件属性及权限等；   可对不存在的文件或目录创建软链接；   软链接可交叉文件系统；   软链接可对文件或目录创建；   创建软链接时，链接计数 i_nlink 不会增加；   删除软链接并不影响被指向的文件，但若被指向的原文件被删除，则相关软连接被称为死链接</code></pre><h2 id="三、目录管理"><a href="#三、目录管理" class="headerlink" title="三、目录管理"></a>三、目录管理</h2><ol><li><p>绝对路径和相对路径</p><p>linux的目录和windows不同，不区分盘符，只有一个根目录，根目录用/表示。</p><ul><li>绝对路径：从根目录到当前文件（目录）的路径，比如：/home/python</li><li>相对路径：以当前目录为基准，表示上级目录或子目录<ul><li>用 . 表示当前目录，一般执行shell脚本可以用 . 1.sh或者 ./1.sh</li><li>用..表示上级目录 </li></ul></li><li>linux目录分隔符只能用正斜线（/）表示</li><li>用 ~ 表示用户主目录，用 - 表示来源目录（你从哪个目录切换到当前目录的）</li></ul></li><li><p>目录切换</p><pre class="line-numbers language-shell"><code class="language-shell">cd 目录名  #切换目录 .  #当前目录 ..  #代表上级目录 /   #代表根目录 ~   #用户家目录  root用户的家目录/root   普通用户的家目录/home/用户名 cd /etc/yum.repos.d cd / #切换到根目录 cd -  #切换到来源目录 cd ~ #返回用户的家目录 pwd #显示当前的目录名<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>提示信息</p></li></ol><pre class="line-numbers language-shell"><code class="language-shell">   [root@localhost ~]# cd /   [root@localhost /]$   root代表用户名   localhost 主机名   ~ 用户的家目录  等同于   /home/用户名   /  根目录   # 表示超级管理员在操作   $ 普通用户在操作<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="4"><li>创建目录   </li></ol><pre class="line-numbers language-shell"><code class="language-shell">   sudo mkdir  目录名   sudo mkdir -p  目录名    #递归创建目录   sudo mkdir -p  h1801/1/2   sudo mkdir -p  1/{2,3}/{4,5,6} #<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ol start="5"><li>删除目录  rmdir</li></ol><pre class="line-numbers language-shell"><code class="language-shell">   sudo rmdir [option]  目录名    #删除的时候目录必须为空   sudo rmdir -p  目录名   #递归删除空目录   sudo rmdir -p 1/2/3 #1,2,3目录都必须不能有文件   sudo rm -rf 目录名<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="四、文件操作"><a href="#四、文件操作" class="headerlink" title="四、文件操作"></a>四、文件操作</h2><ol><li><p>文件创建  </p><pre class="line-numbers language-shell"><code class="language-shell">sudo touch  文件名 [文件名2] [文件名3]....   #创建多个空文件,如果文件存在，自动忽略，不会覆盖echo 'hello world'  > 1.txt   #可以将显示内容输出到文件，但会覆盖原来的内容，文件不存在则创建echo '世界，你好'    >> 1.txt  #将显示内容追加到文件末尾，文件不存在则创建# >  >> 输出重定向<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>文件移动</p></li></ol><pre class="line-numbers language-shell"><code class="language-shell">   sudo mv 源文件   目标文件   #销毁原件   sudo mv  1.txt  ./lpl/  #将1.txt移动到字目录lpl下，文件名不变   sudo mv  1.txt  2.txt   #如果在同一个目录就是文件重命名  将1.txt重命名为2.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol start="3"><li>文件拷贝</li></ol><pre class="line-numbers language-shell"><code class="language-shell">   sudo cp 源文件   目标文件   sudo cp -rf  源目录   目标目录   #递归拷贝目录<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="4"><li>文件删除</li></ol><pre class="line-numbers language-shell"><code class="language-shell">   sudo rm  文件名     sudo rm -i 文件名  #删除前逐一确认   sudo rm  -f  文件名   #删除文件不带提示   sudo rm -rf  目录名   #递归删除目录<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ol start="5"><li>文件查看</li></ol><pre class="line-numbers language-shell"><code class="language-shell">   cat  文件名       #输出文件内容，从前往后输出，   tac   文件名      #cat的反写，从后往前输出   head -n N  文件名   #显示文件的前几行，可以指定查看的行数，默认显示10行   tail -n N 文件名   #显示文件的最后几行，可以指定查看的行数   tail -f  cat 文件名   #实时显示文件内容   watch -d -n 秒杀 cat 文件名  #实时显示文件内容 有高亮   sudo vi  文件名      more  文件名       #从前往后查看，可以翻屏 ,不能往前翻  回车一行行查看，空格翻屏  q退出   less  文件名       #和more类似，可以前翻页，g首页 G尾页，b前翻页，空格和f后翻页，q退出   stat  文件名       #查看文件详细信息   stat 2.txt     File: `2.txt'     Size: 146           Blocks: 8          IO Block: 4096   regular file   Device: fd00h/64768d    Inode: 913936      Links: 1   Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)   Access: 2017-11-21 00:44:49.108999194 -0500   Modify: 2017-11-21 00:44:43.773000078 -0500   Change: 2017-11-21 00:44:43.775000065 -0500<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="6"><li><p>文件查找</p><ul><li>find</li></ul><pre class="line-numbers language-shell"><code class="language-shell"># find 用于在系统内搜索指定文件用法：   find [路径] [参数]     -name  按文件名查找     -mtime +/-n  #-n表示n天以内修改的文件，+n表示修改超过n天的文件     -user   #按文件属主查找     -size [+/-]n[c/k/M/G] #查找文件长度为n块，+表示大于，-表示小于；c是字节      -perm 权限数值    #按照文件权限进行查找find /  -name  "文件名"           #从根目录查找指定文件名的文件find /csl/sh1702 -name "2.txt"  #查找指定目录先的文件find /tools -mtime -3           #查找tools目录下修改时间是3天以内的文find /tools  -size 12c            #查找长度为12字节的文件find /var ‐perm 0642 ‐size +10k ‐size ‐100k ‐name '*.log' #在/var目录下，查找10-100kgrep  hello  2.txt  #查找文件内容ls -al | grep 1.php    # |管道操作，将ls -al操作结果传递给grep，grep 在查找结果搜索指定文件名 which 命令名   #查找命令 whereis  文件名     #只能搜索命令、源文件、二进制文件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>grep</li></ul><pre class="line-numbers language-shell"><code class="language-shell">#grep 用于搜索文件内容用法：   grep [options] 'pattern' filename     -i  不区分大小写     -r  递归查找子目录     -l  列出文件内容符合指定的范本样式的文件名称。     -n  显示行号     -w  只匹配单词，不是匹配单词一部分     -E 按正则表达式搜索     --include '*.py'  #仅搜索py文件     --exclude '*.py'  #不搜索py文件   #只在目录中所有的.php和.html文件中递归搜索字符"echo"   grep "Root" -w -n -i /etc/passwd<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>文件内容统计（wc）</p><pre class="line-numbers language-shell"><code class="language-shell">用法：   wc [options] [文件列表]      -l  统计有多少行      -w  统计有多少单词 $ wc -l  /etc/passwd  #统计passwd有多少用户<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>awk</p><p>awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。</p></li></ol><pre class="line-numbers language-shell"><code class="language-shell">   语法：awk '{pattern + action}' {filenames}   cat /etc/passwd |awk  -F ':'  '{print $1}'   #$1显示第一列  -F 指定分割符为':'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>   ​</p><ol start="9"><li><p>sort</p><p>sort将文件/文本的每一行作为一个单位，相互比较，比较原则是从首字符向后，依次按<a href="http://zh.wikipedia.org/zh/ASCII" target="_blank" rel="noopener">ASCII</a>码值进行比较，最后将他们按升序输出。</p></li></ol><pre class="line-numbers language-shell"><code class="language-shell">   sort(选项)(参数)   选项：      -u忽略相同行      -k 按指定列排序      -n 按数值排序      -t 分割符      -r 逆序    #指定passwd文件按第三列 的数值比较，列之间的分隔符为：    cat /etc/passwd | sort -n -t ':' -k 3  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>   ​</p><h2 id="五-文件权限"><a href="#五-文件权限" class="headerlink" title="五. 文件权限"></a>五. 文件权限</h2><p>   1.文件权限修改</p><pre class="line-numbers language-shell"><code class="language-shell">   -rwxr-xr-x.  1 root root   24 Nov 21 20:26 1.sh   -rw-r--r-x.  1 root root    0 Nov 20 07:37 1.txt   -rw-r--r--.  1 root root    0 Nov 20 07:37 2.txt   #1.数字表示   r  4 100   读   w  2 010   写   x  1 001   执行   -  0       没有权限   rwx   7 可读可写可执行   rwxrw-r-- 764  文件拥有者可读可写可执行  文件所属的组可读可写  其他人可读   #2.符号表示   u  表示文件的拥有者    g  文件所属的组   o  其他人   a  所有的人  all   u+/-/=  u=rwx  g+x  o-r   + 表示增加权限   -  削减权限   =  赋权限   chmod o-x 32.txt   #削减其他用户的可执行权限   chmod a=rwx 32.txt  #给所有人赋可读可写可执行权限   chmod o+x,g+w 32.txt   chmod o=x 32.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>chmod </li></ul><pre class="line-numbers language-shell"><code class="language-shell">        用法：            chmod  权限  文件名/目录            chmod  -R  权限  目录  递归修改目录及其子目录的所有文件的权限         #数字表示         chmod 641  1.sh           #符号表示         chmod a=rwx 1.sh         chmod g-w 1.sh         chmod -R  o+w tmp   #递归修改tmp及其子目录中所有文件的权限<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>chown(change owner) 修改文件的所有者</li></ol><pre class="line-numbers language-shell"><code class="language-shell">    要求：所有者必须在/etc/passwd文件中         chown 用户名  文件名/目录名          chown 用户名:组名  文件名/目录名         chown :组名  文件名/目录名         chown -R 用户名  文件名/目录名         chown csl 1.sh         chown csl:csl 1.sh  #修改用户和所属组<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>修改用户组 chgrp(change group )</li></ol><pre class="line-numbers language-shell"><code class="language-shell">     chgrp 组名  文件名/目录名     chgrp -R 组名  文件名/目录名     chgrp -R csl tmp  #递归修改tmp及其子目录下文件所属组  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol start="4"><li><p>lsattr/chattr 修改和查看文件只读属性</p><pre class="line-numbers language-shell"><code class="language-shell"> lsattr  文件名   查看文件的只读属性,使用ls无法查看 chattr +/-i 文件名  给文件增加或去除只读属性 chattr +/-a 文件名  只能追加数据，不能修改或删除 lsattr 3.py  #3.py有只读属性 ----i--------e- 3.py chattr -i 3.py  #去掉只读属性 chattr +i 3.py  #添加只读属性<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="六-用户管理"><a href="#六-用户管理" class="headerlink" title="六.  用户管理"></a>六.  用户管理</h2><pre class="line-numbers language-shell"><code class="language-shell">sudo创建目录，并且修改目录的所属用户和所属用户组sudo mkdir  目录sudo chown -Rf  zhouguangyou  目录sudo  chgrp  -Rf  zhouguangyou  目录<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ol><li><p>用户和组</p><ul><li>一个用户必须有一个主组</li><li>一个用户可以有多个组</li><li>一个组可以有多个用户</li><li>用户账户的信息存放在/etc/passwd文件中；用户的密码存放到/etc/shadow，该文件只有root可以修改；组账户信息存放到/etc/group中</li></ul></li><li><p>useradd 添加一个用户</p></li></ol></li></ol><pre class="line-numbers language-shell"><code class="language-shell">       用法：          useradd [-gud] 用户名              -g 指定主组名或组id            -u 指定用户的id            -m 自动建立用户主目录            -d 指定用户的家目录            -s 指定用户登录后使用shell，默认是/bin/bash          #创建一个用户没有指定组，则默认创建一个和用户名一样的组，作为用户的主组       所有的用户都在/etc/passwd文件中       luoming:x:501:501::/home/luoming:/bin/bash       用户名  密码 用户id  用户所属组的id  用户的家目录   shell                     uid     gid       #Ubuntu 特别提供了一个adduser 命令以交互模式创建用户，       adduser csl<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​</p><ol start="3"><li>删除用户 userdel</li></ol><pre class="line-numbers language-shell"><code class="language-shell">userdel -r 用户名  删除用户同时删除家目录（家目录要和用户名一致才能删除）#如果用户登录了无法删除，应该先切换用户，然后kill -9 用户进程号，然后在删除<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="4"><li>修改用户信息  usermod</li></ol><pre class="line-numbers language-shell"><code class="language-shell"> usermod [option]  用户名      -u  用户id      -g  主组id      -G  附属组名称      -a  将用户添加到附属组，必须与-G配合使用      -d  用户的家目录      -l  用户登录名    sudo usermod -u 1001 -g 999 -l lkz  liwenkai    sudo usermod -a -G csl python  #将用户python添加到附属组csl中    sudo usermod -l newusername  oldusername #修改用户名<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="5"><li>修改用户密码</li></ol><p>用法：</p><pre class="line-numbers language-shell"><code class="language-shell">passwd [-lu] 用户名   -l 锁定账户密码   -u 解锁账户密码<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p> root 可以修改其他用户的密码<br> 普通用户只能修改自己的密码</p><ol start="6"><li>su和sudo</li></ol><p>​    Ubuntu默认禁止使用root账户，在系统安装的时候，创建的第一个用户作为管理员（属于sudo组），其权限要低于root，但比普通用户高，普通用户只能处理自己创建的东西，管理员可以安装软件、修改日期、删除用户等。在Ubuntu中一般看到提示符是$，当执行需要root权限操作的时候需要提升权限，我们可以使用sudo暂时提升用户权限</p><p>   我们也可以使用sudo切换用户身份，可以切换到root或管理员，完成工作后再切换回来</p><pre class="line-numbers language-shell"><code class="language-shell">用法：   sudo  命令  #需要输入用户自己的密码用法：      su    用户名  #需要输入目标用户的密码root切换到普通用户不用输入密码普通用户切换，必须输入密码因为Ubuntu默认提供root密码，不能直接由su切换到root，可以先使用sudo来获取root权限$ sudo su root  #临时切换到root#启用root账户$ sudo password root #根据提示为root输入密码<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>7.其他命令</p><ul><li><p>id  查看用户的id和组信息</p></li><li><p>groups查看用户的组</p></li><li><p>whoami 查看当前的用户是谁 </p><h2 id="七-组管理"><a href="#七-组管理" class="headerlink" title="七.  组管理"></a>七.  组管理</h2></li></ul><pre class="line-numbers language-shell"><code class="language-shell"> #添加一个组 groupadd 组名    1702:x:1001:    组名 密码  gid groupdel  组名  #删除组 groupmod  -n 新组名  旧组名 groups 显示用户的组 #所有的组信息都在/etc/group文件中记录<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>apt install  — 系统安装工具</p><p>pip  install   — python 安装工具</p><p>python  setup.py  build   &amp; python setup.py install    —— python 源码安装方式</p><h3 id="八-命令组合"><a href="#八-命令组合" class="headerlink" title="八.  命令组合"></a>八.  命令组合</h3><p>（1） 查找文件目录下内容信息</p><p>查找一个目录下所有文件中，存在“hello”字符串的文件和行数，并打印行数，红色显示查出的内容</p><pre><code>find  path  -name  文件类型  |  xargs  grep  -rn  -n   "查找内容"eg: find   ./   -name "*.py" | xargs grep -n "hello"  --color -rn</code></pre><p>|管道符，用来隔开两个命令，管道符左边命令的输出会作为管道符右边命令的输入。</p><p>（2）统计当前文件夹下文件的个数，包括子文件夹里的: </p><pre class="line-numbers language-shell"><code class="language-shell">ls -lR | grep “^-” |wc -l<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>wc命令<br>-c 统计字节数。<br>-l 统计行数。<br>-m 统计字符数。这个标志不能与 -c 标志一起使用。<br>-w 统计字数。一个字被定义为由空白、跳格或换行字符分隔的字符串。<br>-L 打印最长行的长度。<br>-help 显示帮助信息<br>–version 显示版本信息</p><pre class="line-numbers language-shell"><code class="language-shell"> （3）修改文件夹权限  sudo mkdir  /opt/project  修改目录以及下面的文件用户权限为zhouguangyou  sudo chown -Rf   zhouguangyou   /opt/project  修改文件目录所属组权限为zhouguangyou  sudo  chgrp  -Rf   zhouguangyou  /opt/project<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）采用vim编辑linux文件技巧</p><p>​    vim创建新文件，编辑内容，保存；vim切屏技巧，定位，拷贝粘贴等技巧</p><p>(5)  linux压缩文件解压方式</p><pre class="line-numbers language-shell"><code class="language-shell">gz文件解压： tar -zxvf openresty-1.11.2.5.tar.gzzip 文件压缩：zip  -r  help.zip  help/zip 文件解压：unzip   help.zip bz2 文件解压：tar xjvf openresty.tar.bz2 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>md5sum命令</strong>采用MD5报文摘要算法（128位）计算和检查文件的校验和。一般来说，安装了Linux后，就会有md5sum这个工具，直接在命令行终端直接运行。</p><pre class="line-numbers language-shell"><code class="language-shell"> md5sum insert.sql<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(6) nc 瑞士军刀</p><p>如何在两台linux服务器之间拷贝数据，并且不知道用户名和密码的情况下 </p><p>scp</p><p>nc 命令：</p><pre class="line-numbers language-shell"><code class="language-shell">（1）服务器端收， 客户端发服务端（192.168.11.11）：nc   -l   11111   >    1.txt    服务端从端口11111接受文件1.txt客户端：nc  192.168.11.11  11111 < 1.txt   客户端往192.168.11.11服务器发送文件1.txt（2）客户端收，服务器端发服务端（192.168.11.11）：nc   -l   11111   <   1.txt    服务端从端口11111发送文件1.txt客户端：nc  192.168.11.11  11111  >   1.txt   客户端往192.168.11.11服务器接受文件1.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="九-附加"><a href="#九-附加" class="headerlink" title="九 附加"></a>九 附加</h4><p> 了解更多关于linux常用命令， 可以参考 <a href="http://man.linuxde.net/" target="_blank" rel="noopener">http://man.linuxde.net/</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux更换阿里源</title>
      <link href="/2020/05/12/Linux%E6%9B%B4%E6%8D%A2%E9%98%BF%E9%87%8C%E6%BA%90/"/>
      <url>/2020/05/12/Linux%E6%9B%B4%E6%8D%A2%E9%98%BF%E9%87%8C%E6%BA%90/</url>
      
        <content type="html"><![CDATA[<p>1.备份系统自带源</p><pre class="line-numbers language-shell"><code class="language-shell">mv /etc/apt/sources.list /etc/apt/sources.list.bak<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2.修改/etc/apt/sources.list文件</p><pre class="line-numbers language-shell"><code class="language-shell">　　vim /etc/apt/sources.list  <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>加入如下内容</p><pre class="line-numbers language-list"><code class="language-list">deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3.更新生效</p><pre class="line-numbers language-shell"><code class="language-shell">　sudo apt-get update<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>DEEPIN添加阿里源</strong></p><pre class="line-numbers language-shell"><code class="language-shell">## Generated by deepin-installerdeb [by-hash=force] http://mirrors.aliyun.com/deepin lion main contrib non-free#deb-src http://mirrors.aliyun.com/deepin lion main contrib non-free<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>损失函数</title>
      <link href="/2020/05/12/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
      <url>/2020/05/12/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<p><strong>TensorFlow和PyTorch很多是相似的，此处以PyTorch为例</strong></p><h5 id="1-L1范数损失-L1Loss"><a href="#1-L1范数损失-L1Loss" class="headerlink" title="1. L1范数损失 L1Loss"></a>1. L1范数损失 L1Loss</h5><p>计算output和target之差的绝对值</p><pre class="line-numbers language-python"><code class="language-python">torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>L1Loss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数：reduction的三个值，none：不适用约简；mean：返回loss的平均值；sum：返回loss的和。默认：mean</p><h5 id="2-均方误差损失MSELoss"><a href="#2-均方误差损失MSELoss" class="headerlink" title="2. 均方误差损失MSELoss"></a>2. 均方误差损失MSELoss</h5><p>计算output和target之差的均方差</p><pre class="line-numbers language-python"><code class="language-python">torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数：reduction的三个值，none：不适用约简；mean：返回loss的平均值；sum：返回loss的和。默认：mean</p><h5 id="3-交叉熵损失-CrossEntropyLoss"><a href="#3-交叉熵损失-CrossEntropyLoss" class="headerlink" title="3.交叉熵损失 CrossEntropyLoss"></a>3.交叉熵损失 CrossEntropyLoss</h5><p>当训练有 C 个类别的分类问题时很有效. 可选参数 weight 必须是一个1维 Tensor, 权重将被分配给各个类别. 对于不平衡的训练集非常有效。<br>在多分类任务中，经常采用 softmax 激活函数+交叉熵损失函数，因为交叉熵描述了两个概率分布的差异，然而神经网络输出的是向量，并不是概率分布的形式。所以需要 softmax激活函数将一个向量进行“归一化”成概率分布的形式，再采用交叉熵损失函数计算 loss。<br><img src="https://img-blog.csdnimg.cn/20190905101057854.png" alt="在这里插入图片描述"></p><pre class="line-numbers language-shell"><code class="language-shell">torch.nn.CrossEntropyLoss(weight=None,ignore_index=-100,reduction='mean')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数：weight (Tensor, optional) – 自定义的每个类别的权重. 必须是一个长度为 C 的 Tensor<br>ignore_index (int, optional) – 设置一个目标值, 该目标值会被忽略, 从而不会影响到 输入的梯度。<br>reduction-三个值，none: 不使用约简；mean:返回loss和的平均值；sum:返回loss的和。默认：mean。</p><h5 id="KL散度损失-KLDivLoss"><a href="#KL散度损失-KLDivLoss" class="headerlink" title="KL散度损失 KLDivLoss"></a>KL散度损失 KLDivLoss</h5><p>计算input与target之间的KL散度。KL散度可用于衡量不同的连续分布之间的距离，在连续的输出分布的空间上（离散采样）上直接进行回归时很有效。</p><pre class="line-numbers language-sql"><code class="language-sql">torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>KLDivLoss<span class="token punctuation">(</span>reduciton<span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数：reduction-三个值，none: 不使用约简；mean:返回loss和的平均值；sum:返回loss的和。默认：mean。</p><h5 id="5-二进制的交叉熵损失BCELoss"><a href="#5-二进制的交叉熵损失BCELoss" class="headerlink" title="5.二进制的交叉熵损失BCELoss"></a>5.二进制的交叉熵损失BCELoss</h5><p>二分类任务时的交叉熵计算函数。用于测量重构的误差，例如自动编码机，注意目标的值t[i]的范围为0到1之间</p><pre class="line-numbers language-shell"><code class="language-shell">torch.nn.BCELoss(weight=None, reduction='mean')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数：weight (Tensor, optional) – 自定义的每个 batch 元素的 loss 的权重. 必须是一个长度为 “nbatch” 的 的 Tensor</p><h5 id="6-BCEWithLogitsLoss"><a href="#6-BCEWithLogitsLoss" class="headerlink" title="6.BCEWithLogitsLoss"></a>6.BCEWithLogitsLoss</h5><p>BCEWithLogitsLoss损失函数把Sigmoid层集成到了BCELoss类中，该版比用一个更简单的Sigmoid层和BCELoss在数值上更稳定，因为把这个两个操作合并为一个层之后，可以利用log-sum-exp的技巧来实现数值稳定</p><pre class="line-numbers language-shell"><code class="language-shell">torch.nn.BCEWithLogitsLoss(weight=None, reduction='mean', pos_weight=None)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数：weight (Tensor, optional) – 自定义的每个 batch 元素的 loss 的权重. 必须是一个长度 为 “nbatch” 的 Tensor</p><h5 id="7-MarginRankingLoss"><a href="#7-MarginRankingLoss" class="headerlink" title="7. MarginRankingLoss"></a>7. MarginRankingLoss</h5><pre class="line-numbers language-shell"><code class="language-shell">torch.nn.MarginRankingLoss(margin=0.0, reduction='mean')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对于mini-batch（小批量）中每个实例的损失函数如下：<br><img src="https://img-blog.csdnimg.cn/20190905141351423.png" alt="在这里插入图片描述"><br>参数：margin：默认值0</p><h5 id="8-HingeEmbeddingLoss"><a href="#8-HingeEmbeddingLoss" class="headerlink" title="8.HingeEmbeddingLoss"></a>8.HingeEmbeddingLoss</h5><pre class="line-numbers language-shell"><code class="language-shell">torch.nn.HingeEmbeddingLoss(margin=1.0, reduction='mean')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对于mini-batch中每个实例的损失函数如下：<br><img src="https://img-blog.csdnimg.cn/20190905141557369.png" alt="在这里插入图片描述"><br>参数：margin：默认值1</p><h5 id="9-多标签分类损失-MultiLabelMarginLoss"><a href="#9-多标签分类损失-MultiLabelMarginLoss" class="headerlink" title="9. 多标签分类损失 MultiLabelMarginLoss"></a>9. 多标签分类损失 MultiLabelMarginLoss</h5><pre class="line-numbers language-shell"><code class="language-shell">torch.nn.MultiLabelMarginLoss(reduction='mean')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对于mini-batch中每个样本按如下公式计算损失：<br><img src="https://img-blog.csdnimg.cn/20190905142252287.png" alt="在这里插入图片描述"></p><h5 id="10-平滑版L1损失-SmoothL1Loss"><a href="#10-平滑版L1损失-SmoothL1Loss" class="headerlink" title="10.平滑版L1损失 SmoothL1Loss"></a>10.平滑版L1损失 SmoothL1Loss</h5><p>也被成为Huber损失函数</p><pre class="line-numbers language-shell"><code class="language-shell">torch.nn.SmoothL1Loss(reduction='mean')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/20190905142410652.png" alt="在这里插入图片描述"><br>其中<br><img src="https://img-blog.csdnimg.cn/20190905142427758.png" alt="在这里插入图片描述"></p><h5 id="11-2分类的logsitic损失SoftMarginLoss"><a href="#11-2分类的logsitic损失SoftMarginLoss" class="headerlink" title="11.2分类的logsitic损失SoftMarginLoss"></a>11.2分类的logsitic损失SoftMarginLoss</h5><pre class="line-numbers language-shell"><code class="language-shell">torch.nn.SoftMarginLoss(reduction='mean')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/20190905142541778.png" alt="在这里插入图片描述"></p><h5 id="12-多标签one-versus-all损失MultiLabelSoftMarginLoss"><a href="#12-多标签one-versus-all损失MultiLabelSoftMarginLoss" class="headerlink" title="12.多标签one-versus-all损失MultiLabelSoftMarginLoss"></a>12.多标签one-versus-all损失MultiLabelSoftMarginLoss</h5><pre class="line-numbers language-shell"><code class="language-shell">torch.mm.MultiLabelSoftMarginLoss(weight=None, reduction='mean')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/2019090514345686.png" alt=""></p><h5 id="13-cosine-损失-CosineEmbeddingLoss"><a href="#13-cosine-损失-CosineEmbeddingLoss" class="headerlink" title="13. cosine 损失 CosineEmbeddingLoss"></a>13. cosine 损失 CosineEmbeddingLoss</h5><pre class="line-numbers language-shell"><code class="language-shell">torch.nn.CosineEmbeddingLoss(margin=0.0, reduction='mean')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/20190905143632571.png" alt="在这里插入图片描述"><br>参数：margin：默认值0</p><h5 id="14-多分类的hinge损失-MultiMarginLoss"><a href="#14-多分类的hinge损失-MultiMarginLoss" class="headerlink" title="14. 多分类的hinge损失 MultiMarginLoss"></a>14. 多分类的hinge损失 MultiMarginLoss</h5><pre class="line-numbers language-python"><code class="language-python">torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MultiMarginLoss<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> margin<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> weight<span class="token operator">=</span>None<span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/20190905145119801.png" alt="在这里插入图片描述"><br>参数：p=1或者2 默认值1； margin：默认值1</p><h5 id="15-三元损失-TripletMarginLoss"><a href="#15-三元损失-TripletMarginLoss" class="headerlink" title="15. 三元损失 TripletMarginLoss"></a>15. 三元损失 TripletMarginLoss</h5><pre class="line-numbers language-shell"><code class="language-shell">torch.nn.TripletMarginLoss(margin=1.0, p=2.0, eps=1e-06, swap=False, reduction='mean')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/20190905145326932.png" alt="在这里插入图片描述"><br>其中：<br><img src="https://img-blog.csdnimg.cn/2019090514534185.png" alt="在这里插入图片描述"></p><h5 id="16-连接时序分类损失-CTCLoss"><a href="#16-连接时序分类损失-CTCLoss" class="headerlink" title="16.连接时序分类损失 CTCLoss"></a>16.连接时序分类损失 CTCLoss</h5><p>CTC连接时序分类损失，可以对没有对齐的数据进行自动对齐，主要用在没有事先对齐的序列化数据训练上。比如语音识别、ocr识别等</p><pre class="line-numbers language-shell"><code class="language-shell">torch.nn.CTCLoss(blank=0, reduction='mean')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数：reduction-三个值，none: 不使用约简；mean:返回loss和的平均值；sum:返回loss的和。默认：mean。</p><h5 id="17-负对数似然损失NLLLoss"><a href="#17-负对数似然损失NLLLoss" class="headerlink" title="17.负对数似然损失NLLLoss"></a>17.负对数似然损失NLLLoss</h5><p>负对数似然损失，用于训练C个类别的分类问题</p><pre class="line-numbers language-shell"><code class="language-shell">torch.nn.NLLLoss(weight=None, ignore_index=-100, reduction='mean')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数：weight (Tensor, optional) – 自定义的每个类别的权重. 必须是一个长度为 C 的 Tensor<br>ignore_index (int, optional) – 设置一个目标值, 该目标值会被忽略, 从而不会影响到 输入的梯度.</p><h5 id="18-NLLLoss2d"><a href="#18-NLLLoss2d" class="headerlink" title="18.NLLLoss2d"></a>18.NLLLoss2d</h5><p>对于图片输入的负对数似然损失，计算每个像素的负对数似然损失</p><pre class="line-numbers language-shell"><code class="language-shell">torch.nn.NLLLoss2d(weight=None, ignore_index=-100, reduction='mean')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数：weight (Tensor, optional) – 自定义的每个类别的权重. 必须是一个长度为 C 的 Tensor<br>reduction-三个值，none: 不使用约简；mean:返回loss和的平均值；sum:返回loss的和。默认：mean。</p><h5 id="19-PoissonNLLLoss"><a href="#19-PoissonNLLLoss" class="headerlink" title="19.PoissonNLLLoss"></a>19.PoissonNLLLoss</h5><p>目标值为泊松分布的负对数似然损失</p><pre class="line-numbers language-shell"><code class="language-shell">torch.nn.PoissonNLLLoss(log_input=True, eps=1e-08, reduction='mean')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数：log_input (bool, optional) – 如果设置为 True , loss 将会按照公 式 exp(input) - target * input 来计算, 如果设置为 False , loss 将会按照 input - target * log(input+eps) 计算.<br>full (bool, optional) – 是否计算全部的 loss, i. e. 加上 Stirling 近似项 target * log(target) - target + 0.5 * log(2 * pi * target).<br>eps (float, optional) – 默认值: 1e-8</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Keras </category>
          
          <category> Pytorch </category>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Keras:cifar10图像分类</title>
      <link href="/2020/05/12/Keras-cifar10%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
      <url>/2020/05/12/Keras-cifar10%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> cifar10<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npnp<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token punctuation">(</span>x_img_train<span class="token punctuation">,</span> y_label_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_img_test<span class="token punctuation">,</span> y_label_test<span class="token punctuation">)</span> <span class="token operator">=</span> cifar10<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">len<span class="token punctuation">(</span>x_img_train<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>50000</code></pre><pre class="line-numbers language-python"><code class="language-python">len<span class="token punctuation">(</span>x_img_test<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>10000</code></pre><pre class="line-numbers language-python"><code class="language-python">x_img_train<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>(50000, 32, 32, 3)</code></pre><pre class="line-numbers language-python"><code class="language-python">x_img_test<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>array([[[158, 112,  49],        [159, 111,  47],        [165, 116,  51],        ...,        [137,  95,  36],        [126,  91,  36],        [116,  85,  33]],       [[152, 112,  51],        [151, 110,  40],        [159, 114,  45],        ...,        [136,  95,  31],        [125,  91,  32],        [119,  88,  34]],       [[151, 110,  47],        [151, 109,  33],        [158, 111,  36],        ...,        [139,  98,  34],        [130,  95,  34],        [120,  89,  33]],       ...,       [[ 68, 124, 177],        [ 42, 100, 148],        [ 31,  88, 137],        ...,        [ 38,  97, 146],        [ 13,  64, 108],        [ 40,  85, 127]],       [[ 61, 116, 168],        [ 49, 102, 148],        [ 35,  85, 132],        ...,        [ 26,  82, 130],        [ 29,  82, 126],        [ 20,  64, 107]],       [[ 54, 107, 160],        [ 56, 105, 149],        [ 45,  89, 132],        ...,        [ 24,  77, 124],        [ 34,  84, 129],        [ 21,  67, 110]]], dtype=uint8)</code></pre><pre class="line-numbers language-python"><code class="language-python">label_dict <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">'airplane'</span><span class="token punctuation">,</span>    <span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">'automobile'</span><span class="token punctuation">,</span>    <span class="token number">2</span><span class="token punctuation">:</span> <span class="token string">'bird'</span><span class="token punctuation">,</span>    <span class="token number">3</span><span class="token punctuation">:</span> <span class="token string">'cat'</span><span class="token punctuation">,</span>    <span class="token number">4</span><span class="token punctuation">:</span> <span class="token string">'deer'</span><span class="token punctuation">,</span>    <span class="token number">5</span><span class="token punctuation">:</span> <span class="token string">'dog'</span><span class="token punctuation">,</span>    <span class="token number">6</span><span class="token punctuation">:</span> <span class="token string">'frog'</span><span class="token punctuation">,</span>    <span class="token number">7</span><span class="token punctuation">:</span> <span class="token string">'horse'</span><span class="token punctuation">,</span>    <span class="token number">8</span><span class="token punctuation">:</span> <span class="token string">'ship'</span><span class="token punctuation">,</span>    <span class="token number">9</span><span class="token punctuation">:</span> <span class="token string">'truck'</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">def</span> <span class="token function">show_images_labels_prediction</span><span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> prediction<span class="token punctuation">,</span> idx<span class="token punctuation">,</span> num<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>gcf<span class="token punctuation">(</span><span class="token punctuation">)</span>    fig<span class="token punctuation">.</span>set_size_inches<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> num <span class="token operator">></span> <span class="token number">25</span><span class="token punctuation">:</span> num <span class="token operator">=</span> <span class="token number">25</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num<span class="token punctuation">)</span><span class="token punctuation">:</span>        ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>        ax<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>images<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'binary'</span><span class="token punctuation">)</span>        title <span class="token operator">=</span> str<span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'label_dict[labels[i][0]]'</span>        <span class="token keyword">if</span> len<span class="token punctuation">(</span>prediction<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>            title <span class="token operator">+=</span> <span class="token string">',label_dict[prediction[i]]'</span>        ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span>title<span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>        ax<span class="token punctuation">.</span>set_xticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        ax<span class="token punctuation">.</span>set_yticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        idx <span class="token operator">+=</span> <span class="token number">1</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">show_images_labels_prediction<span class="token punctuation">(</span>x_img_train<span class="token punctuation">,</span> y_label_train<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/20190909092353563.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd4dzE4MDM=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># images 预处理</span>x_img_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>array([59, 62, 63], dtype=uint8)</code></pre><pre class="line-numbers language-python"><code class="language-python">x_img_train_normalize <span class="token operator">=</span> x_img_train<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span>x_img_test_normalize <span class="token operator">=</span> x_img_test<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">x_img_train_normalize<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>array([0.23137255, 0.24313726, 0.24705882], dtype=float32)</code></pre><pre class="line-numbers language-python"><code class="language-python">y_label_train<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>(50000, 1)</code></pre><pre class="line-numbers language-python"><code class="language-python">y_label_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>array([[6],       [9],       [9],       [4],       [1]], dtype=uint8)</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>utils <span class="token keyword">import</span> to_categoricaly_label_train_Onehot <span class="token operator">=</span> np_utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_label_train<span class="token punctuation">)</span>y_label_test_Onehot <span class="token operator">=</span> np_utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_label_test<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">y_label_train_Onehot<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>(50000, 10)</code></pre><pre class="line-numbers language-python"><code class="language-python">y_label_train_Onehot<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dropout<span class="token punctuation">,</span> Activation<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Dense<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Conv2D<span class="token punctuation">,</span> MaxPool2D<span class="token punctuation">,</span> ZeroPadding2D<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>    Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>           kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span>           padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>    Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span>rate<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       _________________________________________________________________dropout_9 (Dropout)          (None, 32, 32, 32)        0         _________________________________________________________________max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         _________________________________________________________________conv2d_6 (Conv2D)            (None, 16, 16, 64)        18496     _________________________________________________________________dropout_10 (Dropout)         (None, 16, 16, 64)        0         _________________________________________________________________max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         _________________________________________________________________flatten_3 (Flatten)          (None, 4096)              0         _________________________________________________________________dropout_11 (Dropout)         (None, 4096)              0         _________________________________________________________________dense_5 (Dense)              (None, 1024)              4195328   _________________________________________________________________dropout_12 (Dropout)         (None, 1024)              0         _________________________________________________________________dense_6 (Dense)              (None, 10)                10250     =================================================================Total params: 4,224,970Trainable params: 4,224,970Non-trainable params: 0_________________________________________________________________</code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span>              optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">train_history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_img_train_normalize<span class="token punctuation">,</span>                          y_label_train_Onehot<span class="token punctuation">,</span>                          validation_split<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>                          epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>                          batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span>                          verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>W0815 14:02:18.266812  3476 deprecation.py:323] From E:\Anaconda3\envs\ml\lib\site-packages\tensorflow\python\ops\math_grad.py:1250: add_dispatch_support.&lt;locals&gt;.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.Instructions for updating:Use tf.where in 2.0, which has the same broadcast rule as np.whereTrain on 40000 samples, validate on 10000 samplesEpoch 1/1040000/40000 [==============================] - 80s 2ms/step - loss: 1.4861 - acc: 0.4651 - val_loss: 1.2726 - val_acc: 0.5727Epoch 2/1040000/40000 [==============================] - 78s 2ms/step - loss: 1.1343 - acc: 0.5957 - val_loss: 1.1271 - val_acc: 0.6321Epoch 3/1040000/40000 [==============================] - 78s 2ms/step - loss: 0.9794 - acc: 0.6547 - val_loss: 1.0180 - val_acc: 0.6591Epoch 4/1040000/40000 [==============================] - 79s 2ms/step - loss: 0.8696 - acc: 0.6945 - val_loss: 0.9446 - val_acc: 0.6983Epoch 5/1040000/40000 [==============================] - 79s 2ms/step - loss: 0.7815 - acc: 0.7254 - val_loss: 0.8846 - val_acc: 0.6979Epoch 6/1040000/40000 [==============================] - 79s 2ms/step - loss: 0.6987 - acc: 0.7541 - val_loss: 0.8430 - val_acc: 0.7234Epoch 7/1040000/40000 [==============================] - 80s 2ms/step - loss: 0.6221 - acc: 0.7812 - val_loss: 0.8249 - val_acc: 0.7241Epoch 8/1040000/40000 [==============================] - 78s 2ms/step - loss: 0.5540 - acc: 0.8058 - val_loss: 0.7874 - val_acc: 0.7359Epoch 9/1040000/40000 [==============================] - 79s 2ms/step - loss: 0.4923 - acc: 0.8278 - val_loss: 0.7541 - val_acc: 0.7458Epoch 10/1040000/40000 [==============================] - 78s 2ms/step - loss: 0.4360 - acc: 0.8477 - val_loss: 0.7844 - val_acc: 0.7289</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">show_train_hitory</span><span class="token punctuation">(</span>train<span class="token punctuation">,</span> validation<span class="token punctuation">)</span><span class="token punctuation">:</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_history<span class="token punctuation">.</span>history<span class="token punctuation">[</span>train<span class="token punctuation">]</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_history<span class="token punctuation">.</span>history<span class="token punctuation">[</span>validation<span class="token punctuation">]</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Train_History'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'validation'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">show_train_hitory<span class="token punctuation">(</span><span class="token string">'acc'</span><span class="token punctuation">,</span> <span class="token string">'val_acc'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/20190909092249168.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd4dzE4MDM=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><pre class="line-numbers language-python"><code class="language-python">show_train_hitory<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">,</span> <span class="token string">'val_loss'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/20190909092303755.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd4dzE4MDM=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><pre class="line-numbers language-python"><code class="language-python">scores <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_img_test_normalize<span class="token punctuation">,</span> y_label_test_Onehot<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">scores<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>0.7243</code></pre><pre class="line-numbers language-python"><code class="language-python">prediction <span class="token operator">=</span> model<span class="token punctuation">.</span>predict_classes<span class="token punctuation">(</span>x_img_test_normalize<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">prediction<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>array([3, 8, 8, 0, 6, 6, 1, 6, 3, 1], dtype=int64)</code></pre><pre class="line-numbers language-python"><code class="language-python">show_images_labels_prediction<span class="token punctuation">(</span>x_img_test<span class="token punctuation">,</span> y_label_test<span class="token punctuation">,</span> prediction<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/20190909092318639.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd4dzE4MDM=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><pre class="line-numbers language-python"><code class="language-python">predicted_Probability <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_img_test_normalize<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">show_Predicted_Probability</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> prediction<span class="token punctuation">,</span> x_img<span class="token punctuation">,</span> Predicted_Probability<span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'label:'</span><span class="token punctuation">,</span> label_dict<span class="token punctuation">[</span>y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'predict'</span><span class="token punctuation">,</span> label_dict<span class="token punctuation">[</span>prediction<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>np<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x_img_test<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>label_dict<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">'Probability: % 1.9f'</span> <span class="token operator">%</span>              <span class="token punctuation">(</span>Predicted_Probability<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">show_Predicted_Probability<span class="token punctuation">(</span>y_label_test<span class="token punctuation">,</span> prediction<span class="token punctuation">,</span> x_img_test<span class="token punctuation">,</span>                           predicted_Probability<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>label: cat predict cat</code></pre><p><img src="https://img-blog.csdnimg.cn/20190909092328420.png" alt="在这里插入图片描述"></p><pre><code>airplaneProbability:  0.006167101automobileProbability:  0.001565425birdProbability:  0.044187795catProbability:  0.715321243deerProbability:  0.014729370dogProbability:  0.098865360frogProbability:  0.068471827horseProbability:  0.006407721shipProbability:  0.043457642truckProbability:  0.000826489</code></pre><pre class="line-numbers language-python"><code class="language-python">show_Predicted_Probability<span class="token punctuation">(</span>y_label_test<span class="token punctuation">,</span> prediction<span class="token punctuation">,</span> x_img_test<span class="token punctuation">,</span>                           predicted_Probability<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>label: airplane predict airplane</code></pre><p><img src="https://img-blog.csdnimg.cn/20190909092337127.png" alt="在这里插入图片描述"></p><pre><code>airplaneProbability:  0.840534329automobileProbability:  0.001597346birdProbability:  0.083605878catProbability:  0.000940685deerProbability:  0.008222473dogProbability:  0.000034206frogProbability:  0.000021479horseProbability:  0.000218752shipProbability:  0.064438224truckProbability:  0.000386720</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdpd<span class="token punctuation">.</span>crosstab<span class="token punctuation">(</span>y_label_test<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            prediction<span class="token punctuation">,</span>            rownames<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            colnames<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'predict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>E:\Anaconda3\envs\ml\lib\importlib\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject  return f(*args, **kwds)</code></pre><div><style scoped="">    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th {    vertical-align: top;}.dataframe thead th {    text-align: right;}</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th>predict</th>      <th>0</th>      <th>1</th>      <th>2</th>      <th>3</th>      <th>4</th>      <th>5</th>      <th>6</th>      <th>7</th>      <th>8</th>      <th>9</th>    </tr>    <tr>      <th>label</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>791</td>      <td>6</td>      <td>85</td>      <td>8</td>      <td>28</td>      <td>3</td>      <td>15</td>      <td>6</td>      <td>46</td>      <td>12</td>    </tr>    <tr>      <th>1</th>      <td>35</td>      <td>752</td>      <td>29</td>      <td>11</td>      <td>14</td>      <td>4</td>      <td>20</td>      <td>2</td>      <td>58</td>      <td>75</td>    </tr>    <tr>      <th>2</th>      <td>49</td>      <td>2</td>      <td>696</td>      <td>25</td>      <td>101</td>      <td>37</td>      <td>65</td>      <td>16</td>      <td>8</td>      <td>1</td>    </tr>    <tr>      <th>3</th>      <td>23</td>      <td>5</td>      <td>133</td>      <td>427</td>      <td>91</td>      <td>159</td>      <td>122</td>      <td>26</td>      <td>8</td>      <td>6</td>    </tr>    <tr>      <th>4</th>      <td>16</td>      <td>0</td>      <td>97</td>      <td>21</td>      <td>759</td>      <td>23</td>      <td>54</td>      <td>22</td>      <td>8</td>      <td>0</td>    </tr>    <tr>      <th>5</th>      <td>9</td>      <td>4</td>      <td>98</td>      <td>109</td>      <td>63</td>      <td>627</td>      <td>49</td>      <td>33</td>      <td>5</td>      <td>3</td>    </tr>    <tr>      <th>6</th>      <td>3</td>      <td>2</td>      <td>44</td>      <td>20</td>      <td>30</td>      <td>15</td>      <td>881</td>      <td>0</td>      <td>5</td>      <td>0</td>    </tr>    <tr>      <th>7</th>      <td>13</td>      <td>1</td>      <td>63</td>      <td>19</td>      <td>90</td>      <td>73</td>      <td>9</td>      <td>725</td>      <td>6</td>      <td>1</td>    </tr>    <tr>      <th>8</th>      <td>59</td>      <td>16</td>      <td>32</td>      <td>7</td>      <td>15</td>      <td>7</td>      <td>11</td>      <td>2</td>      <td>837</td>      <td>14</td>    </tr>    <tr>      <th>9</th>      <td>63</td>      <td>64</td>      <td>27</td>      <td>11</td>      <td>7</td>      <td>13</td>      <td>17</td>      <td>19</td>      <td>31</td>      <td>748</td>    </tr>  </tbody></table></div><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Keras </category>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Keras:多层感知器IMDb情感分类</title>
      <link href="/2020/05/12/Keras-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E5%99%A8IMDb%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/"/>
      <url>/2020/05/12/Keras-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E5%99%A8IMDb%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 下载</span><span class="token keyword">import</span> urllib<span class="token punctuation">.</span>request<span class="token keyword">import</span> os<span class="token keyword">import</span> tarfileurl <span class="token operator">=</span> <span class="token string">'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'</span>filepath <span class="token operator">=</span> <span class="token string">'./data/aclImdb_v1.tar.gz'</span><span class="token keyword">if</span> <span class="token operator">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>filepath<span class="token punctuation">)</span><span class="token punctuation">:</span>    result <span class="token operator">=</span> urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>urlretrieve<span class="token punctuation">(</span>url<span class="token punctuation">,</span> filepath<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'download:'</span><span class="token punctuation">,</span> result<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 解压</span><span class="token keyword">if</span> <span class="token operator">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span><span class="token string">'./data/aclImdb'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    tfile <span class="token operator">=</span> tarfile<span class="token punctuation">.</span>open<span class="token punctuation">(</span><span class="token string">'./data/aclImdb_v1.tar.gz'</span><span class="token punctuation">,</span> <span class="token string">'r:gz'</span><span class="token punctuation">)</span>    result <span class="token operator">=</span> tfile<span class="token punctuation">.</span>extractall<span class="token punctuation">(</span><span class="token string">'./data/'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> sequence<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>text <span class="token keyword">import</span> Tokenizer<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> re<span class="token keyword">def</span> <span class="token function">rm_tags</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    re_tag <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">'&lt;[^>]+>'</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> re_tag<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">def</span> <span class="token function">read_files</span><span class="token punctuation">(</span>filetype<span class="token punctuation">)</span><span class="token punctuation">:</span>    path <span class="token operator">=</span> <span class="token string">'./data/aclImdb/'</span>    file_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    positive_path <span class="token operator">=</span> path <span class="token operator">+</span> filetype <span class="token operator">+</span> <span class="token string">'/pos/'</span>    <span class="token keyword">for</span> f <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>positive_path<span class="token punctuation">)</span><span class="token punctuation">:</span>        file_list <span class="token operator">+=</span> <span class="token punctuation">[</span>positive_path <span class="token operator">+</span> f<span class="token punctuation">]</span>    negative_path <span class="token operator">=</span> path <span class="token operator">+</span> filetype <span class="token operator">+</span> <span class="token string">'/neg/'</span>    <span class="token keyword">for</span> f <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>negative_path<span class="token punctuation">)</span><span class="token punctuation">:</span>        file_list <span class="token operator">+=</span> <span class="token punctuation">[</span>negative_path <span class="token operator">+</span> f<span class="token punctuation">]</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'read'</span><span class="token punctuation">,</span> filetype<span class="token punctuation">,</span> <span class="token string">'files:'</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>file_list<span class="token punctuation">)</span><span class="token punctuation">)</span>    all_labels <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">12500</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">12500</span><span class="token punctuation">)</span>    all_texts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> fi <span class="token keyword">in</span> file_list<span class="token punctuation">:</span>        <span class="token keyword">with</span> open<span class="token punctuation">(</span>fi<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> file_input<span class="token punctuation">:</span>            all_texts <span class="token operator">+=</span> <span class="token punctuation">[</span>rm_tags<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>file_input<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> all_labels<span class="token punctuation">,</span> all_texts<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">y_train<span class="token punctuation">,</span> train_text <span class="token operator">=</span> read_files<span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>read train files: 25000</code></pre><pre class="line-numbers language-python"><code class="language-python">y_test<span class="token punctuation">,</span> test_text <span class="token operator">=</span> read_files<span class="token punctuation">(</span><span class="token string">'test'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>read test files: 25000</code></pre><pre class="line-numbers language-python"><code class="language-python">train_text<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as "Teachers". My 35 years in the teaching profession lead me to believe that Bromwell High\'s satire is much closer to reality than is "Teachers". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\'t!'</code></pre><pre class="line-numbers language-python"><code class="language-python">y_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>1</code></pre><pre class="line-numbers language-python"><code class="language-python">train_text<span class="token punctuation">[</span><span class="token number">12501</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>"Airport '77 starts as a brand new luxury 747 plane is loaded up with valuable paintings &amp; such belonging to rich businessman Philip Stevens (James Stewart) who is flying them &amp; a bunch of VIP's to his estate in preparation of it being opened to the public as a museum, also on board is Stevens daughter Julie (Kathleen Quinlan) &amp; her son. The luxury jetliner takes off as planned but mid-air the plane is hi-jacked by the co-pilot Chambers (Robert Foxworth) &amp; his two accomplice's Banker (Monte Markham) &amp; Wilson (Michael Pataki) who knock the passengers &amp; crew out with sleeping gas, they plan to steal the valuable cargo &amp; land on a disused plane strip on an isolated island but while making his descent Chambers almost hits an oil rig in the Ocean &amp; loses control of the plane sending it crashing into the sea where it sinks to the bottom right bang in the middle of the Bermuda Triangle. With air in short supply, water leaking in &amp; having flown over 200 miles off course the problems mount for the survivor's as they await help with time fast running out...Also known under the slightly different tile Airport 1977 this second sequel to the smash-hit disaster thriller Airport (1970) was directed by Jerry Jameson &amp; while once again like it's predecessors I can't say Airport '77 is any sort of forgotten classic it is entertaining although not necessarily for the right reasons. Out of the three Airport films I have seen so far I actually liked this one the best, just. It has my favourite plot of the three with a nice mid-air hi-jacking &amp; then the crashing (didn't he see the oil rig?) &amp; sinking of the 747 (maybe the makers were trying to cross the original Airport with another popular disaster flick of the period The Poseidon Adventure (1972)) &amp; submerged is where it stays until the end with a stark dilemma facing those trapped inside, either suffocate when the air runs out or drown as the 747 floods or if any of the doors are opened &amp; it's a decent idea that could have made for a great little disaster flick but bad unsympathetic character's, dull dialogue, lethargic set-pieces &amp; a real lack of danger or suspense or tension means this is a missed opportunity. While the rather sluggish plot keeps one entertained for 108 odd minutes not that much happens after the plane sinks &amp; there's not as much urgency as I thought there should have been. Even when the Navy become involved things don't pick up that much with a few shots of huge ships &amp; helicopters flying about but there's just something lacking here. George Kennedy as the jinxed airline worker Joe Patroni is back but only gets a couple of scenes &amp; barely even says anything preferring to just look worried in the background.The home video &amp; theatrical version of Airport '77 run 108 minutes while the US TV versions add an extra hour of footage including a new opening credits sequence, many more scenes with George Kennedy as Patroni, flashbacks to flesh out character's, longer rescue scenes &amp; the discovery or another couple of dead bodies including the navigator. While I would like to see this extra footage I am not sure I could sit through a near three hour cut of Airport '77. As expected the film has dated badly with horrible fashions &amp; interior design choices, I will say no more other than the toy plane model effects aren't great either. Along with the other two Airport sequels this takes pride of place in the Razzie Award's Hall of Shame although I can think of lots of worse films than this so I reckon that's a little harsh. The action scenes are a little dull unfortunately, the pace is slow &amp; not much excitement or tension is generated which is a shame as I reckon this could have been a pretty good film if made properly.The production values are alright if nothing spectacular. The acting isn't great, two time Oscar winner Jack Lemmon has said since it was a mistake to star in this, one time Oscar winner James Stewart looks old &amp; frail, also one time Oscar winner Lee Grant looks drunk while Sir Christopher Lee is given little to do &amp; there are plenty of other familiar faces to look out for too.Airport '77 is the most disaster orientated of the three Airport films so far &amp; I liked the ideas behind it even if they were a bit silly, the production &amp; bland direction doesn't help though &amp; a film about a sunken plane just shouldn't be this boring or lethargic. Followed by The Concorde ... Airport '79 (1979)."</code></pre><pre class="line-numbers language-python"><code class="language-python">token <span class="token operator">=</span> Tokenizer<span class="token punctuation">(</span>num_words<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">)</span>token<span class="token punctuation">.</span>fit_on_texts<span class="token punctuation">(</span>train_text<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">x_train_seq <span class="token operator">=</span> token<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span>train_text<span class="token punctuation">)</span>x_test_seq <span class="token operator">=</span> token<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span>test_text<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">x_train <span class="token operator">=</span> sequence<span class="token punctuation">.</span>pad_sequences<span class="token punctuation">(</span>x_train_seq<span class="token punctuation">,</span> maxlen<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>x_test <span class="token operator">=</span> sequence<span class="token punctuation">.</span>pad_sequences<span class="token punctuation">(</span>x_test_seq<span class="token punctuation">,</span> maxlen<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> imdb<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> sequence<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>text <span class="token keyword">import</span> Tokenizer<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">y_train<span class="token punctuation">,</span> train_text <span class="token operator">=</span> read_files<span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>read train files: 25000</code></pre><pre class="line-numbers language-python"><code class="language-python">y_test<span class="token punctuation">,</span> train_text <span class="token operator">=</span>read_files<span class="token punctuation">(</span><span class="token string">'test'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>read test files: 25000</code></pre><pre class="line-numbers language-python"><code class="language-python">token <span class="token operator">=</span> Tokenizer<span class="token punctuation">(</span>num_words<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">)</span>token<span class="token punctuation">.</span>fit_on_texts<span class="token punctuation">(</span>train_text<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">x_train_seq <span class="token operator">=</span> token<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span>train_text<span class="token punctuation">)</span>x_test_seq <span class="token operator">=</span> token<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span>test_text<span class="token punctuation">)</span>x_train <span class="token operator">=</span> sequence<span class="token punctuation">.</span>pad_sequences<span class="token punctuation">(</span>x_train_seq<span class="token punctuation">,</span> maxlen<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>x_test <span class="token operator">=</span> sequence<span class="token punctuation">.</span>pad_sequences<span class="token punctuation">(</span>x_test_seq<span class="token punctuation">,</span> maxlen<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>core <span class="token keyword">import</span> Dense<span class="token punctuation">,</span> Dropout<span class="token punctuation">,</span> Activation<span class="token punctuation">,</span> Flatten<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> Embedding<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Embedding<span class="token punctuation">(</span>output_dim<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> input_dim<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">,</span> input_length<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>               activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.35</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>W0819 14:48:52.688199  9352 deprecation_wrapper.py:119] From E:\Anaconda3\envs\ml\lib\site-packages\keras\backend\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.W0819 14:48:52.700166  9352 deprecation_wrapper.py:119] From E:\Anaconda3\envs\ml\lib\site-packages\keras\backend\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.W0819 14:48:52.705153  9352 deprecation_wrapper.py:119] From E:\Anaconda3\envs\ml\lib\site-packages\keras\backend\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.W0819 14:48:52.720114  9352 deprecation_wrapper.py:119] From E:\Anaconda3\envs\ml\lib\site-packages\keras\backend\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.W0819 14:48:52.730087  9352 deprecation.py:506] From E:\Anaconda3\envs\ml\lib\site-packages\keras\backend\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.Instructions for updating:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.</code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================embedding_1 (Embedding)      (None, 100, 32)           64000     _________________________________________________________________dropout_1 (Dropout)          (None, 100, 32)           0         _________________________________________________________________flatten_1 (Flatten)          (None, 3200)              0         _________________________________________________________________dense_1 (Dense)              (None, 256)               819456    _________________________________________________________________dropout_2 (Dropout)          (None, 256)               0         _________________________________________________________________dense_2 (Dense)              (None, 1)                 257       =================================================================Total params: 883,713Trainable params: 883,713Non-trainable params: 0_________________________________________________________________</code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span>             optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>             metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>W0819 14:48:52.872310  9352 deprecation_wrapper.py:119] From E:\Anaconda3\envs\ml\lib\site-packages\keras\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.W0819 14:48:52.896245  9352 deprecation_wrapper.py:119] From E:\Anaconda3\envs\ml\lib\site-packages\keras\backend\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.W0819 14:48:52.902229  9352 deprecation.py:323] From E:\Anaconda3\envs\ml\lib\site-packages\tensorflow\python\ops\nn_impl.py:180: add_dispatch_support.&lt;locals&gt;.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.Instructions for updating:Use tf.where in 2.0, which has the same broadcast rule as np.where</code></pre><pre class="line-numbers language-python"><code class="language-python">train_history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>                          y_train<span class="token punctuation">,</span>                          batch_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>                          epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>                          verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>                          validation_split<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Train on 20000 samples, validate on 5000 samplesEpoch 1/10 - 4s - loss: 0.4585 - acc: 0.7695 - val_loss: 0.5365 - val_acc: 0.7516Epoch 2/10 - 4s - loss: 0.2481 - acc: 0.8981 - val_loss: 0.5019 - val_acc: 0.7854Epoch 3/10 - 4s - loss: 0.1478 - acc: 0.9465 - val_loss: 0.5992 - val_acc: 0.7796Epoch 4/10 - 4s - loss: 0.0739 - acc: 0.9754 - val_loss: 0.9505 - val_acc: 0.7286Epoch 5/10 - 4s - loss: 0.0425 - acc: 0.9866 - val_loss: 0.9713 - val_acc: 0.7640Epoch 6/10 - 4s - loss: 0.0321 - acc: 0.9888 - val_loss: 1.1840 - val_acc: 0.7470Epoch 7/10 - 4s - loss: 0.0246 - acc: 0.9914 - val_loss: 1.4026 - val_acc: 0.7220Epoch 8/10 - 4s - loss: 0.0247 - acc: 0.9914 - val_loss: 1.4726 - val_acc: 0.7214Epoch 9/10 - 4s - loss: 0.0243 - acc: 0.9907 - val_loss: 1.6475 - val_acc: 0.7066Epoch 10/10 - 4s - loss: 0.0216 - acc: 0.9920 - val_loss: 1.9692 - val_acc: 0.6810</code></pre><pre class="line-numbers language-python"><code class="language-python">scores <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>25000/25000 [==============================] - 1s 36us/step</code></pre><pre class="line-numbers language-python"><code class="language-python">scores<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>0.93452</code></pre><pre class="line-numbers language-python"><code class="language-python">predict <span class="token operator">=</span> model<span class="token punctuation">.</span>predict_classes<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">predict<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>array([[1],       [1],       [1],       [1],       [1],       [1],       [1],       [1],       [1],       [1]])</code></pre><pre class="line-numbers language-python"><code class="language-python">predict_classes <span class="token operator">=</span> predict<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>predict_classes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])</code></pre><pre class="line-numbers language-python"><code class="language-python">SentimentDict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">'正面的'</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span> <span class="token string">'负面的'</span><span class="token punctuation">}</span><span class="token keyword">def</span> <span class="token function">display_test_SentimentDisct</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>test_text<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'label真实值：'</span><span class="token punctuation">,</span> SentimentDict<span class="token punctuation">[</span>y_test<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'预测结果:'</span><span class="token punctuation">,</span>          SentimentDict<span class="token punctuation">[</span>predict_classes<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">display_test_SentimentDisct<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>As a recreational golfer with some knowledge of the sport's history, I was pleased with Disney's sensitivity to the issues of class in golf in the early twentieth century. The movie depicted well the psychological battles that Harry Vardon fought within himself, from his childhood trauma of being evicted to his own inability to break that glass ceiling that prevents him from being accepted as an equal in English golf society. Likewise, the young Ouimet goes through his own class struggles, being a mere caddie in the eyes of the upper crust Americans who scoff at his attempts to rise above his standing. What I loved best, however, is how this theme of class is manifested in the characters of Ouimet's parents. His father is a working-class drone who sees the value of hard work but is intimidated by the upper class; his mother, however, recognizes her son's talent and desire and encourages him to pursue his dream of competing against those who think he is inferior.Finally, the golf scenes are well photographed. Although the course used in the movie was not the actual site of the historical tournament, the little liberties taken by Disney do not detract from the beauty of the film. There's one little Disney moment at the pool table; otherwise, the viewer does not really think Disney. The ending, as in "Miracle," is not some Disney creation, but one that only human history could have written.label真实值： 正面的 预测结果: 正面的</code></pre><pre class="line-numbers language-python"><code class="language-python">display_test_SentimentDisct<span class="token punctuation">(</span><span class="token number">1250</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>This movie was well done but it also made me feel very down at times as well. For anyone that is considering show business this is a must see as it shows the raw deal in what goes on for these struggling workers. The soundtrack was definitely cool and the acting and dancing complimented it nicely. Some of the student's attitudes might have been a little far-fetched like Leroy's especially because I'm sure someone like that would've been kicked out immediately for refusing to read and such if this was the real High School For Performing Arts. The Coco screen test is hard to watch for any people out there with weak stomachs, please heed my warning. While it's very gritty I know it's the truth on what happens so in this respect the movie is right on. Overall it's entertaining and even though some parts drag on the majority goes by really quickly.Final Grouping:Movies: Probably would've skipped this one.DVD Purchase: Not something I'd need to see again and again.Rental: Worth renting at least once in your life!label真实值： 正面的 预测结果: 正面的</code></pre><pre class="line-numbers language-python"><code class="language-python">token <span class="token operator">=</span> Tokenizer<span class="token punctuation">(</span>num_words<span class="token operator">=</span><span class="token number">2800</span><span class="token punctuation">)</span>token<span class="token punctuation">.</span>fit_on_texts<span class="token punctuation">(</span>train_text<span class="token punctuation">)</span>x_train_seq <span class="token operator">=</span> token<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span>train_text<span class="token punctuation">)</span>x_test_seq <span class="token operator">=</span> token<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span>test_text<span class="token punctuation">)</span>x_train <span class="token operator">=</span> sequence<span class="token punctuation">.</span>pad_sequences<span class="token punctuation">(</span>x_train_seq<span class="token punctuation">,</span> maxlen<span class="token operator">=</span><span class="token number">380</span><span class="token punctuation">)</span>x_test <span class="token operator">=</span> sequence<span class="token punctuation">.</span>pad_sequences<span class="token punctuation">(</span>x_test_seq<span class="token punctuation">,</span> maxlen<span class="token operator">=</span><span class="token number">380</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Embedding<span class="token punctuation">(</span>output_dim<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>                   input_dim<span class="token operator">=</span><span class="token number">3800</span><span class="token punctuation">,</span>                   input_length<span class="token operator">=</span><span class="token number">380</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>               activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>               activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================embedding_2 (Embedding)      (None, 380, 32)           121600    _________________________________________________________________dropout_3 (Dropout)          (None, 380, 32)           0         _________________________________________________________________flatten_2 (Flatten)          (None, 12160)             0         _________________________________________________________________dense_3 (Dense)              (None, 256)               3113216   _________________________________________________________________dropout_4 (Dropout)          (None, 256)               0         _________________________________________________________________dense_4 (Dense)              (None, 1)                 257       =================================================================Total params: 3,235,073Trainable params: 3,235,073Non-trainable params: 0_________________________________________________________________</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Keras </category>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Keras:CNN_MNIST数据集</title>
      <link href="/2020/05/12/Keras-CNN-MNIST%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
      <url>/2020/05/12/Keras-CNN-MNIST%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<p>代码如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> os <span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> mnist<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>utils <span class="token keyword">import</span> to_categorical<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token punctuation">(</span>X_tarin<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> mnist<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">X_train4D <span class="token operator">=</span> X_tarin<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X_tarin<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span>X_test4D <span class="token operator">=</span> X_test<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">X_train4D_Normalize <span class="token operator">=</span> X_train4D <span class="token operator">/</span> <span class="token number">255</span> <span class="token comment" spellcheck="true"># 归一化</span>X_test4D_Normalize <span class="token operator">=</span> X_test4D <span class="token operator">/</span> <span class="token number">255</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">y_trainOnehot <span class="token operator">=</span> to_categorical<span class="token punctuation">(</span>y_train<span class="token punctuation">)</span>y_testOnehot <span class="token operator">=</span> to_categorical<span class="token punctuation">(</span>y_test<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 导入相关包</span><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense<span class="token punctuation">,</span> Dropout<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Conv2D<span class="token punctuation">,</span> MaxPool2D<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 建立模型</span>model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 一层卷积</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>    Conv2D<span class="token punctuation">(</span>        filters<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>        kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 保证卷积核大小，不够补零</span>        input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 池化层1</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 二层卷积</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>    Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 池化层2</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>    Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>    Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 平坦层</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 全连接层</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">)</span> model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 激活函数</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>Model: "sequential"_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================conv2d (Conv2D)              (None, 28, 28, 16)        416       _________________________________________________________________max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         _________________________________________________________________dropout (Dropout)            (None, 14, 14, 16)        0         _________________________________________________________________conv2d_1 (Conv2D)            (None, 14, 14, 32)        12832     _________________________________________________________________max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         _________________________________________________________________dropout_1 (Dropout)          (None, 7, 7, 32)          0         _________________________________________________________________conv2d_2 (Conv2D)            (None, 7, 7, 64)          51264     _________________________________________________________________conv2d_3 (Conv2D)            (None, 7, 7, 128)         204928    _________________________________________________________________max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         _________________________________________________________________dropout_2 (Dropout)          (None, 3, 3, 128)         0         _________________________________________________________________flatten (Flatten)            (None, 1152)              0         _________________________________________________________________dense (Dense)                (None, 128)               147584    _________________________________________________________________dropout_3 (Dropout)          (None, 128)               0         _________________________________________________________________dense_1 (Dense)              (None, 10)                1290      =================================================================Total params: 418,314Trainable params: 418,314Non-trainable params: 0_________________________________________________________________</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 训练模型</span>model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span>              optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>train_history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x<span class="token operator">=</span>X_train4D_Normalize<span class="token punctuation">,</span>                          y<span class="token operator">=</span>y_trainOnehot<span class="token punctuation">,</span>                          validation_split<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>                          batch_size<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span>                          epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>                          verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>WARNING:tensorflow:From E:\Anaconda3\envs\dl\lib\site-packages\tensorflow\python\ops\math_grad.py:1250: add_dispatch_support.&lt;locals&gt;.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.Instructions for updating:Use tf.where in 2.0, which has the same broadcast rule as np.whereTrain on 48000 samples, validate on 12000 samplesEpoch 1/1048000/48000 - 81s - loss: 0.4865 - accuracy: 0.8395 - val_loss: 0.0870 - val_accuracy: 0.9719Epoch 2/1048000/48000 - 80s - loss: 0.1150 - accuracy: 0.9651 - val_loss: 0.0539 - val_accuracy: 0.9842Epoch 3/1048000/48000 - 92s - loss: 0.0841 - accuracy: 0.9746 - val_loss: 0.0442 - val_accuracy: 0.9857Epoch 4/1048000/48000 - 90s - loss: 0.0639 - accuracy: 0.9797 - val_loss: 0.0373 - val_accuracy: 0.9892Epoch 5/1048000/48000 - 89s - loss: 0.0532 - accuracy: 0.9835 - val_loss: 0.0341 - val_accuracy: 0.9889Epoch 6/1048000/48000 - 83s - loss: 0.0496 - accuracy: 0.9846 - val_loss: 0.0305 - val_accuracy: 0.9908Epoch 7/1048000/48000 - 85s - loss: 0.0415 - accuracy: 0.9869 - val_loss: 0.0298 - val_accuracy: 0.9912Epoch 8/1048000/48000 - 92s - loss: 0.0390 - accuracy: 0.9879 - val_loss: 0.0288 - val_accuracy: 0.9913Epoch 9/1048000/48000 - 85s - loss: 0.0322 - accuracy: 0.9901 - val_loss: 0.0265 - val_accuracy: 0.9925Epoch 10/1048000/48000 - 83s - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.0304 - val_accuracy: 0.9912</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 定义训练参数可视化</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token operator">%</span>matplotlib inline<span class="token keyword">def</span> <span class="token function">show_train_history</span><span class="token punctuation">(</span>train_history<span class="token punctuation">,</span> train<span class="token punctuation">,</span> validation<span class="token punctuation">)</span><span class="token punctuation">:</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_history<span class="token punctuation">.</span>history<span class="token punctuation">[</span>train<span class="token punctuation">]</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_history<span class="token punctuation">.</span>history<span class="token punctuation">[</span>validation<span class="token punctuation">]</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Train History'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'validation'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 准确率</span>show_train_history<span class="token punctuation">(</span>train_history<span class="token punctuation">,</span> <span class="token string">'accuracy'</span><span class="token punctuation">,</span> <span class="token string">'val_accuracy'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/20190911174113568.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd4dzE4MDM=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 损失率</span>show_train_history<span class="token punctuation">(</span>train_history<span class="token punctuation">,</span> <span class="token string">'loss'</span><span class="token punctuation">,</span> <span class="token string">'val_loss'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/2019091117411976.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd4dzE4MDM=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>X_test4D_Normalize<span class="token punctuation">,</span> y_testOnehot<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>10000/10000 [==============================] - 4s 423us/sample - loss: 0.0252 - accuracy: 0.99150.9915</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 预测值</span>prediction <span class="token operator">=</span> model<span class="token punctuation">.</span>predict_classes<span class="token punctuation">(</span>X_test4D_Normalize<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 预测前十</span>prediction<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=int64)</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 定义图片可视化</span><span class="token keyword">def</span> <span class="token function">plot_labels_prediction</span><span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> prediction<span class="token punctuation">,</span> idx<span class="token punctuation">,</span> num<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>gcf<span class="token punctuation">(</span><span class="token punctuation">)</span>    fig<span class="token punctuation">.</span>set_size_inches<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span>     <span class="token keyword">if</span> num <span class="token operator">></span> <span class="token number">25</span><span class="token punctuation">:</span> num <span class="token operator">=</span> <span class="token number">25</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num<span class="token punctuation">)</span><span class="token punctuation">:</span>        ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>         ax<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>images<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'binary'</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> len<span class="token punctuation">(</span>prediction<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>            title <span class="token operator">=</span> <span class="token string">',labels'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>prediction<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span>        ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span>title<span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>        ax<span class="token punctuation">.</span>set_xticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        ax<span class="token punctuation">.</span>set_yticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        idx <span class="token operator">+=</span> <span class="token number">1</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">plot_labels_prediction<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">,</span> prediction<span class="token punctuation">,</span> idx<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/20190911174051953.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd4dzE4MDM=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 交叉表查看预测数据与原数据对比</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdpd<span class="token punctuation">.</span>crosstab<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> prediction<span class="token punctuation">,</span> rownames<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'lables'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> colnames<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'predict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><div><style scoped="">    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th {    vertical-align: top;}.dataframe thead th {    text-align: right;}</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th>predict</th>      <th>0</th>      <th>1</th>      <th>2</th>      <th>3</th>      <th>4</th>      <th>5</th>      <th>6</th>      <th>7</th>      <th>8</th>      <th>9</th>    </tr>    <tr>      <th>lables</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>977</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>1</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <td>1</td>      <td>0</td>      <td>1120</td>      <td>3</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>5</td>      <td>1</td>      <td>6</td>      <td>0</td>    </tr>    <tr>      <td>2</td>      <td>0</td>      <td>0</td>      <td>1029</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <td>3</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1000</td>      <td>0</td>      <td>8</td>      <td>0</td>      <td>0</td>      <td>2</td>      <td>0</td>    </tr>    <tr>      <td>4</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>973</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>2</td>      <td>6</td>    </tr>    <tr>      <td>5</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>2</td>      <td>0</td>      <td>888</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <td>6</td>      <td>5</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>3</td>      <td>947</td>      <td>0</td>      <td>2</td>      <td>0</td>    </tr>    <tr>      <td>7</td>      <td>1</td>      <td>2</td>      <td>6</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1016</td>      <td>1</td>      <td>1</td>    </tr>    <tr>      <td>8</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>971</td>      <td>1</td>    </tr>    <tr>      <td>9</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>3</td>      <td>4</td>      <td>0</td>      <td>1</td>      <td>6</td>      <td>994</td>    </tr>  </tbody></table></div><p>由上图显示对角线为预测准确的次数</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Keras </category>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Keras:LSTM&amp;RNN对IMDb情感分析</title>
      <link href="/2020/05/12/Keras-LSTM-RNN%E5%AF%B9IMDb%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"/>
      <url>/2020/05/12/Keras-LSTM-RNN%E5%AF%B9IMDb%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="下载IMDb数据"><a href="#下载IMDb数据" class="headerlink" title="下载IMDb数据"></a>下载IMDb数据</h1><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#下载网站http://ai.stanford.edu/~amaas/data/sentiment/</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="读取IMDb数据"><a href="#读取IMDb数据" class="headerlink" title="读取IMDb数据"></a>读取IMDb数据</h1><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> sequence<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>text <span class="token keyword">import</span> Tokenizer<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#因为数据也是从网络上爬取的，所以还需要用正则表达式去除HTML标签</span><span class="token keyword">import</span> re<span class="token keyword">def</span> <span class="token function">remove_html</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    r<span class="token operator">=</span>re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'&lt;[^>]+>'</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> r<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">,</span>text<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#观察IMDB文件目录结构，用函数进行读取</span><span class="token keyword">import</span> os<span class="token keyword">def</span> <span class="token function">read_file</span><span class="token punctuation">(</span>filetype<span class="token punctuation">)</span><span class="token punctuation">:</span>    path<span class="token operator">=</span><span class="token string">'./aclImdb/'</span>    file_list<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>    positive<span class="token operator">=</span>path<span class="token operator">+</span>filetype<span class="token operator">+</span><span class="token string">'/pos/'</span>    <span class="token keyword">for</span> f <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>positive<span class="token punctuation">)</span><span class="token punctuation">:</span>        file_list<span class="token operator">+=</span><span class="token punctuation">[</span>positive<span class="token operator">+</span>f<span class="token punctuation">]</span>    negative<span class="token operator">=</span>path<span class="token operator">+</span>filetype<span class="token operator">+</span><span class="token string">'/neg/'</span>    <span class="token keyword">for</span> f <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>negative<span class="token punctuation">)</span><span class="token punctuation">:</span>        file_list<span class="token operator">+=</span><span class="token punctuation">[</span>negative<span class="token operator">+</span>f<span class="token punctuation">]</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'filetype:'</span><span class="token punctuation">,</span>filetype<span class="token punctuation">,</span><span class="token string">'file_length:'</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>file_list<span class="token punctuation">)</span><span class="token punctuation">)</span>    label<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token number">12500</span><span class="token operator">+</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token number">12500</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#train数据和test数据中positive都是12500，negative都是12500</span>    text<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> f_ <span class="token keyword">in</span> file_list<span class="token punctuation">:</span>        <span class="token keyword">with</span> open<span class="token punctuation">(</span>f_<span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>            text<span class="token operator">+=</span><span class="token punctuation">[</span>remove_html<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> label<span class="token punctuation">,</span>text<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#用x表示label,y表示text里面的内容</span>x_train<span class="token punctuation">,</span>y_train<span class="token operator">=</span>read_file<span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>filetype: train file_length: 25000</code></pre><pre class="line-numbers language-python"><code class="language-python">x_test<span class="token punctuation">,</span>y_test<span class="token operator">=</span>read_file<span class="token punctuation">(</span><span class="token string">'test'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>filetype: test file_length: 25000</code></pre><pre class="line-numbers language-python"><code class="language-python">y_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as "Teachers". My 35 years in the teaching profession lead me to believe that Bromwell High\'s satire is much closer to reality than is "Teachers". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\'t!'</code></pre><h1 id="建立分词器"><a href="#建立分词器" class="headerlink" title="建立分词器"></a>建立分词器</h1><blockquote><p>具体用法可以参看官网<a href="https://keras.io/preprocessing/text/" target="_blank" rel="noopener">https://keras.io/preprocessing/text/</a></p></blockquote><pre class="line-numbers language-python"><code class="language-python">token<span class="token operator">=</span>Tokenizer<span class="token punctuation">(</span>num_words<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#建立一个有2000单词的字典</span>token<span class="token punctuation">.</span>fit_on_texts<span class="token punctuation">(</span>y_train<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#读取所有的训练数据评论，按照单词在评论中出现的次数进行排序，前2000名会列入字典</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#查看token读取多少文章</span>token<span class="token punctuation">.</span>document_count<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>25000</code></pre><h1 id="将评论数据转化为数字列表"><a href="#将评论数据转化为数字列表" class="headerlink" title="将评论数据转化为数字列表"></a>将评论数据转化为数字列表</h1><pre class="line-numbers language-python"><code class="language-python">train_seq<span class="token operator">=</span>token<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span>y_train<span class="token punctuation">)</span>test_seq<span class="token operator">=</span>token<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span>y_test<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>y_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as "Teachers". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is "Teachers". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>[308, 6, 3, 1068, 208, 8, 29, 1, 168, 54, 13, 45, 81, 40, 391, 109, 137, 13, 57, 149, 7, 1, 481, 68, 5, 260, 11, 6, 72, 5, 631, 70, 6, 1, 5, 1, 1530, 33, 66, 63, 204, 139, 64, 1229, 1, 4, 1, 222, 899, 28, 68, 4, 1, 9, 693, 2, 64, 1530, 50, 9, 215, 1, 386, 7, 59, 3, 1470, 798, 5, 176, 1, 391, 9, 1235, 29, 308, 3, 352, 343, 142, 129, 5, 27, 4, 125, 1470, 5, 308, 9, 532, 11, 107, 1466, 4, 57, 554, 100, 11, 308, 6, 226, 47, 3, 11, 8, 214]</code></pre><h1 id="让转换后的数字长度相同"><a href="#让转换后的数字长度相同" class="headerlink" title="让转换后的数字长度相同"></a>让转换后的数字长度相同</h1><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#截长补短，让每一个数字列表长度都为100</span>_train<span class="token operator">=</span>sequence<span class="token punctuation">.</span>pad_sequences<span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>maxlen<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>_test<span class="token operator">=</span>sequence<span class="token punctuation">.</span>pad_sequences<span class="token punctuation">(</span>test_seq<span class="token punctuation">,</span>maxlen<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>[308, 6, 3, 1068, 208, 8, 29, 1, 168, 54, 13, 45, 81, 40, 391, 109, 137, 13, 57, 149, 7, 1, 481, 68, 5, 260, 11, 6, 72, 5, 631, 70, 6, 1, 5, 1, 1530, 33, 66, 63, 204, 139, 64, 1229, 1, 4, 1, 222, 899, 28, 68, 4, 1, 9, 693, 2, 64, 1530, 50, 9, 215, 1, 386, 7, 59, 3, 1470, 798, 5, 176, 1, 391, 9, 1235, 29, 308, 3, 352, 343, 142, 129, 5, 27, 4, 125, 1470, 5, 308, 9, 532, 11, 107, 1466, 4, 57, 554, 100, 11, 308, 6, 226, 47, 3, 11, 8, 214]</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>[  29    1  168   54   13   45   81   40  391  109  137   13   57  149    7    1  481   68    5  260   11    6   72    5  631   70    6    1    5    1 1530   33   66   63  204  139   64 1229    1    4    1  222  899   28   68    4    1    9  693    2   64 1530   50    9  215    1  386    7   59    3 1470  798    5  176    1  391    9 1235   29  308    3  352  343  142  129    5   27    4  125 1470    5  308    9  532   11  107 1466    4   57  554  100   11  308    6  226   47    3   11    8  214]</code></pre><pre class="line-numbers language-python"><code class="language-python">_train<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>(25000, 100)</code></pre><h1 id="加入嵌入层"><a href="#加入嵌入层" class="headerlink" title="加入嵌入层"></a>加入嵌入层</h1><blockquote><p>将数字列表转化为向量列表(为什么转化，建议大家都思考一哈)</p></blockquote><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>core <span class="token keyword">import</span> Dense<span class="token punctuation">,</span>Dropout<span class="token punctuation">,</span>Activation<span class="token punctuation">,</span>Flatten<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Embedding<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token operator">=</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Embedding<span class="token punctuation">(</span>output_dim<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#将数字列表转换为32维的向量</span>                   input_dim<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#输入数据的维度是2000，因为之前建立的字典有2000个单词</span>                   input_length<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#数字列表的长度为100</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h1 id="建立多层感知机模型"><a href="#建立多层感知机模型" class="headerlink" title="建立多层感知机模型"></a>建立多层感知机模型</h1><h5 id="加入平坦层"><a href="#加入平坦层" class="headerlink" title="加入平坦层"></a>加入平坦层</h5><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="加入隐藏层"><a href="#加入隐藏层" class="headerlink" title="加入隐藏层"></a>加入隐藏层</h5><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>               activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.35</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="加入输出层"><a href="#加入输出层" class="headerlink" title="加入输出层"></a>加入输出层</h5><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#输出层只有一个神经元，输出1表示正面评价，输出0表示负面评价</span>               activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="查看模型摘要"><a href="#查看模型摘要" class="headerlink" title="查看模型摘要"></a>查看模型摘要</h5><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================embedding_1 (Embedding)      (None, 100, 32)           64000     _________________________________________________________________dropout_1 (Dropout)          (None, 100, 32)           0         _________________________________________________________________flatten_1 (Flatten)          (None, 3200)              0         _________________________________________________________________dense_1 (Dense)              (None, 256)               819456    _________________________________________________________________dropout_2 (Dropout)          (None, 256)               0         _________________________________________________________________dense_2 (Dense)              (None, 1)                 257       =================================================================Total params: 883,713Trainable params: 883,713Non-trainable params: 0_________________________________________________________________</code></pre><h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span>             optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>             metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">train_history<span class="token operator">=</span>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>_train<span class="token punctuation">,</span>x_train<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>                       epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>                       validation_split<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>Train on 20000 samples, validate on 5000 samplesEpoch 1/10 - 21s - loss: 0.4851 - acc: 0.7521 - val_loss: 0.4491 - val_acc: 0.7894Epoch 2/10 - 20s - loss: 0.2817 - acc: 0.8829 - val_loss: 0.6735 - val_acc: 0.6892Epoch 3/10 - 13s - loss: 0.1901 - acc: 0.9285 - val_loss: 0.5907 - val_acc: 0.7632Epoch 4/10 - 12s - loss: 0.1066 - acc: 0.9622 - val_loss: 0.7522 - val_acc: 0.7528Epoch 5/10 - 13s - loss: 0.0681 - acc: 0.9765 - val_loss: 0.9863 - val_acc: 0.7404Epoch 6/10 - 13s - loss: 0.0486 - acc: 0.9827 - val_loss: 1.0818 - val_acc: 0.7506Epoch 7/10 - 14s - loss: 0.0380 - acc: 0.9859 - val_loss: 0.9823 - val_acc: 0.7780Epoch 8/10 - 17s - loss: 0.0360 - acc: 0.9860 - val_loss: 1.1297 - val_acc: 0.7634Epoch 9/10 - 13s - loss: 0.0321 - acc: 0.9891 - val_loss: 1.2459 - val_acc: 0.7480Epoch 10/10 - 14s - loss: 0.0281 - acc: 0.9899 - val_loss: 1.4111 - val_acc: 0.7304</code></pre><h1 id="评估模型准确率"><a href="#评估模型准确率" class="headerlink" title="评估模型准确率"></a>评估模型准确率</h1><pre class="line-numbers language-python"><code class="language-python">scores<span class="token operator">=</span>model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>_test<span class="token punctuation">,</span>x_test<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#第一个参数为feature,第二个参数为label</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>25000/25000 [==============================] - 4s 148us/step</code></pre><pre class="line-numbers language-python"><code class="language-python">scores<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>0.80972</code></pre><h1 id="进行预测"><a href="#进行预测" class="headerlink" title="进行预测"></a>进行预测</h1><pre class="line-numbers language-python"><code class="language-python">predict<span class="token operator">=</span>model<span class="token punctuation">.</span>predict_classes<span class="token punctuation">(</span>_test<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">predict<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>array([[1],       [0],       [1],       [1],       [1],       [1],       [1],       [1],       [1],       [1]])</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#转换成一维数组</span>predict<span class="token operator">=</span>predict<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>predict<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1])</code></pre><h1 id="查看测试数据预测结果"><a href="#查看测试数据预测结果" class="headerlink" title="查看测试数据预测结果"></a>查看测试数据预测结果</h1><pre class="line-numbers language-python"><code class="language-python">_dict<span class="token operator">=</span><span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token string">'正面的评论'</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token string">'负面的评论'</span><span class="token punctuation">}</span><span class="token keyword">def</span> <span class="token function">display</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>y_test<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'label真实值为:'</span><span class="token punctuation">,</span>_dict<span class="token punctuation">[</span>x_test<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token string">'预测结果为:'</span><span class="token punctuation">,</span>_dict<span class="token punctuation">[</span>predict<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">display<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.label真实值为: 正面的评论 预测结果为: 正面的评论</code></pre><h1 id="完整函数"><a href="#完整函数" class="headerlink" title="完整函数"></a>完整函数</h1><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">review</span><span class="token punctuation">(</span>input_text<span class="token punctuation">)</span><span class="token punctuation">:</span>    input_seq<span class="token operator">=</span>token<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span><span class="token punctuation">[</span>input_text<span class="token punctuation">]</span><span class="token punctuation">)</span>    pad_input_seq<span class="token operator">=</span>sequence<span class="token punctuation">.</span>pad_sequences<span class="token punctuation">(</span>input_seq<span class="token punctuation">,</span>maxlen<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>    predict_result<span class="token operator">=</span>model<span class="token punctuation">.</span>predict_classes<span class="token punctuation">(</span>pad_input_seq<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>_dict<span class="token punctuation">[</span>predict_result<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#IMDB上面找的一段评论，进行预测</span>review<span class="token punctuation">(</span><span class="token triple-quoted-string string">'''Going into this movie, I had low expectations. I'd seen poor reviews, and I also kind of hate the idea of remaking animated films for no reason other than to make them live action, as if that's supposed to make them better some how. This movie pleasantly surprised me!Beauty and the Beast is a fun, charming movie, that is a blast in many ways. The film very easy on the eyes! Every shot is colourful and beautifully crafted. The acting is also excellent. Dan Stevens is excellent. You can see him if you look closely at The Beast, but not so clearly that it pulls you out of the film. His performance is suitably over the top in anger, but also very charming. Emma Watson was fine, but to be honest, she was basically just playing Hermione, and I didn't get much of a character from her. She likes books, and she's feisty. That's basically all I got. For me, the one saving grace for her character, is you can see how much fun Emma Watson is having. I've heard interviews in which she's expressed how much she's always loved Belle as a character, and it shows.The stand out for me was Lumieré, voiced by Ewan McGregor. He was hilarious, and over the top, and always fun! He lit up the screen (no pun intended) every time he showed up!The only real gripes I have with the film are some questionable CGI with the Wolves and with a couple of The Beast's scenes, and some pacing issues. The film flows really well, to such an extent that in some scenes, the camera will dolly away from the character it's focusing on, and will pan across the countryside, and track to another, far away, with out cutting. This works really well, but a couple times, the film will just fade to black, and it's quite jarring. It happens like 3 or 4 times, but it's really noticeable, and took me out of the experience. Also, they added some stuff to the story that I don't want to spoil, but I don't think it worked on any level, story wise, or logically.Overall, it's a fun movie! I would recommend it to any fan of the original, but those who didn't like the animated classic, or who hate musicals might be better off staying aw'''</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>正面的评论</code></pre><pre class="line-numbers language-python"><code class="language-python">review<span class="token punctuation">(</span><span class="token triple-quoted-string string">'''This is a horrible Disney piece of crap full of completely lame singsongs, a script so wrong it is an insult to other scripts to even call it a script. The only way I could enjoy this is after eating two complete space cakes, and even then I would prefer analysing our wallpaper!'''</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>负面的评论</code></pre><ul><li>到这里用在keras中用多层感知机进行情感预测就结束了，反思实验可以改进的地方，除了神经元的个数，还可以将字典的单词个数设置大一些（原来是2000），数字列表的长度maxlen也可以设置长一些</li></ul><h1 id="用RNN模型进行IMDb情感分析"><a href="#用RNN模型进行IMDb情感分析" class="headerlink" title="用RNN模型进行IMDb情感分析"></a>用RNN模型进行IMDb情感分析</h1><ul><li>使用RNN的好处也可以思考一哈</li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>core <span class="token keyword">import</span> Dense<span class="token punctuation">,</span>Dropout<span class="token punctuation">,</span>Activation<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Embedding<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> SimpleRNN<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model_rnn<span class="token operator">=</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model_rnn<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Embedding<span class="token punctuation">(</span>output_dim<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>                   input_dim<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">,</span>                   input_length<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model_rnn<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model_rnn<span class="token punctuation">.</span>add<span class="token punctuation">(</span>SimpleRNN<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#RNN层有16个神经元</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model_rnn<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model_rnn<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model_rnn<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model_rnn<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================embedding_1 (Embedding)      (None, 100, 32)           64000     _________________________________________________________________dropout_1 (Dropout)          (None, 100, 32)           0         _________________________________________________________________simple_rnn_1 (SimpleRNN)     (None, 16)                784       _________________________________________________________________dense_1 (Dense)              (None, 256)               4352      _________________________________________________________________dropout_2 (Dropout)          (None, 256)               0         _________________________________________________________________dense_2 (Dense)              (None, 1)                 257       =================================================================Total params: 69,393Trainable params: 69,393Non-trainable params: 0_________________________________________________________________</code></pre><pre class="line-numbers language-python"><code class="language-python">model_rnn<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span>             optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>             metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>train_history<span class="token operator">=</span>model_rnn<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>_train<span class="token punctuation">,</span>x_train<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>                       epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>                       validation_split<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Train on 20000 samples, validate on 5000 samplesEpoch 1/10 - 13s - loss: 0.5200 - acc: 0.7319 - val_loss: 0.6095 - val_acc: 0.6960Epoch 2/10 - 12s - loss: 0.3485 - acc: 0.8506 - val_loss: 0.4994 - val_acc: 0.7766Epoch 3/10 - 12s - loss: 0.3109 - acc: 0.8710 - val_loss: 0.5842 - val_acc: 0.7598Epoch 4/10 - 13s - loss: 0.2874 - acc: 0.8833 - val_loss: 0.4420 - val_acc: 0.8136Epoch 5/10 - 12s - loss: 0.2649 - acc: 0.8929 - val_loss: 0.6818 - val_acc: 0.7270Epoch 6/10 - 14s - loss: 0.2402 - acc: 0.9035 - val_loss: 0.5634 - val_acc: 0.7984Epoch 7/10 - 16s - loss: 0.2084 - acc: 0.9190 - val_loss: 0.6392 - val_acc: 0.7694Epoch 8/10 - 16s - loss: 0.1855 - acc: 0.9289 - val_loss: 0.6388 - val_acc: 0.7650Epoch 9/10 - 14s - loss: 0.1641 - acc: 0.9367 - val_loss: 0.8356 - val_acc: 0.7592Epoch 10/10 - 19s - loss: 0.1430 - acc: 0.9451 - val_loss: 0.7365 - val_acc: 0.7766</code></pre><pre class="line-numbers language-python"><code class="language-python">scores<span class="token operator">=</span>model_rnn<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>_test<span class="token punctuation">,</span>x_test<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>25000/25000 [==============================] - 14s 567us/step</code></pre><pre class="line-numbers language-python"><code class="language-python">scores<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#提高了大概两个百分点</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>0.82084</code></pre><h1 id="用LSTM模型进行IMDb情感分析"><a href="#用LSTM模型进行IMDb情感分析" class="headerlink" title="用LSTM模型进行IMDb情感分析"></a>用LSTM模型进行IMDb情感分析</h1><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense<span class="token punctuation">,</span> Dropout<span class="token punctuation">,</span> Activation<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Embedding<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> LSTM<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model_lstm<span class="token operator">=</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model_lstm<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Embedding<span class="token punctuation">(</span>output_dim<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>                   input_dim<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">,</span>                   input_length<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model_lstm<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model_lstm<span class="token punctuation">.</span>add<span class="token punctuation">(</span>LSTM<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model_lstm<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model_lstm<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model_lstm<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model_lstm<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================embedding_2 (Embedding)      (None, 100, 32)           64000     _________________________________________________________________dropout_3 (Dropout)          (None, 100, 32)           0         _________________________________________________________________lstm_1 (LSTM)                (None, 32)                8320      _________________________________________________________________dense_3 (Dense)              (None, 256)               8448      _________________________________________________________________dropout_4 (Dropout)          (None, 256)               0         _________________________________________________________________dense_4 (Dense)              (None, 1)                 257       =================================================================Total params: 81,025Trainable params: 81,025Non-trainable params: 0_________________________________________________________________</code></pre><pre class="line-numbers language-python"><code class="language-python">scores<span class="token operator">=</span>model_rnn<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>_test<span class="token punctuation">,</span>x_test<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>25000/25000 [==============================] - 13s 522us/step</code></pre><pre class="line-numbers language-python"><code class="language-python">scores<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>0.82084</code></pre><blockquote><p>可以看出和RMNN差不多，这可能因为事评论数据的时间间隔不大，不能充分体现LSTM的优越性</p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Keras </category>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Keras泰坦尼克数据集预测</title>
      <link href="/2020/05/12/Keras%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E9%A2%84%E6%B5%8B/"/>
      <url>/2020/05/12/Keras%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E9%A2%84%E6%B5%8B/</url>
      
        <content type="html"><![CDATA[<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> urllib<span class="token punctuation">.</span>request<span class="token keyword">import</span> osurl <span class="token operator">=</span> <span class="token string">'http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.xls'</span>filepath <span class="token operator">=</span> <span class="token string">'./data/titanic3.xls'</span><span class="token keyword">if</span> <span class="token operator">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>filepath<span class="token punctuation">)</span><span class="token punctuation">:</span>    result <span class="token operator">=</span> urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>urlretrieve<span class="token punctuation">(</span>url<span class="token punctuation">,</span> filepath<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'downloaded:'</span><span class="token punctuation">,</span> result<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>downloaded: ('./data/titanic3.xls', &lt;http.client.HTTPMessage object at 0x00000214763EAEB8&gt;)</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdall_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_excel<span class="token punctuation">(</span><span class="token string">'./data/titanic3.xls'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">cols <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token string">'survived'</span><span class="token punctuation">,</span> <span class="token string">'name'</span><span class="token punctuation">,</span> <span class="token string">'pclass'</span><span class="token punctuation">,</span> <span class="token string">'sex'</span><span class="token punctuation">,</span> <span class="token string">'age'</span><span class="token punctuation">,</span> <span class="token string">'sibsp'</span><span class="token punctuation">,</span> <span class="token string">'parch'</span><span class="token punctuation">,</span> <span class="token string">'fare'</span><span class="token punctuation">,</span>    <span class="token string">'embarked'</span><span class="token punctuation">]</span>all_df <span class="token operator">=</span> all_df<span class="token punctuation">[</span>cols<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">all_df<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><div><style scoped="">    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th {    vertical-align: top;}.dataframe thead th {    text-align: right;}</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>survived</th>      <th>name</th>      <th>pclass</th>      <th>sex</th>      <th>age</th>      <th>sibsp</th>      <th>parch</th>      <th>fare</th>      <th>embarked</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>Allen, Miss. Elisabeth Walton</td>      <td>1</td>      <td>female</td>      <td>29.0000</td>      <td>0</td>      <td>0</td>      <td>211.3375</td>      <td>S</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>Allison, Master. Hudson Trevor</td>      <td>1</td>      <td>male</td>      <td>0.9167</td>      <td>1</td>      <td>2</td>      <td>151.5500</td>      <td>S</td>    </tr>  </tbody></table></div><pre class="line-numbers language-python"><code class="language-python">df <span class="token operator">=</span> all_df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">all_df<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>survived      0name          0pclass        0sex           0age         263sibsp         0parch         0fare          1embarked      2dtype: int64</code></pre><pre class="line-numbers language-python"><code class="language-python">age_mean <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>age_mean<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">fare_mean <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'fare'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">'fare'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'fare'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>fare_mean<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">df<span class="token punctuation">[</span><span class="token string">'sex'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'sex'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'female'</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'male'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>int<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">x_Onehot_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data<span class="token operator">=</span>df<span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'embarked'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">x_Onehot_df<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><div><style scoped="">    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th {    vertical-align: top;}.dataframe thead th {    text-align: right;}</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>survived</th>      <th>pclass</th>      <th>sex</th>      <th>age</th>      <th>sibsp</th>      <th>parch</th>      <th>fare</th>      <th>embarked_C</th>      <th>embarked_Q</th>      <th>embarked_S</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>1</td>      <td>0</td>      <td>29.0000</td>      <td>0</td>      <td>0</td>      <td>211.3375</td>      <td>0</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>1</td>      <td>1</td>      <td>0.9167</td>      <td>1</td>      <td>2</td>      <td>151.5500</td>      <td>0</td>      <td>0</td>      <td>1</td>    </tr>  </tbody></table></div><pre class="line-numbers language-python"><code class="language-python">ndarray <span class="token operator">=</span> x_Onehot_df<span class="token punctuation">.</span>values<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">ndarray<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>(1309, 10)</code></pre><pre class="line-numbers language-python"><code class="language-python">ndarray<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>array([[  1.    ,   1.    ,   0.    ,  29.    ,   0.    ,   0.    ,        211.3375,   0.    ,   0.    ,   1.    ],       [  1.    ,   1.    ,   1.    ,   0.9167,   1.    ,   2.    ,        151.55  ,   0.    ,   0.    ,   1.    ]])</code></pre><pre class="line-numbers language-python"><code class="language-python">Label <span class="token operator">=</span> ndarray<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span>Features <span class="token operator">=</span> ndarray<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">Label<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>array([1., 1.])</code></pre><pre class="line-numbers language-python"><code class="language-python">Features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>array([[  1.    ,   0.    ,  29.    ,   0.    ,   0.    , 211.3375,          0.    ,   0.    ,   1.    ],       [  1.    ,   1.    ,   0.9167,   1.    ,   2.    , 151.55  ,          0.    ,   0.    ,   1.    ]])</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> preprocessing<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">minmax_Scale <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>MinMaxScaler<span class="token punctuation">(</span>feature_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>scaledFeatures <span class="token operator">=</span> minmax_Scale<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>Features<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">scaledFeatures<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>array([[0.        , 0.        , 0.36116884, 0.        , 0.        ,        0.41250333, 0.        , 0.        , 1.        ],       [0.        , 1.        , 0.00939458, 0.125     , 0.22222222,        0.2958059 , 0.        , 0.        , 1.        ]])</code></pre><pre class="line-numbers language-python"><code class="language-python">msk <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>len<span class="token punctuation">(</span>all_df<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">0.8</span>train_df <span class="token operator">=</span> all_df<span class="token punctuation">[</span>msk<span class="token punctuation">]</span>test_df <span class="token operator">=</span> all_df<span class="token punctuation">[</span><span class="token operator">~</span>msk<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'total:'</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>all_df<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'train:'</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>train_df<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'test:'</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>test_df<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>total: 1309 train: 1071 test: 238</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">PreprocessData</span><span class="token punctuation">(</span>raw_df<span class="token punctuation">)</span><span class="token punctuation">:</span>    df <span class="token operator">=</span> raw_df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    age_mean <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>    df<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>age_mean<span class="token punctuation">)</span>    fare_mean <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'fare'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>    df<span class="token punctuation">[</span><span class="token string">'fare'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'fare'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>age_mean<span class="token punctuation">)</span>    df<span class="token punctuation">[</span><span class="token string">'sex'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'sex'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'female'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'male'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>int<span class="token punctuation">)</span>    x_Onehot_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data<span class="token operator">=</span>df<span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'embarked'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    ndarray <span class="token operator">=</span> x_Onehot_df<span class="token punctuation">.</span>values    Features <span class="token operator">=</span> ndarray<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>    Label <span class="token operator">=</span> ndarray<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>    minmax_scale <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>MinMaxScaler<span class="token punctuation">(</span>feature_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    scaledFeatures <span class="token operator">=</span> minmax_scale<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>Features<span class="token punctuation">)</span>    <span class="token keyword">return</span> scaledFeatures<span class="token punctuation">,</span> Label<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">train_Features<span class="token punctuation">,</span> train_Label <span class="token operator">=</span> PreprocessData<span class="token punctuation">(</span>train_df<span class="token punctuation">)</span>test_Features<span class="token punctuation">,</span> test_Label <span class="token operator">=</span> PreprocessData<span class="token punctuation">(</span>test_df<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">train_Features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>array([[0.        , 0.        , 0.0229641 , 0.125     , 0.22222222,        0.2958059 , 0.        , 0.        , 1.        ],       [0.        , 1.        , 0.37369494, 0.125     , 0.22222222,        0.2958059 , 0.        , 0.        , 1.        ]])</code></pre><pre class="line-numbers language-python"><code class="language-python">test_Label<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>array([1., 1.])</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 建立模型</span><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense<span class="token punctuation">,</span> Dropout<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>    Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">,</span>          input_dim<span class="token operator">=</span><span class="token number">9</span><span class="token punctuation">,</span>          kernel_initializer<span class="token operator">=</span><span class="token string">'uniform'</span><span class="token punctuation">,</span>          activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> kernel_initializer<span class="token operator">=</span><span class="token string">'uniform'</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>kernel_initializer<span class="token operator">=</span><span class="token string">'uniform'</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span>             optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>             metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>W0819 11:23:43.940761  6100 deprecation_wrapper.py:119] From E:\Anaconda3\envs\ml\lib\site-packages\keras\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.W0819 11:23:43.970712  6100 deprecation_wrapper.py:119] From E:\Anaconda3\envs\ml\lib\site-packages\keras\backend\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.W0819 11:23:43.976665  6100 deprecation.py:323] From E:\Anaconda3\envs\ml\lib\site-packages\tensorflow\python\ops\nn_impl.py:180: add_dispatch_support.&lt;locals&gt;.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.Instructions for updating:Use tf.where in 2.0, which has the same broadcast rule as np.where</code></pre><pre class="line-numbers language-python"><code class="language-python">train_history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x<span class="token operator">=</span>train_Features<span class="token punctuation">,</span>                          y<span class="token operator">=</span>train_Label<span class="token punctuation">,</span>                          validation_split<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>                          batch_size<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span>                          epochs<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span>                          verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Train on 963 samples, validate on 108 samplesEpoch 1/30 - 0s - loss: 0.6645 - acc: 0.6023 - val_loss: 0.5840 - val_acc: 0.7685Epoch 2/30 - 0s - loss: 0.6062 - acc: 0.6594 - val_loss: 0.4936 - val_acc: 0.7870Epoch 3/30 - 0s - loss: 0.5513 - acc: 0.7487 - val_loss: 0.4564 - val_acc: 0.7870Epoch 4/30 - 0s - loss: 0.5151 - acc: 0.7747 - val_loss: 0.4487 - val_acc: 0.8056Epoch 5/30 - 0s - loss: 0.4968 - acc: 0.7757 - val_loss: 0.4538 - val_acc: 0.8056Epoch 6/30 - 0s - loss: 0.4882 - acc: 0.7736 - val_loss: 0.4354 - val_acc: 0.8056Epoch 7/30 - 0s - loss: 0.4839 - acc: 0.7695 - val_loss: 0.4277 - val_acc: 0.8148Epoch 8/30 - 0s - loss: 0.4818 - acc: 0.7788 - val_loss: 0.4254 - val_acc: 0.8148Epoch 9/30 - 0s - loss: 0.4796 - acc: 0.7840 - val_loss: 0.4231 - val_acc: 0.8333Epoch 10/30 - 0s - loss: 0.4766 - acc: 0.7819 - val_loss: 0.4247 - val_acc: 0.8148Epoch 11/30 - 0s - loss: 0.4733 - acc: 0.7830 - val_loss: 0.4240 - val_acc: 0.8148Epoch 12/30 - 0s - loss: 0.4714 - acc: 0.7840 - val_loss: 0.4174 - val_acc: 0.8333Epoch 13/30 - 0s - loss: 0.4684 - acc: 0.7871 - val_loss: 0.4181 - val_acc: 0.8426Epoch 14/30 - 0s - loss: 0.4666 - acc: 0.7871 - val_loss: 0.4169 - val_acc: 0.8426Epoch 15/30 - 0s - loss: 0.4643 - acc: 0.7892 - val_loss: 0.4151 - val_acc: 0.8519Epoch 16/30 - 0s - loss: 0.4632 - acc: 0.7892 - val_loss: 0.4134 - val_acc: 0.8426Epoch 17/30 - 0s - loss: 0.4618 - acc: 0.7902 - val_loss: 0.4133 - val_acc: 0.8426Epoch 18/30 - 0s - loss: 0.4618 - acc: 0.7913 - val_loss: 0.4145 - val_acc: 0.8056Epoch 19/30 - 0s - loss: 0.4606 - acc: 0.7944 - val_loss: 0.4160 - val_acc: 0.8426Epoch 20/30 - 0s - loss: 0.4606 - acc: 0.7934 - val_loss: 0.4155 - val_acc: 0.8148Epoch 21/30 - 0s - loss: 0.4588 - acc: 0.7944 - val_loss: 0.4124 - val_acc: 0.8426Epoch 22/30 - 0s - loss: 0.4568 - acc: 0.7954 - val_loss: 0.4136 - val_acc: 0.8426Epoch 23/30 - 0s - loss: 0.4571 - acc: 0.7985 - val_loss: 0.4152 - val_acc: 0.8333Epoch 24/30 - 0s - loss: 0.4585 - acc: 0.7923 - val_loss: 0.4190 - val_acc: 0.8056Epoch 25/30 - 0s - loss: 0.4577 - acc: 0.7923 - val_loss: 0.4162 - val_acc: 0.8426Epoch 26/30 - 0s - loss: 0.4610 - acc: 0.7882 - val_loss: 0.4192 - val_acc: 0.8426Epoch 27/30 - 0s - loss: 0.4553 - acc: 0.8006 - val_loss: 0.4156 - val_acc: 0.8333Epoch 28/30 - 0s - loss: 0.4580 - acc: 0.7902 - val_loss: 0.4186 - val_acc: 0.7963Epoch 29/30 - 0s - loss: 0.4590 - acc: 0.7975 - val_loss: 0.4145 - val_acc: 0.8426Epoch 30/30 - 0s - loss: 0.4550 - acc: 0.7934 - val_loss: 0.4165 - val_acc: 0.8241</code></pre><pre class="line-numbers language-python"><code class="language-python">scores <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x<span class="token operator">=</span>test_Features<span class="token punctuation">,</span> y<span class="token operator">=</span> test_Label<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>238/238 [==============================] - 0s 21us/step</code></pre><pre class="line-numbers language-python"><code class="language-python">scores<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>0.8025210089042407</code></pre><pre class="line-numbers language-python"><code class="language-python">Jack <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'Jack'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">'male'</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5.000</span><span class="token punctuation">,</span> <span class="token string">'S'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>Rose <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'Rose'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'female'</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">100.000</span><span class="token punctuation">,</span> <span class="token string">'S'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">JR_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">[</span>list<span class="token punctuation">(</span>Jack<span class="token punctuation">)</span><span class="token punctuation">,</span> list<span class="token punctuation">(</span>Rose<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                     columns<span class="token operator">=</span><span class="token punctuation">[</span>                         <span class="token string">'survived'</span><span class="token punctuation">,</span> <span class="token string">'name'</span><span class="token punctuation">,</span> <span class="token string">'pclass'</span><span class="token punctuation">,</span> <span class="token string">'sex'</span><span class="token punctuation">,</span> <span class="token string">'age'</span><span class="token punctuation">,</span> <span class="token string">'sibsp'</span><span class="token punctuation">,</span>                         <span class="token string">'parch'</span><span class="token punctuation">,</span> <span class="token string">'fare'</span><span class="token punctuation">,</span> <span class="token string">'embarked'</span>                     <span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">all_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>all_df<span class="token punctuation">,</span> JR_df<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">all_df<span class="token punctuation">[</span><span class="token operator">~</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><div><style scoped="">    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th {    vertical-align: top;}.dataframe thead th {    text-align: right;}</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>survived</th>      <th>name</th>      <th>pclass</th>      <th>sex</th>      <th>age</th>      <th>sibsp</th>      <th>parch</th>      <th>fare</th>      <th>embarked</th>    </tr>  </thead>  <tbody>    <tr>      <th>1308</th>      <td>0</td>      <td>Zimmerman, Mr. Leo</td>      <td>3</td>      <td>male</td>      <td>29.0</td>      <td>0</td>      <td>0</td>      <td>7.875</td>      <td>S</td>    </tr>    <tr>      <th>0</th>      <td>0</td>      <td>Jack</td>      <td>3</td>      <td>male</td>      <td>23.0</td>      <td>1</td>      <td>0</td>      <td>5.000</td>      <td>S</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>Rose</td>      <td>1</td>      <td>female</td>      <td>20.0</td>      <td>1</td>      <td>0</td>      <td>100.000</td>      <td>S</td>    </tr>  </tbody></table></div><pre class="line-numbers language-python"><code class="language-python">all_Features<span class="token punctuation">,</span> Label <span class="token operator">=</span> PreprocessData<span class="token punctuation">(</span>all_df<span class="token punctuation">)</span>all_probability <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>all_Features<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">all_probability<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>array([[0.97387624],       [0.36760893],       [0.9653297 ],       [0.29578814],       [0.96136355],       [0.26288155],       [0.93404984],       [0.27685004],       [0.92254674],       [0.30783302]], dtype=float32)</code></pre><pre class="line-numbers language-python"><code class="language-python">pd <span class="token operator">=</span> all_dfpd<span class="token punctuation">.</span>insert<span class="token punctuation">(</span>len<span class="token punctuation">(</span>all_df<span class="token punctuation">.</span>columns<span class="token punctuation">)</span><span class="token punctuation">,</span>         <span class="token string">'probability'</span><span class="token punctuation">,</span> all_probability<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">pd<span class="token punctuation">[</span><span class="token operator">~</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><div><style scoped="">    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th {    vertical-align: top;}.dataframe thead th {    text-align: right;}</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>survived</th>      <th>name</th>      <th>pclass</th>      <th>sex</th>      <th>age</th>      <th>sibsp</th>      <th>parch</th>      <th>fare</th>      <th>embarked</th>      <th>probability</th>    </tr>  </thead>  <tbody>    <tr>      <th>1308</th>      <td>0</td>      <td>Zimmerman, Mr. Leo</td>      <td>3</td>      <td>male</td>      <td>29.0</td>      <td>0</td>      <td>0</td>      <td>7.875</td>      <td>S</td>      <td>0.132631</td>    </tr>    <tr>      <th>0</th>      <td>0</td>      <td>Jack</td>      <td>3</td>      <td>male</td>      <td>23.0</td>      <td>1</td>      <td>0</td>      <td>5.000</td>      <td>S</td>      <td>0.130663</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>Rose</td>      <td>1</td>      <td>female</td>      <td>20.0</td>      <td>1</td>      <td>0</td>      <td>100.000</td>      <td>S</td>      <td>0.963028</td>    </tr>  </tbody></table></div><pre class="line-numbers language-python"><code class="language-python">pd<span class="token punctuation">[</span><span class="token punctuation">(</span>pd<span class="token punctuation">[</span><span class="token string">'survived'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><div><style scoped="">    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th {    vertical-align: top;}.dataframe thead th {    text-align: right;}</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>survived</th>      <th>name</th>      <th>pclass</th>      <th>sex</th>      <th>age</th>      <th>sibsp</th>      <th>parch</th>      <th>fare</th>      <th>embarked</th>      <th>probability</th>    </tr>  </thead>  <tbody>    <tr>      <th>2</th>      <td>0</td>      <td>Allison, Miss. Helen Loraine</td>      <td>1</td>      <td>female</td>      <td>2.0</td>      <td>1</td>      <td>2</td>      <td>151.5500</td>      <td>S</td>      <td>0.965330</td>    </tr>    <tr>      <th>3</th>      <td>0</td>      <td>Allison, Mr. Hudson Joshua Creighton</td>      <td>1</td>      <td>male</td>      <td>30.0</td>      <td>1</td>      <td>2</td>      <td>151.5500</td>      <td>S</td>      <td>0.295788</td>    </tr>    <tr>      <th>4</th>      <td>0</td>      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>      <td>1</td>      <td>female</td>      <td>25.0</td>      <td>1</td>      <td>2</td>      <td>151.5500</td>      <td>S</td>      <td>0.961364</td>    </tr>    <tr>      <th>7</th>      <td>0</td>      <td>Andrews, Mr. Thomas Jr</td>      <td>1</td>      <td>male</td>      <td>39.0</td>      <td>0</td>      <td>0</td>      <td>0.0000</td>      <td>S</td>      <td>0.276850</td>    </tr>    <tr>      <th>9</th>      <td>0</td>      <td>Artagaveytia, Mr. Ramon</td>      <td>1</td>      <td>male</td>      <td>71.0</td>      <td>0</td>      <td>0</td>      <td>49.5042</td>      <td>C</td>      <td>0.307833</td>    </tr>    <tr>      <th>10</th>      <td>0</td>      <td>Astor, Col. John Jacob</td>      <td>1</td>      <td>male</td>      <td>47.0</td>      <td>1</td>      <td>0</td>      <td>227.5250</td>      <td>C</td>      <td>0.382211</td>    </tr>    <tr>      <th>15</th>      <td>0</td>      <td>Baumann, Mr. John D</td>      <td>1</td>      <td>male</td>      <td>NaN</td>      <td>0</td>      <td>0</td>      <td>25.9250</td>      <td>S</td>      <td>0.303370</td>    </tr>    <tr>      <th>16</th>      <td>0</td>      <td>Baxter, Mr. Quigg Edmond</td>      <td>1</td>      <td>male</td>      <td>24.0</td>      <td>0</td>      <td>1</td>      <td>247.5208</td>      <td>C</td>      <td>0.568902</td>    </tr>    <tr>      <th>19</th>      <td>0</td>      <td>Beattie, Mr. Thomson</td>      <td>1</td>      <td>male</td>      <td>36.0</td>      <td>0</td>      <td>0</td>      <td>75.2417</td>      <td>C</td>      <td>0.418435</td>    </tr>    <tr>      <th>25</th>      <td>0</td>      <td>Birnbaum, Mr. Jakob</td>      <td>1</td>      <td>male</td>      <td>25.0</td>      <td>0</td>      <td>0</td>      <td>26.0000</td>      <td>C</td>      <td>0.446399</td>    </tr>    <tr>      <th>30</th>      <td>0</td>      <td>Blackwell, Mr. Stephen Weart</td>      <td>1</td>      <td>male</td>      <td>45.0</td>      <td>0</td>      <td>0</td>      <td>35.5000</td>      <td>S</td>      <td>0.271255</td>    </tr>    <tr>      <th>34</th>      <td>0</td>      <td>Borebank, Mr. John James</td>      <td>1</td>      <td>male</td>      <td>42.0</td>      <td>0</td>      <td>0</td>      <td>26.5500</td>      <td>S</td>      <td>0.275931</td>    </tr>    <tr>      <th>38</th>      <td>0</td>      <td>Brady, Mr. John Bertram</td>      <td>1</td>      <td>male</td>      <td>41.0</td>      <td>0</td>      <td>0</td>      <td>30.5000</td>      <td>S</td>      <td>0.278998</td>    </tr>    <tr>      <th>39</th>      <td>0</td>      <td>Brandeis, Mr. Emil</td>      <td>1</td>      <td>male</td>      <td>48.0</td>      <td>0</td>      <td>0</td>      <td>50.4958</td>      <td>C</td>      <td>0.364540</td>    </tr>    <tr>      <th>40</th>      <td>0</td>      <td>Brewe, Dr. Arthur Jackson</td>      <td>1</td>      <td>male</td>      <td>NaN</td>      <td>0</td>      <td>0</td>      <td>39.6000</td>      <td>C</td>      <td>0.429713</td>    </tr>    <tr>      <th>45</th>      <td>0</td>      <td>Butt, Major. Archibald Willingham</td>      <td>1</td>      <td>male</td>      <td>45.0</td>      <td>0</td>      <td>0</td>      <td>26.5500</td>      <td>S</td>      <td>0.269356</td>    </tr>    <tr>      <th>46</th>      <td>0</td>      <td>Cairns, Mr. Alexander</td>      <td>1</td>      <td>male</td>      <td>NaN</td>      <td>0</td>      <td>0</td>      <td>31.0000</td>      <td>S</td>      <td>0.304525</td>    </tr>    <tr>      <th>51</th>      <td>0</td>      <td>Carlsson, Mr. Frans Olof</td>      <td>1</td>      <td>male</td>      <td>33.0</td>      <td>0</td>      <td>0</td>      <td>5.0000</td>      <td>S</td>      <td>0.291429</td>    </tr>    <tr>      <th>52</th>      <td>0</td>      <td>Carrau, Mr. Francisco M</td>      <td>1</td>      <td>male</td>      <td>28.0</td>      <td>0</td>      <td>0</td>      <td>47.1000</td>      <td>S</td>      <td>0.312617</td>    </tr>    <tr>      <th>53</th>      <td>0</td>      <td>Carrau, Mr. Jose Pedro</td>      <td>1</td>      <td>male</td>      <td>17.0</td>      <td>0</td>      <td>0</td>      <td>47.1000</td>      <td>S</td>      <td>0.339315</td>    </tr>    <tr>      <th>58</th>      <td>0</td>      <td>Case, Mr. Howard Brown</td>      <td>1</td>      <td>male</td>      <td>49.0</td>      <td>0</td>      <td>0</td>      <td>26.0000</td>      <td>S</td>      <td>0.260632</td>    </tr>    <tr>      <th>60</th>      <td>0</td>      <td>Cavendish, Mr. Tyrell William</td>      <td>1</td>      <td>male</td>      <td>36.0</td>      <td>1</td>      <td>0</td>      <td>78.8500</td>      <td>S</td>      <td>0.271148</td>    </tr>    <tr>      <th>62</th>      <td>0</td>      <td>Chaffee, Mr. Herbert Fuller</td>      <td>1</td>      <td>male</td>      <td>46.0</td>      <td>1</td>      <td>0</td>      <td>61.1750</td>      <td>S</td>      <td>0.246321</td>    </tr>    <tr>      <th>70</th>      <td>0</td>      <td>Chisholm, Mr. Roderick Robert Crispin</td>      <td>1</td>      <td>male</td>      <td>NaN</td>      <td>0</td>      <td>0</td>      <td>0.0000</td>      <td>S</td>      <td>0.297509</td>    </tr>    <tr>      <th>71</th>      <td>0</td>      <td>Clark, Mr. Walter Miller</td>      <td>1</td>      <td>male</td>      <td>27.0</td>      <td>1</td>      <td>0</td>      <td>136.7792</td>      <td>C</td>      <td>0.426140</td>    </tr>    <tr>      <th>74</th>      <td>0</td>      <td>Clifford, Mr. George Quincy</td>      <td>1</td>      <td>male</td>      <td>NaN</td>      <td>0</td>      <td>0</td>      <td>52.0000</td>      <td>S</td>      <td>0.309330</td>    </tr>    <tr>      <th>75</th>      <td>0</td>      <td>Colley, Mr. Edward Pomeroy</td>      <td>1</td>      <td>male</td>      <td>47.0</td>      <td>0</td>      <td>0</td>      <td>25.5875</td>      <td>S</td>      <td>0.264827</td>    </tr>    <tr>      <th>77</th>      <td>0</td>      <td>Compton, Mr. Alexander Taylor Jr</td>      <td>1</td>      <td>male</td>      <td>37.0</td>      <td>1</td>      <td>1</td>      <td>83.1583</td>      <td>C</td>      <td>0.365659</td>    </tr>    <tr>      <th>80</th>      <td>0</td>      <td>Crafton, Mr. John Bertram</td>      <td>1</td>      <td>male</td>      <td>NaN</td>      <td>0</td>      <td>0</td>      <td>26.5500</td>      <td>S</td>      <td>0.303512</td>    </tr>    <tr>      <th>81</th>      <td>0</td>      <td>Crosby, Capt. Edward Gifford</td>      <td>1</td>      <td>male</td>      <td>70.0</td>      <td>1</td>      <td>1</td>      <td>71.0000</td>      <td>S</td>      <td>0.200277</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>1276</th>      <td>0</td>      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>      <td>3</td>      <td>female</td>      <td>31.0</td>      <td>1</td>      <td>0</td>      <td>18.0000</td>      <td>S</td>      <td>0.390119</td>    </tr>    <tr>      <th>1278</th>      <td>0</td>      <td>Vendel, Mr. Olof Edvin</td>      <td>3</td>      <td>male</td>      <td>20.0</td>      <td>0</td>      <td>0</td>      <td>7.8542</td>      <td>S</td>      <td>0.144151</td>    </tr>    <tr>      <th>1279</th>      <td>0</td>      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>      <td>3</td>      <td>female</td>      <td>14.0</td>      <td>0</td>      <td>0</td>      <td>7.8542</td>      <td>S</td>      <td>0.541694</td>    </tr>    <tr>      <th>1280</th>      <td>0</td>      <td>Vovk, Mr. Janko</td>      <td>3</td>      <td>male</td>      <td>22.0</td>      <td>0</td>      <td>0</td>      <td>7.8958</td>      <td>S</td>      <td>0.141521</td>    </tr>    <tr>      <th>1281</th>      <td>0</td>      <td>Waelens, Mr. Achille</td>      <td>3</td>      <td>male</td>      <td>22.0</td>      <td>0</td>      <td>0</td>      <td>9.0000</td>      <td>S</td>      <td>0.141519</td>    </tr>    <tr>      <th>1282</th>      <td>0</td>      <td>Ware, Mr. Frederick</td>      <td>3</td>      <td>male</td>      <td>NaN</td>      <td>0</td>      <td>0</td>      <td>8.0500</td>      <td>S</td>      <td>0.131565</td>    </tr>    <tr>      <th>1283</th>      <td>0</td>      <td>Warren, Mr. Charles William</td>      <td>3</td>      <td>male</td>      <td>NaN</td>      <td>0</td>      <td>0</td>      <td>7.5500</td>      <td>S</td>      <td>0.131566</td>    </tr>    <tr>      <th>1284</th>      <td>0</td>      <td>Webber, Mr. James</td>      <td>3</td>      <td>male</td>      <td>NaN</td>      <td>0</td>      <td>0</td>      <td>8.0500</td>      <td>S</td>      <td>0.131565</td>    </tr>    <tr>      <th>1285</th>      <td>0</td>      <td>Wenzel, Mr. Linhart</td>      <td>3</td>      <td>male</td>      <td>32.5</td>      <td>0</td>      <td>0</td>      <td>9.5000</td>      <td>S</td>      <td>0.128364</td>    </tr>    <tr>      <th>1287</th>      <td>0</td>      <td>Widegren, Mr. Carl/Charles Peter</td>      <td>3</td>      <td>male</td>      <td>51.0</td>      <td>0</td>      <td>0</td>      <td>7.7500</td>      <td>S</td>      <td>0.107727</td>    </tr>    <tr>      <th>1288</th>      <td>0</td>      <td>Wiklund, Mr. Jakob Alfred</td>      <td>3</td>      <td>male</td>      <td>18.0</td>      <td>1</td>      <td>0</td>      <td>6.4958</td>      <td>S</td>      <td>0.136882</td>    </tr>    <tr>      <th>1289</th>      <td>0</td>      <td>Wiklund, Mr. Karl Johan</td>      <td>3</td>      <td>male</td>      <td>21.0</td>      <td>1</td>      <td>0</td>      <td>6.4958</td>      <td>S</td>      <td>0.133120</td>    </tr>    <tr>      <th>1291</th>      <td>0</td>      <td>Willer, Mr. Aaron ("Abi Weller")</td>      <td>3</td>      <td>male</td>      <td>NaN</td>      <td>0</td>      <td>0</td>      <td>8.7125</td>      <td>S</td>      <td>0.131564</td>    </tr>    <tr>      <th>1292</th>      <td>0</td>      <td>Willey, Mr. Edward</td>      <td>3</td>      <td>male</td>      <td>NaN</td>      <td>0</td>      <td>0</td>      <td>7.5500</td>      <td>S</td>      <td>0.131566</td>    </tr>    <tr>      <th>1293</th>      <td>0</td>      <td>Williams, Mr. Howard Hugh "Harry"</td>      <td>3</td>      <td>male</td>      <td>NaN</td>      <td>0</td>      <td>0</td>      <td>8.0500</td>      <td>S</td>      <td>0.131565</td>    </tr>    <tr>      <th>1294</th>      <td>0</td>      <td>Williams, Mr. Leslie</td>      <td>3</td>      <td>male</td>      <td>28.5</td>      <td>0</td>      <td>0</td>      <td>16.1000</td>      <td>S</td>      <td>0.133237</td>    </tr>    <tr>      <th>1295</th>      <td>0</td>      <td>Windelov, Mr. Einar</td>      <td>3</td>      <td>male</td>      <td>21.0</td>      <td>0</td>      <td>0</td>      <td>7.2500</td>      <td>S</td>      <td>0.142832</td>    </tr>    <tr>      <th>1296</th>      <td>0</td>      <td>Wirz, Mr. Albert</td>      <td>3</td>      <td>male</td>      <td>27.0</td>      <td>0</td>      <td>0</td>      <td>8.6625</td>      <td>S</td>      <td>0.135120</td>    </tr>    <tr>      <th>1297</th>      <td>0</td>      <td>Wiseman, Mr. Phillippe</td>      <td>3</td>      <td>male</td>      <td>NaN</td>      <td>0</td>      <td>0</td>      <td>7.2500</td>      <td>S</td>      <td>0.131567</td>    </tr>    <tr>      <th>1298</th>      <td>0</td>      <td>Wittevrongel, Mr. Camille</td>      <td>3</td>      <td>male</td>      <td>36.0</td>      <td>0</td>      <td>0</td>      <td>9.5000</td>      <td>S</td>      <td>0.124216</td>    </tr>    <tr>      <th>1299</th>      <td>0</td>      <td>Yasbeck, Mr. Antoni</td>      <td>3</td>      <td>male</td>      <td>27.0</td>      <td>1</td>      <td>0</td>      <td>14.4542</td>      <td>C</td>      <td>0.161984</td>    </tr>    <tr>      <th>1301</th>      <td>0</td>      <td>Youseff, Mr. Gerious</td>      <td>3</td>      <td>male</td>      <td>45.5</td>      <td>0</td>      <td>0</td>      <td>7.2250</td>      <td>C</td>      <td>0.147109</td>    </tr>    <tr>      <th>1302</th>      <td>0</td>      <td>Yousif, Mr. Wazli</td>      <td>3</td>      <td>male</td>      <td>NaN</td>      <td>0</td>      <td>0</td>      <td>7.2250</td>      <td>C</td>      <td>0.169266</td>    </tr>    <tr>      <th>1303</th>      <td>0</td>      <td>Yousseff, Mr. Gerious</td>      <td>3</td>      <td>male</td>      <td>NaN</td>      <td>0</td>      <td>0</td>      <td>14.4583</td>      <td>C</td>      <td>0.169295</td>    </tr>    <tr>      <th>1304</th>      <td>0</td>      <td>Zabour, Miss. Hileni</td>      <td>3</td>      <td>female</td>      <td>14.5</td>      <td>1</td>      <td>0</td>      <td>14.4542</td>      <td>C</td>      <td>0.674486</td>    </tr>    <tr>      <th>1305</th>      <td>0</td>      <td>Zabour, Miss. Thamine</td>      <td>3</td>      <td>female</td>      <td>NaN</td>      <td>1</td>      <td>0</td>      <td>14.4542</td>      <td>C</td>      <td>0.603369</td>    </tr>    <tr>      <th>1306</th>      <td>0</td>      <td>Zakarian, Mr. Mapriededer</td>      <td>3</td>      <td>male</td>      <td>26.5</td>      <td>0</td>      <td>0</td>      <td>7.2250</td>      <td>C</td>      <td>0.174369</td>    </tr>    <tr>      <th>1307</th>      <td>0</td>      <td>Zakarian, Mr. Ortin</td>      <td>3</td>      <td>male</td>      <td>27.0</td>      <td>0</td>      <td>0</td>      <td>7.2250</td>      <td>C</td>      <td>0.173603</td>    </tr>    <tr>      <th>1308</th>      <td>0</td>      <td>Zimmerman, Mr. Leo</td>      <td>3</td>      <td>male</td>      <td>29.0</td>      <td>0</td>      <td>0</td>      <td>7.8750</td>      <td>S</td>      <td>0.132631</td>    </tr>    <tr>      <th>0</th>      <td>0</td>      <td>Jack</td>      <td>3</td>      <td>male</td>      <td>23.0</td>      <td>1</td>      <td>0</td>      <td>5.0000</td>      <td>S</td>      <td>0.130663</td>    </tr>  </tbody></table><p>810 rows × 10 columns</p></div><pre class="line-numbers language-python"><code class="language-python">pd<span class="token punctuation">[</span><span class="token punctuation">(</span>pd<span class="token punctuation">[</span><span class="token string">'survived'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>pd<span class="token punctuation">[</span><span class="token string">'probability'</span><span class="token punctuation">]</span> <span class="token operator">></span> <span class="token number">0.9</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><div><style scoped="">    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th {    vertical-align: top;}.dataframe thead th {    text-align: right;}</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>survived</th>      <th>name</th>      <th>pclass</th>      <th>sex</th>      <th>age</th>      <th>sibsp</th>      <th>parch</th>      <th>fare</th>      <th>embarked</th>      <th>probability</th>    </tr>  </thead>  <tbody>    <tr>      <th>2</th>      <td>0</td>      <td>Allison, Miss. Helen Loraine</td>      <td>1</td>      <td>female</td>      <td>2.0</td>      <td>1</td>      <td>2</td>      <td>151.5500</td>      <td>S</td>      <td>0.965330</td>    </tr>    <tr>      <th>4</th>      <td>0</td>      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>      <td>1</td>      <td>female</td>      <td>25.0</td>      <td>1</td>      <td>2</td>      <td>151.5500</td>      <td>S</td>      <td>0.961364</td>    </tr>    <tr>      <th>105</th>      <td>0</td>      <td>Evans, Miss. Edith Corse</td>      <td>1</td>      <td>female</td>      <td>36.0</td>      <td>0</td>      <td>0</td>      <td>31.6792</td>      <td>C</td>      <td>0.973539</td>    </tr>    <tr>      <th>169</th>      <td>0</td>      <td>Isham, Miss. Ann Elizabeth</td>      <td>1</td>      <td>female</td>      <td>50.0</td>      <td>0</td>      <td>0</td>      <td>28.7125</td>      <td>C</td>      <td>0.971705</td>    </tr>    <tr>      <th>286</th>      <td>0</td>      <td>Straus, Mrs. Isidor (Rosalie Ida Blun)</td>      <td>1</td>      <td>female</td>      <td>63.0</td>      <td>1</td>      <td>0</td>      <td>221.7792</td>      <td>S</td>      <td>0.954021</td>    </tr>  </tbody></table></div><pre class="line-numbers language-python"><code class="language-python">pd<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><div><style scoped="">    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th {    vertical-align: top;}.dataframe thead th {    text-align: right;}</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>survived</th>      <th>name</th>      <th>pclass</th>      <th>sex</th>      <th>age</th>      <th>sibsp</th>      <th>parch</th>      <th>fare</th>      <th>embarked</th>      <th>probability</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>Allen, Miss. Elisabeth Walton</td>      <td>1</td>      <td>female</td>      <td>29.0000</td>      <td>0</td>      <td>0</td>      <td>211.3375</td>      <td>S</td>      <td>0.973876</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>Allison, Master. Hudson Trevor</td>      <td>1</td>      <td>male</td>      <td>0.9167</td>      <td>1</td>      <td>2</td>      <td>151.5500</td>      <td>S</td>      <td>0.367609</td>    </tr>    <tr>      <th>2</th>      <td>0</td>      <td>Allison, Miss. Helen Loraine</td>      <td>1</td>      <td>female</td>      <td>2.0000</td>      <td>1</td>      <td>2</td>      <td>151.5500</td>      <td>S</td>      <td>0.965330</td>    </tr>    <tr>      <th>3</th>      <td>0</td>      <td>Allison, Mr. Hudson Joshua Creighton</td>      <td>1</td>      <td>male</td>      <td>30.0000</td>      <td>1</td>      <td>2</td>      <td>151.5500</td>      <td>S</td>      <td>0.295788</td>    </tr>    <tr>      <th>4</th>      <td>0</td>      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>      <td>1</td>      <td>female</td>      <td>25.0000</td>      <td>1</td>      <td>2</td>      <td>151.5500</td>      <td>S</td>      <td>0.961364</td>    </tr>  </tbody></table></div><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Keras </category>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>softmax_MNIST</title>
      <link href="/2020/05/12/softmax-MNIST/"/>
      <url>/2020/05/12/softmax-MNIST/</url>
      
        <content type="html"><![CDATA[<h2 id="Pytorch：softmax-MNIST"><a href="#Pytorch：softmax-MNIST" class="headerlink" title="Pytorch：softmax_MNIST"></a>Pytorch：softmax_MNIST</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span> transforms<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">520</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">520</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">240</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">240</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># view类似于np中的resize</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l4<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>l5<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Run</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> <span class="token punctuation">(</span>data<span class="token punctuation">,</span> target<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>            data<span class="token punctuation">,</span> target <span class="token operator">=</span> Variable<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> Variable<span class="token punctuation">(</span>target<span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> batch_idx <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>                    epoch<span class="token punctuation">,</span> batch_idx <span class="token operator">*</span> len<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>train_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">,</span>                           <span class="token number">100</span><span class="token punctuation">.</span> <span class="token operator">*</span> batch_idx <span class="token operator">/</span> len<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>        test_loss <span class="token operator">=</span> <span class="token number">0</span>        correct <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> data<span class="token punctuation">,</span> target <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>            data<span class="token punctuation">,</span> target <span class="token operator">=</span> Variable<span class="token punctuation">(</span>data<span class="token punctuation">,</span> volatile<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Variable<span class="token punctuation">(</span>target<span class="token punctuation">)</span>            output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>            test_loss <span class="token operator">+=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            pred <span class="token operator">=</span> output<span class="token punctuation">.</span>data<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keeepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>            correct <span class="token operator">+=</span> pred<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>target<span class="token punctuation">.</span>data<span class="token punctuation">.</span>view_as<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>        test_loss <span class="token operator">/=</span> len<span class="token punctuation">(</span>test_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>            test_loss<span class="token punctuation">,</span> correct<span class="token punctuation">,</span> len<span class="token punctuation">(</span>test_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token number">100</span><span class="token punctuation">.</span> <span class="token operator">*</span> correct <span class="token operator">/</span> len<span class="token punctuation">(</span>test_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">run</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>train<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>test<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Life is short, You need Python!"</span><span class="token punctuation">)</span>    batch_size <span class="token operator">=</span> <span class="token number">64</span>    <span class="token comment" spellcheck="true"># MNIST Dataset</span>    train_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'.//data//'</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    test_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'.//data//'</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Data loader</span>    train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    test_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>    r <span class="token operator">=</span> Run<span class="token punctuation">(</span><span class="token punctuation">)</span>    r<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN_MNIST</title>
      <link href="/2020/05/12/CNN-MNIST/"/>
      <url>/2020/05/12/CNN-MNIST/</url>
      
        <content type="html"><![CDATA[<h2 id="Pytorch：CNN网络识别MNIST"><a href="#Pytorch：CNN网络识别MNIST" class="headerlink" title="Pytorch：CNN网络识别MNIST"></a>Pytorch：CNN网络识别MNIST</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span> transforms<span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>mp <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        in_size <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>in_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># flatten the tensor</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> F<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Run</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Run<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> <span class="token punctuation">(</span>data<span class="token punctuation">,</span> target<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>            data<span class="token punctuation">,</span> target <span class="token operator">=</span> Variable<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> Variable<span class="token punctuation">(</span>target<span class="token punctuation">)</span>            optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>            loss <span class="token operator">=</span> F<span class="token punctuation">.</span>nll_loss<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> batch_idx <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>                    epoch<span class="token punctuation">,</span> batch_idx <span class="token operator">*</span> len<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>train_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">,</span>                           <span class="token number">100</span><span class="token punctuation">.</span> <span class="token operator">*</span> batch_idx <span class="token operator">/</span> len<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>        test_loss <span class="token operator">=</span> <span class="token number">0</span>        correct <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> data<span class="token punctuation">,</span> target <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>            data<span class="token punctuation">,</span> target <span class="token operator">=</span> Variable<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> Variable<span class="token punctuation">(</span>target<span class="token punctuation">)</span>            output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># sum up batch loss</span>            test_loss <span class="token operator">+=</span> F<span class="token punctuation">.</span>nll_loss<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># get the index of the max log-probability</span>            pred <span class="token operator">=</span> output<span class="token punctuation">.</span>data<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>            correct <span class="token operator">+=</span> pred<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>target<span class="token punctuation">.</span>data<span class="token punctuation">.</span>view_as<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>        test_loss <span class="token operator">/=</span> len<span class="token punctuation">(</span>test_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>            test_loss<span class="token punctuation">,</span> correct<span class="token punctuation">,</span> len<span class="token punctuation">(</span>test_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token number">100</span><span class="token punctuation">.</span> <span class="token operator">*</span> correct <span class="token operator">/</span> len<span class="token punctuation">(</span>test_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">run</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>train<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>test<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Life is short, You need Python!"</span><span class="token punctuation">)</span>    batch_size <span class="token operator">=</span> <span class="token number">64</span>    train_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">'.//data//'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    test_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">'.//data//'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>    test_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_dataset<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>    model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>    r <span class="token operator">=</span> Run<span class="token punctuation">(</span><span class="token punctuation">)</span>    r<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch基础-Logistic回归</title>
      <link href="/2020/05/12/Pytorch%E5%9F%BA%E7%A1%80-Logistic%E5%9B%9E%E5%BD%92/"/>
      <url>/2020/05/12/Pytorch%E5%9F%BA%E7%A1%80-Logistic%E5%9B%9E%E5%BD%92/</url>
      
        <content type="html"><![CDATA[<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>1.1.0</code></pre><h2 id="Logistic回归"><a href="#Logistic回归" class="headerlink" title="Logistic回归"></a>Logistic回归</h2><p>logistic回归是一中广义线性回归，与多重线性回归分析有很多相同之处。它们模型形式上基本相同，都具有wx+b,其中w和b是待求解参数，区别在于因变量不同，多重线性回归直接将wx+b作为因变量，即y=wx+b，而logistic回归则通过函数L将wx+b对应一个隐状态p，p=L(wx+b)，根据p与1-p的大小决定因变量的值。</p><p>L为logistic函数时为logistic回归，L为多项式函数时为多项式回归  </p><p>logistic回归主要进行二分类预测：sigmoid函数就是常见的logistic函数，因为sigmoid函数的输出时0~1之间的概率，当概率大于0.5时预测为1，小于0.5时为0  </p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 加载数据</span>data <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span><span class="token string">'./data/german.data-numeric'</span><span class="token punctuation">)</span>n<span class="token punctuation">,</span> l <span class="token operator">=</span> data<span class="token punctuation">.</span>shape<span class="token comment" spellcheck="true"># 数据归一化</span><span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>l <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    meanVal <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">)</span>    stdVal <span class="token operator">=</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">)</span>    data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">-</span> meanVal<span class="token punctuation">)</span> <span class="token operator">/</span> stdVal<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 打乱数据</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 划分训练集和测试集</span>train_data <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">900</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>l <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span>train_tag <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">900</span><span class="token punctuation">,</span> l <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span>test_data <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">900</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>l <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span>test_tag <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">900</span><span class="token punctuation">:</span><span class="token punctuation">,</span> l <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 定义网络</span><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        <span class="token keyword">return</span> out<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>pred<span class="token punctuation">,</span> lab<span class="token punctuation">)</span><span class="token punctuation">:</span>    t <span class="token operator">=</span> pred<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> lab    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>t<span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>critertion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 使用交叉熵损失</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Adam优化器</span>epochs <span class="token operator">=</span> <span class="token number">1000</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 指定模型为训练模型，计算梯度</span>    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>train_data<span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>    y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>train_tag<span class="token punctuation">)</span><span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span>    y_pred <span class="token operator">=</span> net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    loss <span class="token operator">=</span> critertion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 计算损失</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 权重置零</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 反向传播</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        net<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#指定模型计算模式</span>        test_in <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>test_data<span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>        test_t <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>test_tag<span class="token punctuation">)</span><span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span>        test_out <span class="token operator">=</span> net<span class="token punctuation">(</span>test_in<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 使用测试函数计算准确率</span>        accu <span class="token operator">=</span> test<span class="token punctuation">(</span>test_out<span class="token punctuation">,</span> test_t<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch: {}, loss: {}, accuracy:{}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>            epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> accu<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>epoch: 100, loss: 0.6658604145050049, accuracy:0.699999988079071epoch: 200, loss: 0.6306068897247314, accuracy:0.8199999928474426epoch: 300, loss: 0.6095178723335266, accuracy:0.8100000023841858epoch: 400, loss: 0.5955496430397034, accuracy:0.8100000023841858epoch: 500, loss: 0.5853410363197327, accuracy:0.800000011920929epoch: 600, loss: 0.5774123072624207, accuracy:0.8199999928474426epoch: 700, loss: 0.5710282921791077, accuracy:0.8199999928474426epoch: 800, loss: 0.5657661557197571, accuracy:0.8199999928474426epoch: 900, loss: 0.5613517165184021, accuracy:0.8199999928474426epoch: 1000, loss: 0.5575944185256958, accuracy:0.8199999928474426</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch基础-卷积神经网络</title>
      <link href="/2020/05/12/Pytorch%E5%9F%BA%E7%A1%80-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2020/05/12/Pytorch%E5%9F%BA%E7%A1%80-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><p>卷积神经网络由一个或多个卷积层和顶端的全连接层（也可为1x1的卷积层作为输出）组成的一种前馈神经网络。  </p><h3 id="结构组成"><a href="#结构组成" class="headerlink" title="结构组成"></a>结构组成</h3><h4 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h4><p>卷积计算如图<br><img src="https://img-blog.csdnimg.cn/20200512153142826.gif#pic_center" alt="卷积计算"></p><p>定义一个权重矩阵即W（一般对于卷积来说，称作卷积的核kernel也有人称为过滤器filter），这个权重一般为3x3、5x5或7x7。一般3x3和5x5为最佳大小。<br>上图计算方式：在输入矩阵上使用权重矩阵进行滑动，每滑一步，将所有覆盖的值与矩阵对应相乘，并将计算结果求和并作为输出矩阵的一项，以此类推完成计算。<br><strong>卷积核大小：f</strong><br>卷积核大小用f表示<br><strong>边界填充：padding</strong><br>由上图可知，经过计算矩阵大小改变，如使矩阵大小保持不变，可以先对矩阵做填充，将矩阵周围再包围一层，这个矩阵即变成7x7大小，上下左右各加1，相当于5+1+1=7,这时计算结果还为5x5，保证了大小不变，p=1<br><strong>步长：stride</strong><br>每次滑动的距离<br><strong>计算公式</strong><br>n为输入的矩阵大小，$\cfrac{n-f+2p}{s} + 1$向下取整<br><strong>卷积层</strong><br>在每一个卷积层中会设置多个核，每个核代表不同的特征，这些特征就是需要传递到下一层的输出。训练过程就是训练不同的核  </p><h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h4><p>由于卷积的操作是线性的，所以需要进行激活，一般情况下使用relu  </p><h4 id="池化层（pooling）"><a href="#池化层（pooling）" class="headerlink" title="池化层（pooling）"></a>池化层（pooling）</h4><p>池化层是CNN重要组成部分，通过减少卷积层之间的连接，降低运算复杂程度，池化层操作相当于合并；输入一个过滤器大小，与卷积的操作一样，也是一步步滑动，但是过滤器覆盖的区域要进行合并，只保留一个值，合并的方式很多，常用的是取最大值maxpolling和平均值avgpooling<br>池化层的大小公式和输入卷积层一样，由于没有填充，所以p等于0，即$\cfrac{n-f}{s} + 1$</p><h4 id="dropout层"><a href="#dropout层" class="headerlink" title="dropout层"></a>dropout层</h4><p>为防止过拟合而采用trick，增强了模型的泛化能力Dropout（随机失活）是指在深度学习网络的训练过程中，按一定的比例将一部分的神经网络单元暂时从网络中那个丢弃，相当于从原始的网络中找到更瘦的网络，即将一部分网络的传播截断。</p><h4 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h4><p>全连接层一般作为最后的输入层使用，卷积的作用是提取图像的特征，最后的全连接层就是要通过这些特征来进行计算，输出即为结果。<br>进行全连接前需要对特征进行压扁，将其变成一维向量，如果进行分类用softmax作为输出，回归使用linear即可</p><h4 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h4><ul><li>用卷积提取空间特征</li><li>由空间平均得到子样本</li><li>用tanh或sigmoid得到非线性</li><li>用multi-layer neural network(MLP)作为最终分类器</li><li>层层之间使用稀疏的连接矩阵，以避免大的计算成本</li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># LeNet 代码来自官方教程</span><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">class</span> <span class="token class-name">LeNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>LeNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 1 input ， 6 output， 5x5 square convlution</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Max pooling over (2x2) </span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_flat_features<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x    <span class="token keyword">def</span> <span class="token function">num_flat_features</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        size <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>        num_features <span class="token operator">=</span> <span class="token number">1</span>        <span class="token keyword">for</span> s <span class="token keyword">in</span> size<span class="token punctuation">:</span>            num_features <span class="token operator">*=</span> s        <span class="token keyword">return</span> num_features<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    net <span class="token operator">=</span> LeNet<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>LeNet(  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))  (fc1): Linear(in_features=640, out_features=120, bias=True)  (fc2): Linear(in_features=120, out_features=84, bias=True)  (fc3): Linear(in_features=84, out_features=10, bias=True))</code></pre><h4 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h4><ul><li>用rectified linear utils得到非线性</li><li>使用dropout在训练期间有选择的忽略单个神经单元，来缓解过拟合</li><li>重叠最大池，避免平均池的平均效果</li><li>使用GPU NVDIA可以有效地减少训练时间，可以用于更大的数据集和图像上</li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># AlexNet</span><span class="token keyword">import</span> torchvisionmodel <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>alexnet<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre><code>AlexNet(  (features): Sequential(    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))    (1): ReLU(inplace)    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))    (4): ReLU(inplace)    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (7): ReLU(inplace)    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (9): ReLU(inplace)    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (11): ReLU(inplace)    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)  )  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))  (classifier): Sequential(    (0): Dropout(p=0.5)    (1): Linear(in_features=9216, out_features=4096, bias=True)    (2): ReLU(inplace)    (3): Dropout(p=0.5)    (4): Linear(in_features=4096, out_features=4096, bias=True)    (5): ReLU(inplace)    (6): Linear(in_features=4096, out_features=1000, bias=True)  ))</code></pre><h4 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h4><ul><li>每个卷积层中使用更小的3x3 filters，并将它们组成卷积序列</li><li>多个3x3卷积序列可以模拟更大的接受场效果</li><li>每次的图像像素缩小一倍，卷积核的数量增加一倍</li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># VGG16</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>VGG(  (features): Sequential(    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (1): ReLU(inplace)    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (3): ReLU(inplace)    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (6): ReLU(inplace)    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (8): ReLU(inplace)    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (11): ReLU(inplace)    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (13): ReLU(inplace)    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (15): ReLU(inplace)    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (18): ReLU(inplace)    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (20): ReLU(inplace)    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (22): ReLU(inplace)    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (25): ReLU(inplace)    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (27): ReLU(inplace)    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (29): ReLU(inplace)    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  )  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))  (classifier): Sequential(    (0): Linear(in_features=25088, out_features=4096, bias=True)    (1): ReLU(inplace)    (2): Dropout(p=0.5)    (3): Linear(in_features=4096, out_features=4096, bias=True)    (4): ReLU(inplace)    (5): Dropout(p=0.5)    (6): Linear(in_features=4096, out_features=1000, bias=True)  ))</code></pre><h4 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h4><ul><li>使用1x1卷积块（NiN）来减少特征数量，这通常称为“瓶颈”，可以减少深层神界那个网络的计算负担</li><li>每个层池化之前，增加feature maps，增加每一层的宽度来增多特征的组合性</li></ul><pre class="line-numbers language-python"><code class="language-python">model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>inception_v3<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>Inception架构的主要思想是找出如何让已有的稠密组件接近与覆盖卷积视觉网络中的最佳局部稀疏架构。即每一模块都是由若干个不同的特征提取方式，例如3x3卷积，5x5卷积，1x1卷积，pooling等，都计算一下，最后再把这些结果通过FilterConcat来进行连接，并找到里边作用最大的。而网络包含了许多这样的模块，这样不用人为的去判断哪种提取方式好，网络会自己解决，在Pytorch中实现了InceptionA-E，还有InceptionAUX模块</p><h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4><p>残差网络Pytorch实现</p><pre class="line-numbers language-python"><code class="language-python">model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>ResNet(  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  (relu): ReLU(inplace)  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)  (layer1): Sequential(    (0): BasicBlock(      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace)      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )    (1): BasicBlock(      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace)      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )  )  (layer2): Sequential(    (0): BasicBlock(      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace)      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (downsample): Sequential(        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (1): BasicBlock(      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace)      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )  )  (layer3): Sequential(    (0): BasicBlock(      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace)      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (downsample): Sequential(        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (1): BasicBlock(      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace)      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )  )  (layer4): Sequential(    (0): BasicBlock(      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace)      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (downsample): Sequential(        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (1): BasicBlock(      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace)      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )  )  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))  (fc): Linear(in_features=512, out_features=1000, bias=True))</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch-神经网络</title>
      <link href="/2020/04/29/Pytorch-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2020/04/29/Pytorch-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><p>神经网络是由具有适应性的简单单元组成的广泛并行互联的网络，他的组织能够模拟生物神经系统对真实世界物体做出的交互反应</p><p>在深度学习中也借鉴了这样的结构，每一个神经元接受输入x，通过带权重w的连接进行传递，将总输入的信号与神经元的阈值进行比较，最后通过激活函数处理确定是否激活，并将激活后的计算结果y输出；训练即训练权重w</p><h3 id="神经网络表示"><a href="#神经网络表示" class="headerlink" title="神经网络表示"></a>神经网络表示</h3><p>将神经元拼接，两层神经元，即输入层+输出层（M-P)构成感知机。而多层功能神经元相连构成神经网络，输入层与输出层之间的所有层神经元，称为感知层；</p><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p>神经网络中的激活函数就是用来判断我们所计算的信息是否达到了往后面传输的条件<br>在神经网络计算过程中，每层都相当于矩阵相乘，无论神经网络有多少层输入都是输入的线性组合，每一层矩阵相乘获得的信息差距不大，所以需要激活函数来引入非线性因素，是的神经网络可以任意逼近任何非线性函数，这样神经网络就可以应用到众多的非线性模型中，增加和神经网络模型的泛化特性</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npx <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h4><p>$a = \cfrac{1}{1+e^-z}$ 导数：$a’=a(1-a)$ </p><p>在sigmoid函数中，其输入是在(0,1)区间，它能把输入的连续实值变换为0到1之间的输出，如果是非常大的负数，那么输出就是0；如果是非常大的正数输出就是1，起到了抑制的作用</p><pre class="line-numbers language-python"><code class="language-python">ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'right'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_color<span class="token punctuation">(</span><span class="token string">'none'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'top'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_color<span class="token punctuation">(</span><span class="token string">'none'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>xaxis<span class="token punctuation">.</span>set_ticks_position<span class="token punctuation">(</span><span class="token string">'bottom'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'bottom'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_position<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'data'</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>yaxis<span class="token punctuation">.</span>set_ticks_position<span class="token punctuation">(</span><span class="token string">'left'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'left'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_position<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>sigmoid <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> sigmoid<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>[&lt;matplotlib.lines.Line2D at 0x1dda740f408&gt;]</code></pre><p><img src="https://img-blog.csdnimg.cn/20200429095138192.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd4dzE4MDM=,size_16,color_FFFFFF,t_70#pic_center" alt="1"></p><p>sigmoid由于需要指数训练，再加上函数输出不是以0为中心的（权重更新效率低），当输入远离坐标原点，函数的梯度就变得很小（几乎为0）。在神经网络反向传播的过程中不利于权重优化，这个问题叫梯度饱和，也叫梯度弥散。所以sigmoid基本上只在做二元分类(0,1)时的输出层才会使用</p><h4 id="tanh函数"><a href="#tanh函数" class="headerlink" title="tanh函数"></a>tanh函数</h4><p>$a=\cfrac{e^z - e^{-z}}{e^z+e^{-z}}$ 导数：$a’=1-a^2$</p><p>tanh是双曲线正切函数，输输出区间在(-1, 1)之间，函数以0为中心</p><pre class="line-numbers language-python"><code class="language-python">ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'right'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_color<span class="token punctuation">(</span><span class="token string">'none'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'top'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_color<span class="token punctuation">(</span><span class="token string">'none'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>xaxis<span class="token punctuation">.</span>set_ticks_position<span class="token punctuation">(</span><span class="token string">'bottom'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'bottom'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_position<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>yaxis<span class="token punctuation">.</span>set_ticks_position<span class="token punctuation">(</span><span class="token string">'left'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'left'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_position<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>tanh <span class="token operator">=</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>x<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tanh<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>[&lt;matplotlib.lines.Line2D at 0x1dda38bf2c8&gt;]</code></pre><p><img src="https://img-blog.csdnimg.cn/20200429095157750.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd4dzE4MDM=,size_16,color_FFFFFF,t_70#pic_center" alt="2"></p><p>与sigmoid函数类似，当输入稍微远离了坐标原点，梯度还是很小，但是tanh是以0为中心点，使用tanh作为激活函数，可以起到归一化（均值为0）效果</p><h4 id="ReLU函数"><a href="#ReLU函数" class="headerlink" title="ReLU函数"></a>ReLU函数</h4><p>ReLu(Rectified Linear Units)修正线性单元<br>$a = max(0, z)$导数大于0时1，小于0时0；即z&gt;0时，梯度始终为1，从而提高了神经网络基于梯度算法的运算速度。当z&lt;0时，梯度一直为0。ReLU函数只有线性关系(只需判断输入是否大于0)不管前向传播还是反向传播，都比sigmoid和tanh速度快</p><pre class="line-numbers language-python"><code class="language-python">ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'right'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_color<span class="token punctuation">(</span><span class="token string">'none'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'top'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_color<span class="token punctuation">(</span><span class="token string">'none'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>xaxis<span class="token punctuation">.</span>set_ticks_position<span class="token punctuation">(</span><span class="token string">'bottom'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'bottom'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_position<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>yaxis<span class="token punctuation">.</span>set_ticks_position<span class="token punctuation">(</span><span class="token string">'left'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'left'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_position<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>relu <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> relu<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>[&lt;matplotlib.lines.Line2D at 0x1ddaa52a948&gt;]</code></pre><p><img src="https://img-blog.csdnimg.cn/20200429095213918.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd4dzE4MDM=,size_16,color_FFFFFF,t_70#pic_center" alt="3"></p><p>当输入为负数的时候，ReLU函数完全不被激活的。这表明如果输入为负数，ReLU会死掉，但是到了反向传播的时候，输入负数，梯度会完全到0</p><h4 id="Leaky-ReLU函数"><a href="#Leaky-ReLU函数" class="headerlink" title="Leaky ReLU函数"></a>Leaky ReLU函数</h4><p>为了解决ReLu函数z&lt;0的问题，出现了Leaky ReLU函数，保证在z&lt;0的时候，梯度仍不为0，ReLu的前半段设为az而不是0，通常a=0.01 $a=max(az,z)$</p><pre class="line-numbers language-python"><code class="language-python">ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'right'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_color<span class="token punctuation">(</span><span class="token string">'none'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'top'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_color<span class="token punctuation">(</span><span class="token string">'none'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>xaxis<span class="token punctuation">.</span>set_ticks_position<span class="token punctuation">(</span><span class="token string">'bottom'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'bottom'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_position<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>yaxis<span class="token punctuation">.</span>set_ticks_position<span class="token punctuation">(</span><span class="token string">'left'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'left'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_position<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>lrelu <span class="token operator">=</span> F<span class="token punctuation">.</span>leaky_relu<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0.09</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lrelu<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>[&lt;matplotlib.lines.Line2D at 0x1ddaaceb4c8&gt;]</code></pre><p><img src="https://img-blog.csdnimg.cn/20200429095233894.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd4dzE4MDM=,size_16,color_FFFFFF,t_70#pic_center" alt="4"></p><p>理论上讲，Leaky ReLu有ReLU的所有优点，但是没有完全证明Leaky ReLU总体好于ReLU<br>ReLU目前仍时常用的activation function，在隐藏层中优先尝试</p><h3 id="前向传播和反向传播"><a href="#前向传播和反向传播" class="headerlink" title="前向传播和反向传播"></a>前向传播和反向传播</h3><h4 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h4><p>对于一个神经网络来说，把输入特征$a^{[0]}$这个输入值就是输入的x，放入第一层并计算第一层的激活函数，用$a^{[1]}$表示，本层中的训练结果用$W^{[1]}$和$b^{[1]}$表示，这两个及计算结果$Z^{[1]}$值都需要进行缓存，往后依此类推，直到最后计算出$z^{[L]}$值。这个第L层的输出值即为网络的预测值。正向传播其实就是输入x经过一系列计网络计算得到y的过程</p><h4 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h4><p>对于反向传播:就是对正向传播的一些列的反向迭代，通过反向计算梯度，来优化需要训练的W和b。$\delta a^{[l]}$值进行求导得到$\delta a^{[l-1]}$，以此类推直到得到$\delta a^{[2]}$和$\delta a^{[1]}$。反向春波步骤中也会输出$\delta W^{[l]}$和$\delta b{[l]}$。这一步已得到权重的变化量</p><p>$W = W - \alpha \delta W$</p><p>$b = b - \alpha \delta b$</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch-深度学习基础</title>
      <link href="/2020/04/29/Pytorch-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
      <url>/2020/04/29/Pytorch-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch：深度学习基础及数学原理"><a href="#Pytorch：深度学习基础及数学原理" class="headerlink" title="Pytorch：深度学习基础及数学原理"></a>Pytorch：深度学习基础及数学原理</h1><h2 id="监督学习和无监督学习"><a href="#监督学习和无监督学习" class="headerlink" title="监督学习和无监督学习"></a>监督学习和无监督学习</h2><p>常见机器学习方法：</p><ul><li>监督学习：通过已有的训练样本（即已知数据及对应的输出）去训练得到一个最优模型，再利用这个模型将所有的输入映射为相应的输出</li><li>无监督学习：没有已训练样本，需要对数据进行建模</li><li>半监督学习：在训练阶段结合大量未标记的数据和少量的标签数据。使用训练集训练的模型在训练时更为准确</li><li>强化学习：设定一个回报函数，通过这个函数来确认是否与目标值越来越接近。</li></ul><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>线性回归是利用数理统计中回归分析，来确定两种或两种以上的变量间的相互依赖的定量关系的一种统计方法<br>回归分析中，只包含一个自变量和一个因变量，并且二者的关系可以用一条直线近似表示，这种回归分析称为一元线性回归分析。如包含两个或两个以上的自变量，且自变量与因变量之间是线性关系，则称为多元线性回归</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Linear<span class="token punctuation">,</span> Module<span class="token punctuation">,</span> MSELoss<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> SGD<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 定义一个线性函数， y = 2x + 3</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">)</span>y <span class="token operator">=</span> <span class="token number">3</span> <span class="token operator">*</span> x <span class="token operator">+</span> <span class="token number">5</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre><code>[&lt;matplotlib.lines.Line2D at 0x2dd900b01c8&gt;]</code></pre><p><img src="https://img-blog.csdnimg.cn/20200429094242381.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd4dzE4MDM=,size_16,color_FFFFFF,t_70#pic_center" alt="1"></p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 生成随机的点，作为训练数据</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span>noise <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">4</span>y <span class="token operator">=</span> <span class="token number">3</span> <span class="token operator">*</span> x <span class="token operator">+</span> <span class="token number">5</span> <span class="token operator">+</span> noisedf <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">'x'</span><span class="token punctuation">]</span> <span class="token operator">=</span> xdf<span class="token punctuation">[</span><span class="token string">'y'</span><span class="token punctuation">]</span> <span class="token operator">=</span> y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 显示数据</span>sns<span class="token punctuation">.</span>lmplot<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token string">'x'</span><span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token string">'y'</span><span class="token punctuation">,</span> data<span class="token operator">=</span>df<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>&lt;seaborn.axisgrid.FacetGrid at 0x2dd9017dc08&gt;</code></pre><p><img src="https://img-blog.csdnimg.cn/20200429094301542.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd4dzE4MDM=,size_16,color_FFFFFF,t_70#pic_center" alt="2"></p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 训练</span>model <span class="token operator">=</span> Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 参数代表输入输出的特征（features）数量都是1， Linear模型的表达式为y=w*x+b,其中w代表权重，b代表偏置</span>criterion <span class="token operator">=</span> MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># MSDLoss均方误差</span>optimizer <span class="token operator">=</span> SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 优化器选择常见的SGD优化器，即每一次计算batch梯度，学习率0.01</span>epochs <span class="token operator">=</span> <span class="token number">2000</span><span class="token comment" spellcheck="true"># 训练2000次</span><span class="token comment" spellcheck="true"># 准备训练数据，x_train,y_train的形状（256，1），代表batch大小为256， features为1， astype为float32</span>x_train <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span>y_train <span class="token operator">=</span> y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 开始训练</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 整理输入和输出符合torch的Tensor类型</span>    inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>    labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y_train<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 使用模型预测</span>    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 重置权重</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 计算损失</span>    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 反向传播</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 使用优化器默认优化方法</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch {}, loss: {:.3f}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>i<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>data<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>epoch 0, loss: 35.537epoch 100, loss: 0.294epoch 200, loss: 0.074epoch 300, loss: 0.070epoch 400, loss: 0.068epoch 500, loss: 0.066epoch 600, loss: 0.065epoch 700, loss: 0.064epoch 800, loss: 0.063epoch 900, loss: 0.063epoch 1000, loss: 0.062epoch 1100, loss: 0.062epoch 1200, loss: 0.062epoch 1300, loss: 0.062epoch 1400, loss: 0.061epoch 1500, loss: 0.061epoch 1600, loss: 0.061epoch 1700, loss: 0.061epoch 1800, loss: 0.061epoch 1900, loss: 0.061</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 使用model.parameters提取模型参数，w和b是需要训练的模型参数</span><span class="token punctuation">[</span>w<span class="token punctuation">,</span> b<span class="token punctuation">]</span> <span class="token operator">=</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'w:'</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'b:'</span><span class="token punctuation">,</span> b<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>w: 3.033578872680664 b: 4.967657089233398</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 可视化模型</span>predicted <span class="token operator">=</span> model<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> <span class="token string">'go'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'data'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> predicted<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'predicted'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/2020042909434538.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd4dzE4MDM=,size_16,color_FFFFFF,t_70#pic_center" alt="3"></p><h2 id="损失函数（Loss-Function）"><a href="#损失函数（Loss-Function）" class="headerlink" title="损失函数（Loss Function）"></a>损失函数（Loss Function）</h2><p>损失函数是用来估量模型的预测值与真实值的差异程度，它是一个非负数，且数值越小则模型性能越好。<br>训练模型的过程即为通过不断迭代计算，使用梯度下降优化算法，使得损失函数越来越小，以达到模型最优</p><h3>Pytorch内置损失函数</h3><h4>nn.L1loss(reduction='sum')</h4>参数：reduction有三个参数，none:不适用约简，mean:返回loss的平均值，sum:返回loss的和。默认mean输入x与目标y之间的绝对值，要求x与y的维度一样，得到的loss维度也是一样: <p>$loss(x,y)=1/n \Sigma|x_{i} - y_{i}|$</p><h4>nn.NLLLoss(weight=None,ignore_index=-100,reduction='mean')</h4>用于多分类的负对数似然损失函数: <p>$loss(x,class) = -x[class]$</p><p>NLLLoss中如果传递了weight参数，会对损失函数进行加权，公式即变成:</p><p>$loss(x,class) = -weight[class] * x[class]$</p><h4>nn.MSELoss(reduction='mean')</h4>均方误差损失函数，输入x和目标值y之间的均方差  <p>$loss(x, y) = 1/n \Sigma (x_i - y_i)^2$</p><h4>nn.CrossEntropyLoss(weight=None,ignore_index=-100,reduction='mean')</h4>参数：weight(Tensor， optional)-自定义的每个类别的权重，必须是长度为C的Tensor；ignore_index(int, optional) -设置一个目标值，该值会被忽略，从而不影响到输入的梯度；reduction同上多分类用的交叉熵损失函数，LogSoftMax和NLLLoss集成到一个类中，会调用nn.NLLLoss函数，可以理解为： <p>CrossEntropyLoss() = log_softmax() + NLLLoss()</p><p>$losss(x, class) = -log \cfrac{exp(x[class]} {\Sigma_j exp(x[j])}$ </p><p>因为使用了NLLLoss，所以可以传入weight参数，这时loss的计算公式变为：</p><p>$loss(x,y)=weights[class] * (-x[class]+log(\Sigma_j exp(x[j])))$</p><p>所以一般多分类的情况会使用这个损失函数</p><h4>nn.BCELoss</h4>计算x与y之间的二进制交叉熵  <p>$loss(o,t)=-\cfrac{1}{n}\Sigma_i(t[i]<em>log(o[i]+(1-t[i])</em>log(1-o[i]))$</p><p>用的时候需要在该层前面加Sigmoid函数</p><h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>梯度下降是一个使损失函数越来越小的优化算法，在约束优化问题时，梯度下降（Gradient Descent）是最常采用的方法之一。  </p><h4 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h4><p>梯度的本意是一个向量（矢量），标识某一函数在该点处的方向导数沿着该方向取得最大值，即函数在该点处沿着该方向（此梯度的方向）变化最快，变化率最大（为该梯度的模）<br>我们需要最小化损失函数，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数和模型参数</p><h4 id="Mini-batch的梯度下降法"><a href="#Mini-batch的梯度下降法" class="headerlink" title="Mini_batch的梯度下降法"></a>Mini_batch的梯度下降法</h4><p>对于整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练集很大的时候处理速度会很慢，而且也不可能一次的载入到内存或显存中，所以要把大数据集分成小数据集，一部分一部分的训练，这个训练子集即称为Mini_batch。<br>对于普通的梯度下降法，一个epoch只能进行一次梯度下降，而对于Mini_batch梯度下降法，一个epoch可以进行Mini_batch的个数次梯度下降</p><ul><li>如果训练样本的大小比较小时，能够一次性的读取到内存中，那就不需要使用Mini_batch</li><li>如果训练样本的大小比较大时，一次读入不到内存或显存中，那么必须使用Mini_batch来分批的计算</li><li>Mini_batch size的计算规则如下，在内存允许的最大情况下使用2的N次方个size</li></ul><h4 id="torch-optim-SGD"><a href="#torch-optim-SGD" class="headerlink" title="torch.optim.SGD"></a>torch.optim.SGD</h4><p>随机梯度下降算法，带有动量(momentum)的算法作为一个可选参数进行设置  </p><pre class="line-numbers language-python"><code class="language-python">optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> moment_num<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="torch-optim-RMSprop"><a href="#torch-optim-RMSprop" class="headerlink" title="torch.optim.RMSprop"></a>torch.optim.RMSprop</h4><p>RMSprop(root mean square prop)也是一种可以加快梯度下降的算法，利用RMSprop算法，可以减小某些维度更新波动较大的情况，使其梯度下降的变化最快</p><pre class="line-numbers language-python"><code class="language-python">optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.99</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="torch-optim-Adam"><a href="#torch-optim-Adam" class="headerlink" title="torch.optim.Adam"></a>torch.optim.Adam</h4><p>Adam优化算法的基本思想就是将Momentnum和RMSprop结合起来的一种适用于不同深度学习结构的优化算法</p><pre class="line-numbers language-python"><code class="language-python">optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token number">0.99</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">08</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="方差-偏差"><a href="#方差-偏差" class="headerlink" title="方差/偏差"></a>方差/偏差</h4><ul><li>偏差度量了学习算法的期望预测与真实结果的偏离程序，即算法本身的拟合能力  </li><li>方差度量了同样大小的训练集的变动所导致的学习性能的变化，即模型的泛化能力</li></ul><ol><li>高偏差：一般称为欠拟合（underfitting），即莫i选哪个并没有很好的适配现有数据，拟合度不够</li><li>高方差：一般称为过拟合（overfitting），即模型对于训练的拟合度太高了，失去了泛化能力</li></ol><h5 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h5><p>欠拟合：</p><ol><li>增加网络结构，如增加隐藏层数目</li><li>训练更长的时间</li><li>寻找合适的网络架构，使用更大的NN结构</li></ol><p>过拟合：</p><ol><li>使用更多数据</li><li>正则化（regularization）</li><li>寻找合适的网络结构</li></ol><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 计算偏差</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token operator">-</span>w<span class="token punctuation">.</span>data<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token operator">-</span>b<span class="token punctuation">.</span>data<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>-0.03357887268066406 0.03234291076660156</code></pre><h4 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h4><p>利用正则化解决高方差问题，正则化在Cost function中加入正则化项，惩罚模型的复杂度  </p><h5 id="L1正则化"><a href="#L1正则化" class="headerlink" title="L1正则化"></a>L1正则化</h5><p>在损失函数的基础上加上权重参数的绝对值</p><p>$L=E_in + \lambda \Sigma_j |w_j|$</p><h5 id="L2正则化"><a href="#L2正则化" class="headerlink" title="L2正则化"></a>L2正则化</h5><p>在损失函数的基础上加权重参数的平方和  </p><p>$L=E_in + \lambda \Sigma_j w_j^2$</p><p><strong>L1比L2更容易获得稀疏解</strong></p><ul><li>W大于1的时候， L2正则项的w更新速度比L1快；当w小于1的时候，L1比L2快，而且L1的w更新很容易就能到0；</li><li>L2正则项，w的分布时高斯分布（对高斯概率密度函数取log得到w的平方项）；L1正则项，w的分布是拉普拉斯分布（对Laplace概率密度函数取log得到w的绝对值项）</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch-数据处理及预加载</title>
      <link href="/2020/04/28/Pytorch-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%8F%8A%E9%A2%84%E5%8A%A0%E8%BD%BD/"/>
      <url>/2020/04/28/Pytorch-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%8F%8A%E9%A2%84%E5%8A%A0%E8%BD%BD/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch基础：数据加载和预处理"><a href="#Pytorch基础：数据加载和预处理" class="headerlink" title="Pytorch基础：数据加载和预处理"></a>Pytorch基础：数据加载和预处理</h1><p>Pytorch通过torch.utils.data对数据实现封装，可以容易的实现多线程数据预读和批量加载</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torchtorch<span class="token punctuation">.</span>__version__<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>'1.1.0'</code></pre><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p>Dataset是一个抽象类，为方便读取，需要将使用的数据包装为Dataset类。自定义Dataset需要继承它并实现他的两个方法：</p><ol><li><strong>getitem</strong>() 该方法定义用索引（0到self.len）获取一条数据或一个样本</li><li><strong>len</strong>() 该方法返回数据总长度</li></ol><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment" spellcheck="true"># 定义一个数据类</span><span class="token keyword">class</span> <span class="token class-name">Diabetes</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Diabetes<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        data <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span><span class="token string">'.//data//diabetes.csv.gz'</span><span class="token punctuation">,</span>                          delimiter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">,</span>                          dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>len <span class="token operator">=</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 根据index返回一行数据</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>x_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>y_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 返回data长度</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>len<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>len</strong> 方法可以直接使用len获取数据总数</p><pre class="line-numbers language-python"><code class="language-python">diabetes <span class="token operator">=</span> Diabetes<span class="token punctuation">(</span><span class="token punctuation">)</span>len<span class="token punctuation">(</span>diabetes<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>759</code></pre><h3 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h3><p>DataLoader提供了对Dataset的读取操作，常用的参数：batch_size（每个批次大小），shuffle（是否进行shuffle操作），num_workers（加载数据时使用几个子进程）</p><pre class="line-numbers language-python"><code class="language-python">d <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>diabetes<span class="token punctuation">,</span>                                batch_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>                                shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>DataLoader返回一个可迭代对象，可使用迭代器分批次获取</p><pre class="line-numbers language-python"><code class="language-python">itdata <span class="token operator">=</span> iter<span class="token punctuation">(</span>d<span class="token punctuation">)</span>next<span class="token punctuation">(</span>itdata<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>[tensor([[ 0.7647,  0.3668,  0.1475, -0.3535, -0.7400,  0.1058, -0.9360, -0.2667],         [-0.8824,  0.0050,  0.0820, -0.6970, -0.8676, -0.2966, -0.4979, -0.8333],         [-0.5294,  0.3668,  0.1475,  0.0000,  0.0000, -0.0700, -0.0572, -0.9667],         [ 0.0000,  0.4171,  0.0000,  0.0000,  0.0000,  0.2638, -0.8915, -0.7333],         [-0.7647,  0.0854,  0.0164, -0.3535, -0.8676, -0.2489, -0.9573,  0.0000],         [-0.5294,  0.1256,  0.2787, -0.1919,  0.0000,  0.1744, -0.8651, -0.4333],         [-0.7647, -0.1859, -0.0164, -0.5556,  0.0000, -0.1744, -0.8190, -0.8667],         [-0.7647,  0.1859,  0.3115,  0.0000,  0.0000,  0.2787, -0.4748,  0.0000],         [-0.8824,  0.1256,  0.3115, -0.0909, -0.6879,  0.0373, -0.8813, -0.9000],         [ 0.0000,  0.4673,  0.3443,  0.0000,  0.0000,  0.2072,  0.4543, -0.2333]]), tensor([[0.],         [1.],         [0.],         [0.],         [1.],         [1.],         [1.],         [0.],         [1.],         [1.]])]</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 常见用法是使用for循环遍历</span><span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> data<span class="token punctuation">)</span>    <span class="token keyword">break</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre><code>0 [tensor([[ 0.0000,  0.1859,  0.3770, -0.0505, -0.4563,  0.3651, -0.5961, -0.6667],        [ 0.0588, -0.1055,  0.0164,  0.0000,  0.0000, -0.3294, -0.9453, -0.6000],        [ 0.0000,  0.1759,  0.0820, -0.3737, -0.5556, -0.0820, -0.6456, -0.9667],        [ 0.1765,  0.6884,  0.2131,  0.0000,  0.0000,  0.1326, -0.6080, -0.5667],        [-0.7647,  0.4673,  0.0000,  0.0000,  0.0000, -0.1803, -0.8617, -0.7667],        [-0.1765,  0.1457,  0.2459, -0.6566, -0.7400, -0.2906, -0.6687, -0.6667],        [-0.7647,  0.1256,  0.0820, -0.5556,  0.0000, -0.2548, -0.8044, -0.9000],        [-0.8824,  0.3367,  0.6721, -0.4343, -0.6690, -0.0224, -0.8668, -0.2000],        [-0.8824,  0.6784,  0.2131, -0.6566, -0.6596, -0.3025, -0.6849, -0.6000],        [-0.8824,  0.1658,  0.2787, -0.4141, -0.5745,  0.0760, -0.6430, -0.8667]]), tensor([[0.],        [1.],        [1.],        [0.],        [0.],        [1.],        [1.],        [0.],        [0.],        [1.]])]</code></pre><h3 id="torchvision"><a href="#torchvision" class="headerlink" title="torchvision"></a>torchvision</h3><p>torchvision是Pytorch中用来处理图像的库<br>torchvision.datasets 为Pytorch官方定义的dataset：可直接使用MNIST、COCO、Detetion、LSUN、CIFAR10等</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span> transformstrainset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>    root<span class="token operator">=</span><span class="token string">'.//data//'</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 加载MNIST数据的目录</span>    train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 标识加载数据集，为false时为测试集</span>    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 是否自动下载数据</span>    transform<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 是否需要对数据进行预处理， None时不进行预处理</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="torchvision-models"><a href="#torchvision-models" class="headerlink" title="torchvision.models"></a>torchvision.models</h3><p>torchvision还提供了训练好的模型，可以在进行迁移学习torchvision.models模块的子模块中包含以下结构：  </p><ul><li>AlexNet</li><li>VGG</li><li>ResNet</li><li>SqueezeNet</li><li>DenseNet</li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> torchvision <span class="token keyword">import</span> modelsresnet18 <span class="token operator">=</span> models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>Downloading: "https://download.pytorch.org/models/resnet18-5c106cde.pth" to C:\Users\Zephyrus/.cache\torch\checkpoints\resnet18-5c106cde.pth---------------------------------------------------------------------------</code></pre><h3 id="torchvision-transforms"><a href="#torchvision-transforms" class="headerlink" title="torchvision.transforms"></a>torchvision.transforms</h3><p>transforms模块提供了一般的图像转换操作类，用于数据处理和数据增强</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transformstransform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    transforms<span class="token punctuation">.</span>RandomCrop<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 先四周填充0，把图像随机裁剪成32x32</span>    transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 把图像一般概率翻转，一半的概率不翻转</span>    transforms<span class="token punctuation">.</span>RandomRotation<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">45</span><span class="token punctuation">,</span> <span class="token number">45</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 随机旋转</span>    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.4914</span><span class="token punctuation">,</span> <span class="token number">0.4822</span><span class="token punctuation">,</span> <span class="token number">0.4465</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                         <span class="token punctuation">(</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># RGB每层的归一化用到的均值和方差</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://discuss.pytorch.org/t/normalization-in-mnist-example/457/21" target="_blank" rel="noopener">关于(0.4914, 0.4822, 0.4465),(0.229, 0.224, 0.225)</a>详情说明，这些是根据ImageNet训练的归一化参数，可以直接使用，可认为为固定值</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch-神经网络和优化器</title>
      <link href="/2020/04/28/Pytorch-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8/"/>
      <url>/2020/04/28/Pytorch-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="Pytorch基础：神经网络和优化器"><a href="#Pytorch基础：神经网络和优化器" class="headerlink" title="Pytorch基础：神经网络和优化器"></a>Pytorch基础：神经网络和优化器</h2><p>torch.nn是为神经网络设计的模块化接口。nn构建与autograd上，可用来定义和运行神经网络<br>nn.functional是神经网络中使用的一些常用的函数，（不具有可学习参数，如ReLU、pool、DropOut等）</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 导入相关包</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn  <span class="token comment" spellcheck="true"># 一般设置别名为nn</span><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F  <span class="token comment" spellcheck="true"># 一般设置别名为F</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="定义一个网络"><a href="#定义一个网络" class="headerlink" title="定义一个网络"></a>定义一个网络</h3><p>Pytorch中已准备好的了现有的网络模型，只要继承nn.Module类，并实现forward方法。Pytorch会根据autograd，自动实现backward函数，在forward函数中可使用任何tensor支持的操作及Python语法</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># nn.Module字类函数必须在构建函数中执行父类的构造函数</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 卷积层， 1为单通道， 6为输出通道， 3为卷积核3x3</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1350</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 正向传播</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 结果：[1, 1, 32, 32]</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#根据卷积的尺寸计算公式，计算结果为30</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 结果：[1, 6, 30, 30]</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 池化层， 计算结果为15</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 结果：[1, 6, 15, 15]</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># -1表示自适应，该操作是把[1, 6, 15, 15]压扁，变为[-1， 1350]</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xnet <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Net(  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))  (fc1): Linear(in_features=1350, out_features=10, bias=True))</code></pre><p>网络的科学系参数通过.parameters()返回</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>Parameter containing:tensor([[[[-0.1501,  0.0207, -0.2991],          [ 0.1171,  0.0988,  0.0631],          [ 0.2022, -0.1330, -0.2333]]],        [[[ 0.2957, -0.2145, -0.2514],          [ 0.1999, -0.0470, -0.0605],          [ 0.2975,  0.1932,  0.0635]]],        [[[ 0.1194, -0.2086, -0.1382],          [ 0.0685,  0.1700, -0.1252],          [-0.3048, -0.0106,  0.1005]]],        [[[ 0.3157,  0.3140, -0.1614],          [ 0.1859, -0.2659, -0.1587],          [-0.2780, -0.2142, -0.0624]]],        [[[ 0.2214,  0.1233,  0.1699],          [-0.2489, -0.1493, -0.3306],          [ 0.2730,  0.1064, -0.0716]]],        [[[ 0.3102,  0.2241, -0.2976],          [ 0.0525, -0.0518,  0.1736],          [ 0.2654,  0.3064,  0.3140]]]], requires_grad=True)Parameter containing:tensor([-0.2208, -0.1180, -0.1639, -0.0986,  0.1076,  0.0020],       requires_grad=True)Parameter containing:tensor([[ 0.0004,  0.0112,  0.0163,  ..., -0.0033, -0.0175,  0.0021],        [-0.0188,  0.0177, -0.0196,  ..., -0.0163, -0.0052, -0.0001],        [-0.0009, -0.0209,  0.0002,  ...,  0.0217, -0.0135,  0.0113],        ...,        [-0.0246, -0.0269,  0.0255,  ...,  0.0067, -0.0116, -0.0021],        [ 0.0222,  0.0139,  0.0108,  ..., -0.0138,  0.0266,  0.0183],        [ 0.0195, -0.0110, -0.0210,  ...,  0.0056, -0.0081,  0.0261]],       requires_grad=True)Parameter containing:tensor([ 0.0119, -0.0075,  0.0034, -0.0180, -0.0205, -0.0038,  0.0109, -0.0236,         0.0165,  0.0253], requires_grad=True)</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># net.named_parameters可同时返回参数及名称</span><span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'name: {}, parameters: {}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>name<span class="token punctuation">,</span> param<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>name: conv1.weight, parameters: torch.Size([6, 1, 3, 3])name: conv1.bias, parameters: torch.Size([6])name: fc1.weight, parameters: torch.Size([10, 1350])name: fc1.bias, parameters: torch.Size([10])</code></pre><p>forward函数输入和输出都是Tensor</p><pre class="line-numbers language-python"><code class="language-python">inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>outputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>torch.Size([1, 1, 32, 32])torch.Size([1, 6, 30, 30])torch.Size([1, 6, 15, 15])torch.Size([1, 1350])torch.Size([1, 10])</code></pre><pre class="line-numbers language-python"><code class="language-python">inputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>torch.Size([1, 1, 32, 32])</code></pre><p>反向传播前，首先要将所有的梯度清零<br>反向传播是Pytorch自动实现的，只需调用.backward函数即可</p><pre class="line-numbers language-python"><code class="language-python">net<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>outputs<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>torch.nn只支持batch，不支持一次只输入一个样本。</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># nn中预设了常用的损失函数</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> y<span class="token punctuation">)</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>26.876943588256836</code></pre><h4 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h4><p>反向传播计算完所有梯度后，还需要使用优化方法来更新网络的权重和参数。例如随机梯度下降<br>weight = weight - learning_rate * gradient<br>torch.optim中实现了大多数优化方法</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optimout <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>out<span class="token punctuation">,</span> y<span class="token punctuation">)</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 新建优化器，SGD只需调整参数和学习率</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 梯度清零</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 更新参数</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>torch.Size([1, 1, 32, 32])torch.Size([1, 6, 30, 30])torch.Size([1, 6, 15, 15])torch.Size([1, 1350])</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch基础：自动求导</title>
      <link href="/2020/04/28/Pytorch-%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/"/>
      <url>/2020/04/28/Pytorch-%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/</url>
      
        <content type="html"><![CDATA[<h2 id="Pytorch-自动求导"><a href="#Pytorch-自动求导" class="headerlink" title="Pytorch 自动求导"></a>Pytorch 自动求导</h2><p>深度学习的算法本质上是通过反向传播求导数，而Pytorch的autograd模块实现了此功能。在Tensor上的所有操作，autograd均能为它们提供自动微分</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 在创建张量的时候，可以通过指定requires_grad=True标识，进行自动求导，Pytorch会记录该张量的每一步操作历史，并自动计算</span><span class="token keyword">import</span> torchx <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>tensor([[0.0803, 0.9218, 0.3219],        [0.8003, 0.1912, 0.9332],        [0.6010, 0.2762, 0.0237]], requires_grad=True)</code></pre><pre class="line-numbers language-python"><code class="language-python">y <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([[0.1794, 0.3274, 0.1144],        [0.5815, 0.3099, 0.3854],        [0.0383, 0.7856, 0.2387]], requires_grad=True)</code></pre><pre class="line-numbers language-python"><code class="language-python">z <span class="token operator">=</span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>x <span class="token operator">+</span> y<span class="token punctuation">)</span>z<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor(7.1100, grad_fn=&lt;SumBackward0&gt;)</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 简单的自动求导</span>z<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">,</span> y<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor([[1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.]]) tensor([[1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.]])</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 复杂的自动求导</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>z <span class="token operator">=</span> y<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> x<span class="token operator">**</span><span class="token number">3</span>z<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>tensor([[0.2509, 1.5016, 0.7266],        [0.1246, 0.9339, 0.3272],        [1.0595, 0.4782, 0.0501]], grad_fn=&lt;AddBackward0&gt;)</code></pre><pre class="line-numbers language-python"><code class="language-python">z<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>x<span class="token punctuation">.</span>grad<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([[0.8078, 2.2859, 2.1076],        [0.4714, 2.6892, 0.8068],        [2.2977, 0.2319, 0.0336]])</code></pre><p>使用with torch.no_grad()禁止对已设置requires_grad=True的张量进行自动求导，一般应用在计算测试集准确率时</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">(</span>x <span class="token operator">+</span> y <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>False</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch:张量</title>
      <link href="/2020/04/28/Pytorch-%E5%BC%A0%E9%87%8F/"/>
      <url>/2020/04/28/Pytorch-%E5%BC%A0%E9%87%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="Autograd-Automatic-Differentiation"><a href="#Autograd-Automatic-Differentiation" class="headerlink" title="Autograd:Automatic Differentiation"></a>Autograd:Automatic Differentiation</h2><p>autograd是Pytorch中神经网络的核心<br>autograd包对所有在Tensor上的操作提供自动微分。是一个按运行定义的框架。这意味着backprop是由代码的运行方式定义的，并且每个迭代可以是不同的</p><h3 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h3><p>torch.Tensor是这个包的核心类。</p><ul><li>.requires_grad=True可以追踪所有在其的操作。</li></ul><h1 id="Pytorch-基础：张量"><a href="#Pytorch-基础：张量" class="headerlink" title="Pytorch 基础：张量"></a>Pytorch 基础：张量</h1><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>1.1.0</code></pre><h2 id="张量-Tensor"><a href="#张量-Tensor" class="headerlink" title="张量(Tensor)"></a>张量(Tensor)</h2><p>Pytorch里基础运算单位，与Numpy的ndarray相同都是表示一个多维的矩阵。与ndarray的最大区别是，Tensor可以在GPU上运行，而numpy的ndarrary只能在CPU上运行，在GPU上可以加速运算</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 简单张量</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>tensor([[ 0.6559, -0.4488],        [-0.6773,  0.1955]])</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 查看大小 ，可以使用与numpy相同的shape属性</span>x<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>torch.Size([2, 2])</code></pre><pre class="line-numbers language-python"><code class="language-python">x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 也可以使用size()函数</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>torch.Size([2, 2])</code></pre><p>张量（Tensor）是一个定义在一些向量空间和对偶空间的笛卡尔乘积上的多重线性映射，其坐标是n维空间内，有n个分量的一种量，其中每个分量都是坐标的函数，在坐标变换时，这些分量也按照某些规则作线性变化。r称为该向量的秩或阶</p><pre class="line-numbers language-python"><code class="language-python">y <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([[[0.5697, 0.8745, 0.3675, 0.1490],         [0.0393, 0.9375, 0.8695, 0.9460],         [0.9790, 0.3922, 0.5406, 0.3504]],        [[0.5684, 0.1488, 0.7164, 0.7056],         [0.5746, 0.5168, 0.6269, 0.4023],         [0.6346, 0.5118, 0.0181, 0.3209]]])</code></pre><p>在同构的意义下，第零阶张量(r=0)为标量，第一阶张量（r=1）为向量，第二阶张量（r=2）为矩阵，第三阶及以上统称为多维向量</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 标量</span>scalar <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">3.1415926</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>scalar<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>scalar<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre><code>tensor(3.1416)torch.Size([])</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 对于标量可以直接使用.item() 从中取出对应的数值</span>scalar<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>3.141592502593994</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 张量中只有一个元素的tensor也可以调用.item()方法</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3.14159</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>tensor<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>tensor([3.1416])torch.Size([1])3.141590118408203</code></pre><h3 id="基本类型"><a href="#基本类型" class="headerlink" title="基本类型"></a>基本类型</h3><p>Tensor的基本数据类型：  </p><ul><li>32位浮点型：torch.FloatTensor  (default)</li><li>64位浮点型：torch.DoubleTensor</li><li>64位整型：torch.LongTensor</li><li>32位整型：torch.IntTensor</li><li>16位整型：torch.ShortTensor</li><li>除以上数字类型外还有byte和chart型</li></ul><pre class="line-numbers language-python"><code class="language-python">long <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>long<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([], dtype=torch.int64)</code></pre><pre class="line-numbers language-python"><code class="language-python">double <span class="token operator">=</span> torch<span class="token punctuation">.</span>DoubleTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>double<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([], dtype=torch.float64)</code></pre><pre class="line-numbers language-python"><code class="language-python">Float <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>Float<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([])</code></pre><pre class="line-numbers language-python"><code class="language-python">short <span class="token operator">=</span> torch<span class="token punctuation">.</span>ShortTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>short<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([], dtype=torch.int16)</code></pre><pre class="line-numbers language-python"><code class="language-python">Int <span class="token operator">=</span> torch<span class="token punctuation">.</span>IntTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>Int<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([], dtype=torch.int32)</code></pre><pre class="line-numbers language-python"><code class="language-python">char <span class="token operator">=</span> torch<span class="token punctuation">.</span>CharTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>char<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([], dtype=torch.int8)</code></pre><pre class="line-numbers language-python"><code class="language-python">bt <span class="token operator">=</span> torch<span class="token punctuation">.</span>ByteTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>bt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([], dtype=torch.uint8)</code></pre><h3 id="Numpy转换"><a href="#Numpy转换" class="headerlink" title="Numpy转换"></a>Numpy转换</h3><p>使用numpy方法将tensor转换为ndarray</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>numpy_a <span class="token operator">=</span> a<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>numpy_a<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>array([[-0.04118568,  0.83802617],       [ 0.19688779, -0.8153309 ]], dtype=float32)</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># ndarray转换位numpy</span>torch_a <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>numpy_a<span class="token punctuation">)</span>torch_a<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>tensor([[-0.0412,  0.8380],        [ 0.1969, -0.8153]])</code></pre><p><strong>Tensor和Numpy对象共享内存，所以转换他们相互之间转换很快</strong></p><h3 id="设备间转换"><a href="#设备间转换" class="headerlink" title="设备间转换"></a>设备间转换</h3><p>一般使用.cuda方法将tensor移动到gpu</p><pre class="line-numbers language-python"><code class="language-python">cpu_a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>cpu_a<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>'torch.FloatTensor'</code></pre><pre class="line-numbers language-python"><code class="language-python">gpu_a <span class="token operator">=</span> cpu_a<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>gpu_a<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>gpu_a<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>tensor([[0.8202, 0.8172],        [0.1292, 2.1433]], device='cuda:0')torch.cuda.FloatTensor</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 使用.cpu将tensor移动到cpu</span>cpu_b <span class="token operator">=</span> gpu_a<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>cpu_b<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>'torch.FloatTensor'</code></pre><p>如果有多GPU可用，可使用to方法确定使用设备</p><pre class="line-numbers language-python"><code class="language-python">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span>gpu_b<span class="token operator">=</span>cpu_b<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>gpu_b<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre><code>cuda'torch.cuda.FloatTensor'</code></pre><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>Pytorch中有许多初始化的方法</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 使用[0, 1]均匀分布初始化数组</span>rand <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>rand<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>tensor([[0.5435, 0.6259],        [0.8157, 0.4474],        [0.6790, 0.9695]])</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 使用0填充</span>zero <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>zero<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>tensor([[0., 0.],        [0., 0.]])</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 使用1填充</span>one <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>one<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>tensor([[1., 1.],        [1., 1.]])</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 初始化单位矩阵（对角线为1，其余为0）</span>eye <span class="token operator">=</span> torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>eye<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>tensor([[1., 0.],        [0., 1.]])</code></pre><p>Pytorch中对张量的操作类似Numpy操作</p><pre class="line-numbers language-python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([[ 1.1412, -1.0689],        [-0.1724, -0.6650]])</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 最大值, 沿行取 指定 dim=0/1</span>max_value <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>x<span class="token punctuation">)</span>max_value<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>tensor(1.1412)</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 求和</span>sum_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>sum_x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>tensor([ 0.0723, -0.8374])</code></pre><pre class="line-numbers language-python"><code class="language-python">y <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>z <span class="token operator">=</span> x <span class="token operator">+</span> y z<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>tensor([[ 2.0838, -0.6529],        [ 1.5526, -0.9550]])</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 以_结尾的方法，均会改变调用的值</span>x<span class="token punctuation">.</span>add_<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([[ 2.0838, -0.6529],        [ 1.5526, -0.9550]])</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/04/28/hello-world/"/>
      <url>/2020/04/28/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>start</title>
      <link href="/2020/04/23/start/"/>
      <url>/2020/04/23/start/</url>
      
        <content type="html"><![CDATA[<p>A thousand-li journey is started by taking the first step<br>千里之行始于足下</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
