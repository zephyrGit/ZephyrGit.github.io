<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Pytorch:张量</title>
      <link href="/2020/04/28/Pytorch-%E5%BC%A0%E9%87%8F/"/>
      <url>/2020/04/28/Pytorch-%E5%BC%A0%E9%87%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="Autograd-Automatic-Differentiation"><a href="#Autograd-Automatic-Differentiation" class="headerlink" title="Autograd:Automatic Differentiation"></a>Autograd:Automatic Differentiation</h2><p>autograd是Pytorch中神经网络的核心<br>autograd包对所有在Tensor上的操作提供自动微分。是一个按运行定义的框架。这意味着backprop是由代码的运行方式定义的，并且每个迭代可以是不同的</p><h3 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h3><p>torch.Tensor是这个包的核心类。</p><ul><li>.requires_grad=True可以追踪所有在其的操作。</li></ul><h1 id="Pytorch-基础：张量"><a href="#Pytorch-基础：张量" class="headerlink" title="Pytorch 基础：张量"></a>Pytorch 基础：张量</h1><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">print(torch.__version__)</span><br></pre></td></tr></tbody></table></figure><pre><code>1.1.0</code></pre><h2 id="张量-Tensor"><a href="#张量-Tensor" class="headerlink" title="张量(Tensor)"></a>张量(Tensor)</h2><p>Pytorch里基础运算单位，与Numpy的ndarray相同都是表示一个多维的矩阵。与ndarray的最大区别是，Tensor可以在GPU上运行，而numpy的ndarrary只能在CPU上运行，在GPU上可以加速运算</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 简单张量</span></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">x</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([[ 0.6559, -0.4488],        [-0.6773,  0.1955]])</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看大小 ，可以使用与numpy相同的shape属性</span></span><br><span class="line">x.shape</span><br></pre></td></tr></tbody></table></figure><pre><code>torch.Size([2, 2])</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x.size()</span><br><span class="line"><span class="comment"># 也可以使用size()函数</span></span><br></pre></td></tr></tbody></table></figure><pre><code>torch.Size([2, 2])</code></pre><p>张量（Tensor）是一个定义在一些向量空间和对偶空间的笛卡尔乘积上的多重线性映射，其坐标是n维空间内，有n个分量的一种量，其中每个分量都是坐标的函数，在坐标变换时，这些分量也按照某些规则作线性变化。r称为该向量的秩或阶</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = torch.rand(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">y</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([[[0.5697, 0.8745, 0.3675, 0.1490],         [0.0393, 0.9375, 0.8695, 0.9460],         [0.9790, 0.3922, 0.5406, 0.3504]],        [[0.5684, 0.1488, 0.7164, 0.7056],         [0.5746, 0.5168, 0.6269, 0.4023],         [0.6346, 0.5118, 0.0181, 0.3209]]])</code></pre><p>在同构的意义下，第零阶张量(r=0)为标量，第一阶张量（r=1）为向量，第二阶张量（r=2）为矩阵，第三阶及以上统称为多维向量</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标量</span></span><br><span class="line">scalar = torch.tensor(<span class="number">3.1415926</span>)</span><br><span class="line">print(scalar)</span><br><span class="line">print(scalar.size())</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor(3.1416)torch.Size([])</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于标量可以直接使用.item() 从中取出对应的数值</span></span><br><span class="line">scalar.item()</span><br></pre></td></tr></tbody></table></figure><pre><code>3.141592502593994</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 张量中只有一个元素的tensor也可以调用.item()方法</span></span><br><span class="line">tensor = torch.tensor([<span class="number">3.14159</span>])</span><br><span class="line">print(tensor)</span><br><span class="line">print(tensor.shape)</span><br><span class="line">tensor.item()</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([3.1416])torch.Size([1])3.141590118408203</code></pre><h3 id="基本类型"><a href="#基本类型" class="headerlink" title="基本类型"></a>基本类型</h3><p>Tensor的基本数据类型：  </p><ul><li>32位浮点型：torch.FloatTensor  (default)</li><li>64位浮点型：torch.DoubleTensor</li><li>64位整型：torch.LongTensor</li><li>32位整型：torch.IntTensor</li><li>16位整型：torch.ShortTensor</li><li>除以上数字类型外还有byte和chart型</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">long = torch.LongTensor()</span><br><span class="line">long</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([], dtype=torch.int64)</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">double = torch.DoubleTensor()</span><br><span class="line">double</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([], dtype=torch.float64)</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Float = torch.FloatTensor()</span><br><span class="line">Float</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([])</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">short = torch.ShortTensor()</span><br><span class="line">short</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([], dtype=torch.int16)</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Int = torch.IntTensor()</span><br><span class="line">Int</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([], dtype=torch.int32)</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">char = torch.CharTensor()</span><br><span class="line">char</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([], dtype=torch.int8)</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bt = torch.ByteTensor()</span><br><span class="line">bt</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([], dtype=torch.uint8)</code></pre><h3 id="Numpy转换"><a href="#Numpy转换" class="headerlink" title="Numpy转换"></a>Numpy转换</h3><p>使用numpy方法将tensor转换为ndarray</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">numpy_a = a.numpy()</span><br><span class="line">numpy_a</span><br></pre></td></tr></tbody></table></figure><pre><code>array([[-0.04118568,  0.83802617],       [ 0.19688779, -0.8153309 ]], dtype=float32)</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ndarray转换位numpy</span></span><br><span class="line">torch_a = torch.from_numpy(numpy_a)</span><br><span class="line">torch_a</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([[-0.0412,  0.8380],        [ 0.1969, -0.8153]])</code></pre><p><strong>Tensor和Numpy对象共享内存，所以转换他们相互之间转换很快</strong></p><h3 id="设备间转换"><a href="#设备间转换" class="headerlink" title="设备间转换"></a>设备间转换</h3><p>一般使用.cuda方法将tensor移动到gpu</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cpu_a = torch.randn(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">cpu_a.type()</span><br></pre></td></tr></tbody></table></figure><pre><code>'torch.FloatTensor'</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gpu_a = cpu_a.cuda()</span><br><span class="line">print(gpu_a)</span><br><span class="line">print(gpu_a.type())</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([[0.8202, 0.8172],        [0.1292, 2.1433]], device='cuda:0')torch.cuda.FloatTensor</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用.cpu将tensor移动到cpu</span></span><br><span class="line">cpu_b = gpu_a.cpu()</span><br><span class="line">cpu_b.type()</span><br></pre></td></tr></tbody></table></figure><pre><code>'torch.FloatTensor'</code></pre><p>如果有多GPU可用，可使用to方法确定使用设备</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line">print(device)</span><br><span class="line">gpu_b=cpu_b.to(device)</span><br><span class="line">gpu_b.type()</span><br></pre></td></tr></tbody></table></figure><pre><code>cuda'torch.cuda.FloatTensor'</code></pre><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>Pytorch中有许多初始化的方法</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用[0, 1]均匀分布初始化数组</span></span><br><span class="line">rand = torch.rand(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">rand</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([[0.5435, 0.6259],        [0.8157, 0.4474],        [0.6790, 0.9695]])</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用0填充</span></span><br><span class="line">zero = torch.zeros(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">zero</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([[0., 0.],        [0., 0.]])</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用1填充</span></span><br><span class="line">one = torch.ones(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">one</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([[1., 1.],        [1., 1.]])</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化单位矩阵（对角线为1，其余为0）</span></span><br><span class="line">eye = torch.eye(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">eye</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([[1., 0.],        [0., 1.]])</code></pre><p>Pytorch中对张量的操作类似Numpy操作</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">x</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([[ 1.1412, -1.0689],        [-0.1724, -0.6650]])</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最大值, 沿行取 指定 dim=0/1</span></span><br><span class="line">max_value = torch.max(x)</span><br><span class="line">max_value</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor(1.1412)</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 求和</span></span><br><span class="line">sum_x = torch.sum(x, dim=<span class="number">1</span>)</span><br><span class="line">sum_x</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([ 0.0723, -0.8374])</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y = torch.randn(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">z = x + y </span><br><span class="line">z</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([[ 2.0838, -0.6529],        [ 1.5526, -0.9550]])</code></pre><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以_结尾的方法，均会改变调用的值</span></span><br><span class="line">x.add_(y)</span><br></pre></td></tr></tbody></table></figure><pre><code>tensor([[ 2.0838, -0.6529],        [ 1.5526, -0.9550]])</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/04/28/hello-world/"/>
      <url>/2020/04/28/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></tbody></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></tbody></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></tbody></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></tbody></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>tags</title>
      <link href="/2020/04/26/tags/"/>
      <url>/2020/04/26/tags/</url>
      
        <content type="html"><![CDATA[<script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>start</title>
      <link href="/2020/04/23/start/"/>
      <url>/2020/04/23/start/</url>
      
        <content type="html"><![CDATA[<p>A thousand-li journey is started by taking the first step<br>千里之行始于足下</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
